{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "c0b9Buka3xZm"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import csv\n",
        "import time\n",
        "import math\n",
        "import json\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import scipy.sparse as sp\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from math import log\n",
        "from tqdm.notebook import tqdm\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from IPython.display import display\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "wAyIrQR13xZn"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lq_cMfiv3xZn"
      },
      "outputs": [],
      "source": [
        "EDGE = 1 # 0:d2w 1:d2w+w2w 2:d2w+w2w+d2d\n",
        "NODE = 0 # 0:one-hot #1:BERT\n",
        "NUM_LAYERS = 2\n",
        "graph_window_sizes = 20\n",
        "HIDDEN_DIM = 200\n",
        "DROP_OUT = 0.3  #DROP_OUT = 0.5\n",
        "LR = 0.01  #LR = 0.01 for cs data\n",
        "WEIGHT_DECAY = 0\n",
        "EARLY_STOPPING = 145  # EARLY_STOPPING = 10\n",
        "NUM_EPOCHS = 200\n",
        "dataset = [\"arXiv\", \"DBLP\", \"Elsevier\", \"PubMed\"]\n",
        "dataset_index = dataset[0] # Save the file name with index value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "KhNYuaY83xZn"
      },
      "outputs": [
        {
          "ename": "OSError",
          "evalue": "[Errno 22] Invalid argument: \"C:/Users/romeo/AAAI'25/citation_datasets\\x07rXiv_citation_dataset.json\"",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load the JSON data from file\u001b[39;00m\n\u001b[0;32m      2\u001b[0m file_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mC:/Users/romeo/AAAI\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m25/citation_datasets\u001b[39m\u001b[38;5;130;01m\\a\u001b[39;00m\u001b[38;5;124mrXiv_citation_dataset.json\u001b[39m\u001b[38;5;124m\"\u001b[39m  \n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(file_path, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m      4\u001b[0m     scholar_data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(file)\n",
            "File \u001b[1;32mc:\\Users\\romeo\\anaconda3\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m io_open(file, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "\u001b[1;31mOSError\u001b[0m: [Errno 22] Invalid argument: \"C:/Users/romeo/AAAI'25/citation_datasets\\x07rXiv_citation_dataset.json\""
          ]
        }
      ],
      "source": [
        "# Load the JSON data from file\n",
        "file_path = \"C:/Users/romeo/AAAI'25/citation_datasets\\arXiv_citation_dataset.json\"  \n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
        "    scholar_data = json.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H83b8vlp3xZn"
      },
      "source": [
        "## Making cited_by paper direct cite the main paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "WN9WX29I3xZo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total main articles: 101\n",
            "Total citing articles: 435\n",
            "Total nodes: 647\n",
            "Total edges: 546\n",
            "\n",
            "✅ All data saved to: C:/Users/romeo/AAAI'25/citation_corpus\\arXiv_citation_graph.json\n",
            "Graph data written to graph_representation_all.json\n"
          ]
        }
      ],
      "source": [
        "# Initialize overall graph data\n",
        "all_nodes = []\n",
        "all_edges = []\n",
        "all_titles_lists = []\n",
        "all_abstracts = {}\n",
        "\n",
        "# Loop through each main article\n",
        "for idx, main_entry in enumerate(scholar_data):\n",
        "    # Construct main abstract node\n",
        "    main_abstract = f\"Main_{idx+1}: \" + main_entry[\"original_csv_abstract\"]\n",
        "    all_nodes.append(main_abstract)\n",
        "    all_abstracts[main_abstract] = main_entry[\"original_csv_abstract\"]\n",
        "\n",
        "    # Loop through citing articles\n",
        "    citing_articles = main_entry.get(\"citing_articles\", [])\n",
        "    for i, article in enumerate(citing_articles):\n",
        "        node_abstract = f\"Cite_{idx+1}_{i+1}: {article['abstract']}\"\n",
        "        all_nodes.append(node_abstract)\n",
        "        all_edges.append((node_abstract, main_abstract))  # Citing -> Main\n",
        "        all_abstracts[node_abstract] = article[\"abstract\"]\n",
        "\n",
        "\n",
        "print(f\"Total main articles: {len(scholar_data)}\")\n",
        "print(f\"Total citing articles: {len(node_abstract)}\")\n",
        "print(f\"Total nodes: {len(all_nodes)}\")\n",
        "print(f\"Total edges: {len(all_edges)}\")\n",
        "\n",
        "\n",
        "# Save as JSON\n",
        "output_data = {\n",
        "    \"nodes\": all_nodes,\n",
        "    \"edges\": all_edges,\n",
        "    \"all_abstracts\": all_abstracts,\n",
        "    \"titles\": all_titles_lists,\n",
        "}\n",
        "\n",
        "#Set output path\n",
        "output_dir = r\"C:/Users/romeo/AAAI'25/citation_corpus\" \n",
        "output_filename = f\"{dataset[dataset_index]}.json\"\n",
        "output_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "# Save JSON\n",
        "try:\n",
        "    os.makedirs(output_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
        "    with open(output_path, 'w', encoding='utf-8') as f:\n",
        "        json.dump(output_data, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"\\n✅ All data saved to: {output_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error saving data to JSON file: {e}\")\n",
        "\n",
        "\n",
        "# with open(\"graph_representation_all.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "#     json.dump(output_data, f, ensure_ascii=False, indent=4)\n",
        "\n",
        "print(\"Graph data written to graph_representation_all.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AhLMaadN3xZo"
      },
      "source": [
        "## Extract Title"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "eElxypid3xZo"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "All titles: 647\n"
          ]
        }
      ],
      "source": [
        "all_titles_lists = []\n",
        "for entry in scholar_data:\n",
        "    all_titles_lists.append(entry[\"original_csv_title\"])\n",
        "    all_titles_lists.extend(cit[\"title\"] for cit in entry.get(\"citing_articles\", []))\n",
        "\n",
        "print(\"All titles:\", len(all_titles_lists))\n",
        "\n",
        "#Set output path\n",
        "output_dir = r\"C:\\Users\\romeo\\AAAI'25\\label_data\\raw_title\"\n",
        "output_filename = f\"{dataset[dataset_index]}.json\"\n",
        "output_path = os.path.join(output_dir, output_filename)\n",
        "\n",
        "# Save JSON\n",
        "try:\n",
        "    os.makedirs(output_dir, exist_ok=True)  # Create directory if it doesn't exist\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump({\"titles\": all_titles_lists}, f, ensure_ascii=False, indent=4)\n",
        "    print(f\"\\n✅ All data saved to{dataset[dataset_index]}: {output_path}\")\n",
        "except Exception as e:\n",
        "    print(f\"❌ Error saving data to JSON file: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "CuTp53vQ3xZo"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\romeo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\romeo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     C:\\Users\\romeo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     C:\\Users\\romeo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     C:\\Users\\romeo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     C:\\Users\\romeo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     C:\\Users\\romeo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     C:\\Users\\romeo\\AppData\\Roaming\\nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "517\n",
            "130\n",
            "Vocabulary size: 1024\n",
            "{'hole': 1, 'vacuum': 2, 'environment': 3, 'influence': 4, 'waveform': 5, 'wave': 6, 'analysi': 7, 'work': 8, 'focu': 9, 'generation': 10, 'evolution': 11, 'type': 12, 'center': 13, 'gc': 14, 'region': 15, 'smbh': 16, 'hypervelocity': 17, 'star': 18, 'counterpart': 19, 'orbit': 20, 'hvs': 21, 'escape': 22, 'speed': 23, 'halo': 24, 'distribution': 25, 'velocity': 26, 'merger': 27, 'way': 28, 'galaxy': 29, 'change': 30, 'hv': 31, 'ejection': 32, 'scenario': 33, 'formation': 34, 'cluster': 35, 'size': 36, 'quantization': 37, 'relativity': 38, 'tegr': 39, 'space': 40, 'time': 41, 'formulation': 42, 'equation': 43, 'theory': 44, 'treatment': 45, 'operator': 46, 'number': 47, 'term': 48, 'hamiltonian': 49, 'value': 50, 'existence': 51, 'multus': 52, 'flavor': 53, 'conversion': 54, 'neutrino': 55, 'emission': 56, 'angle': 57, 'accretion': 58, 'toru': 59, 'geometry': 60, 'neutron': 61, 'occurrence': 62, 'direction': 63, 'production': 64, 'density': 65, 'parameter': 66, 'rate': 67, 'gravity': 68, 'contribution': 69, 'system': 70, 'formulate': 71, 'frame': 72, 'einstein': 73, 'show': 74, 'function': 75, 'expansion': 76, 'matter': 77, 'centre': 78, 'measure': 79, 'state': 80, 'conjecture': 81, 'property': 82, 'sequence': 83, 'n': 84, 'text': 85, 'world': 86, 'computation': 87, 'quantum': 88, 'problem': 89, 'accurate': 90, 'simulation': 91, 'day': 92, 'hardware': 93, 'computer': 94, 'model': 95, 'molecule': 96, 'cancer': 97, 'mechanism': 98, 'eigensolver': 99, 'vqe': 100, 'field': 101, 'impurity': 102, 'aim': 103, 'structure': 104, 'body': 105, 'effort': 106, 'electron': 107, 'introduction': 108, 'use': 109, 'efficiency': 110, 'chemistry': 111, 'ratio': 112, 'composition': 113, 'complexity': 114, 'observation': 115, 'behavior': 116, 'design': 117, 'lack': 118, 'verification': 119, 'development': 120, 'engineering': 121, 'capture': 122, 'prediction': 123, 'optimization': 124, 'network': 125, 'calculation': 126, 'scale': 127, 'survey': 128, 'era': 129, 'program': 130, 'ray': 131, 'concentration': 132, 'relation': 133, 'sample': 134, 'framework': 135, 'calibration': 136, 'redshift': 137, 'agreement': 138, 'sn': 139, 'effect': 140, 'vision': 141, 'localization': 142, 'satellite': 143, 'location': 144, 'vector': 145, 'navigation': 146, 'dof': 147, 'cro': 148, 'feature': 149, 'extraction': 150, 'module': 151, 'latency': 152, 'flight': 153, 'deployment': 154, 'representation': 155, 'map': 156, 'robustnes': 157, 'appearance': 158, 'estimation': 159, 'introduce': 160, 'dataset': 161, 'performance': 162, 'accuracy': 163, 'device': 164, 'generalization': 165, 'ability': 166, 'error': 167, 'orientation': 168, 'b': 169, 'km': 170, 'conclusion': 171, 'los': 172, 'regime': 173, 'population': 174, 'history': 175, 'image': 176, 'retrieval': 177, 'alignment': 178, 'fusion': 179, 'information': 180, 'attention': 181, 'gap': 182, 'weight': 183, 'allocation': 184, 'proces': 185, 'art': 186, 'review': 187, 'intelligence': 188, 'language': 189, 'transparency': 190, 'question': 191, 'background': 192, 'ai': 193, 'core': 194, 'analyze': 195, 'literature': 196, 'gradient': 197, 'issue': 198, 'mitigation': 199, 'importance': 200, 'reliability': 201, 'parameterization': 202, 'approximate': 203, 'energy': 204, 'construction': 205, 'validation': 206, 'correlation': 207, 'entropy': 208, 'identification': 209, 'applicability': 210, 'formalism': 211, 'chemical': 212, 'pairwise': 213, 'query': 214, 'gain': 215, 'plate': 216, 'detection': 217, 'classification': 218, 'enhance': 219, 'recognition': 220, 'stage': 221, 'addition': 222, 'variety': 223, 'augmentation': 224, 'community': 225, 'obstacle': 226, 'control': 227, 'regularity': 228, 'result': 229, 'distance': 230, 'improvement': 231, 'solution': 232, 'condition': 233, 'surface': 234, 'step': 235, 'formula': 236, 'estimate': 237, 'power': 238, 'consumption': 239, 'von': 240, 'bottleneck': 241, 'exchange': 242, 'memory': 243, 'processing': 244, 'unit': 245, 'paradigm': 246, 'demand': 247, 'non': 248, 'candidate': 249, 'transition': 250, 'possibility': 251, 'evaluate': 252, 'channel': 253, 'platform': 254, 'projection': 255, 'test': 256, 'dnn': 257, 'architecture': 258, 'goal': 259, 'method': 260, 'occupation': 261, 'input': 262, 'dissociation': 263, 'database': 264, 'quality': 265, 'curve': 266, 'spectroscopic': 267, 'panel': 268, 'heterogeneity': 269, 'estimator': 270, 'coefficient': 271, 'require': 272, 'bound': 273, 'regression': 274, 'application': 275, 'bf': 276, 'group': 277, 'bar': 278, 'g': 279, 'element': 280, 'r': 281, 'learning': 282, 'interest': 283, 'part': 284, 'dl': 285, 'capacity': 286, 'dimensionality': 287, 'sense': 288, 'approximation': 289, 'dimension': 290, 'describe': 291, 'heat': 292, 'activation': 293, 'displacement': 294, 'series': 295, 'period': 296, 'phase': 297, 'water': 298, 'recovery': 299, 'climate': 300, 'grace': 301, 'storage': 302, 'v': 303, 'set': 304, 'wavelet': 305, 'gns': 306, 'resolution': 307, 'benchmark': 308, 'increase': 309, 'advantage': 310, 'response': 311, 'graph': 312, 'order': 313, 'combination': 314, 'momentum': 315, 'frequency': 316, 'tensor': 317, 'redundancy': 318, 'evaluation': 319, 'diagram': 320, 'implementation': 321, 'renormalization': 322, 'scheme': 323, 'integration': 324, 'mode': 325, 'key': 326, 'technique': 327, 'machine': 328, 'methodology': 329, 'effectivenes': 330, 'ga': 331, 'quasiparticle': 332, 'metal': 333, 'separability': 334, 'example': 335, 'entanglement': 336, 'criterion': 337, 'measurement': 338, 'signal': 339, 'point': 340, 'need': 341, 'bridge': 342, 'knowledge': 343, 'assumption': 344, 'range': 345, 'article': 346, 'pipeline': 347, 'offering': 348, 'depth': 349, 'python': 350, 'support': 351, 'transpose': 352, 'pt': 353, 'qubit': 354, 'moment': 355, 'growth': 356, 'bulk': 357, 'side': 358, 'lattice': 359, 'skin': 360, 'amplification': 361, 'decay': 362, 'presence': 363, 'dissipation': 364, 'transmission': 365, 'line': 366, 'reveal': 367, 'tuning': 368, 'interplay': 369, 'strength': 370, 'propagation': 371, 'et': 372, 'al': 373, 'rev': 374, 'detail': 375, 'spin': 376, 'h': 377, 'hydrogen': 378, 'compression': 379, 'inr': 380, 'video': 381, 'deep': 382, 'perspective': 383, 'potential': 384, 'adaptability': 385, 'optimisation': 386, 'level': 387, 'adjustment': 388, 'restoration': 389, 'adaptation': 390, 'reflection': 391, 'macroscopic': 392, 'perturbation': 393, 'case': 394, 'inequality': 395, 'traction': 396, 'separation': 397, 'relationship': 398, 'interface': 399, 'component': 400, 'layer': 401, 'inversion': 402, 'output': 403, 'mean': 404, 'beam': 405, 'end': 406, 'portion': 407, 'boundary': 408, 'training': 409, 'zone': 410, 'consideration': 411, 'interaction': 412, 'health': 413, 'lead': 414, 'maintenance': 415, 'failure': 416, 'degradation': 417, 'situation': 418, 'life': 419, 'comparison': 420, 'diverse': 421, 'consider': 422, 'style': 423, 'addres': 424, 'modulation': 425, 'algorithm': 426, 'interpolation': 427, 'role': 428, 'carbon': 429, 'flexibility': 430, 'market': 431, 'feedback': 432, 'strategy': 433, 'operation': 434, 'reduction': 435, 'utilization': 436, 'target': 437, 'reference': 438, 'distillation': 439, 'teacher': 440, 'student': 441, 'encoder': 442, 'task': 443, 'remote': 444, 'area': 445, 'variation': 446, 'interference': 447, 'novel': 448, 'dependency': 449, 'excitation': 450, 'integrity': 451, 'fermi': 452, 'difference': 453, 'plant': 454, 'disease': 455, 'security': 456, 'shot': 457, 'dml': 458, 'pre': 459, 'dependence': 460, 'convergence': 461, 'source': 462, 'domain': 463, 'zero': 464, 'clas': 465, 'event': 466, 'code': 467, 'examine': 468, 'fraction': 469, 'temperature': 470, 'similarity': 471, 'wheel': 472, 'motor': 473, 'company': 474, 'min': 475, 'concept': 476, 'spacetime': 477, 'view': 478, 'coordinate': 479, 'nature': 480, 'idea': 481, 'sheaf': 482, 'tool': 483, 'precision': 484, 'air': 485, 'monitoring': 486, 'particle': 487, 'standard': 488, 'index': 489, 'detect': 490, 'factor': 491, 'cost': 492, 'correction': 493, 'choice': 494, 'interpretability': 495, 'procedure': 496, 'selection': 497, 'consistency': 498, 'bia': 499, 'post': 500, 'equilibrium': 501, 'phenomenon': 502, 'random': 503, 'demonstrate': 504, 'synchronization': 505, 'limit': 506, 'stability': 507, 'user': 508, 'practice': 509, 'cycle': 510, 'communication': 511, 'burden': 512, 'datum': 513, 'constraint': 514, 'sum': 515, 'convex': 516, 'iteration': 517, 'expectation': 518, 'reliance': 519, 'penalty': 520, 'eeg': 521, 'brain': 522, 'decomposition': 523, 'emergence': 524, 'transfer': 525, 'cp': 526, 'industry': 527, 'transportation': 528, 'sector': 529, 'impact': 530, 'safety': 531, 'technology': 532, 'infrastructure': 533, 'date': 534, 'segmentation': 535, 'inter': 536, 'contrast': 537, 'difficulty': 538, 'randomization': 539, 'diamond': 540, 'integer': 541, 'determine': 542, 'eigenvalue': 543, 'realization': 544, 'balance': 545, 'rehabilitation': 546, 'participation': 547, 'independence': 548, 'load': 549, 'feasibility': 550, 'force': 551, 'preparation': 552, 'bifurcation': 553, 'shilnikov': 554, 'section': 555, 'lyapunov': 556, 'dimensional': 557, 'scene': 558, 'pixel': 559, 'patch': 560, 'wise': 561, 'reconstruction': 562, 'vehicle': 563, 'th': 564, 'synthesi': 565, 'capability': 566, 'controller': 567, 'comfort': 568, 'compute': 569, 'percentage': 570, 'trade': 571, 'smoothnes': 572, 'diversity': 573, 'wind': 574, 'science': 575, 'discovery': 576, 'emphasi': 577, 'resistance': 578, 'future': 579, 'decoder': 580, 'noise': 581, 'permutation': 582, 'rotation': 583, 'inclusion': 584, 'topology': 585, 'telescope': 586, 'perform': 587, 'collaboration': 588, 'compare': 589, 'gp': 590, 'dsi': 591, 'basi': 592, 'identify': 593, 'progress': 594, 'management': 595, 'building': 596, 'experience': 597, 'overview': 598, 'decision': 599, 'reinforcement': 600, 'planning': 601, 'context': 602, 'self': 603, 'innovation': 604, 'fokker': 605, 'planck': 606, 'motion': 607, 'filter': 608, 'tune': 609, 'margin': 610, 'integrator': 611, 'cu': 612, 'transient': 613, 'ground': 614, 'principle': 615, 'symmetry': 616, 'treat': 617, 'collapse': 618, 'search': 619, 'circuit': 620, 'exploration': 621, 'gait': 622, 'disorder': 623, 'aperture': 624, 'array': 625, 'antenna': 626, 'law': 627, 'generate': 628, 'trajectory': 629, 'pattern': 630, 'joint': 631, 'validity': 632, 'flux': 633, 'spectrum': 634, 'configuration': 635, 'investigate': 636, 'absence': 637, 'correspondence': 638, 'edge': 639, 'product': 640, 'incorporate': 641, 'divergence': 642, 'quasi': 643, 'bn': 644, 'virgo': 645, 'gw': 646, 'uncertainty': 647, 'validate': 648, 'foundation': 649, 'slip': 650, 'subduction': 651, 'activity': 652, 'acceleration': 653, 'monte': 654, 'carlo': 655, 'efficacy': 656, 'sensitivity': 657, 'superiority': 658, 'modeling': 659, 'version': 660, 'k': 661, 'dft': 662, 'matrix': 663, 'rdmft': 664, 'inference': 665, 'policy': 666, 'healthcare': 667, 'lstm': 668, 'resource': 669, 'nf': 670, 'baseline': 671, 'fact': 672, 'diffusion': 673, 'succes': 674, 'thesi': 675, 'conservation': 676, 'bu': 677, 'bandwidth': 678, 'trial': 679, 'fock': 680, 'trend': 681, 'moreover': 682, 'scalability': 683, 'material': 684, 'game': 685, 'versatility': 686, 'notion': 687, 'agent': 688, 'imputation': 689, 'characterization': 690, 'foreground': 691, 'color': 692, 'object': 693, 'significance': 694, 'vibration': 695, 'sensor': 696, 'medium': 697, 'hand': 698, 'label': 699, 'ml': 700, 'initialization': 701, 'extension': 702, 'boost': 703, 'calculate': 704, 'pair': 705, 'volume': 706, 'content': 707, 'hypothesi': 708, 'sub': 709, 'db': 710, 'sparsity': 711, 'e': 712, 'regularization': 713, 'transport': 714, 'explicit': 715, 'te': 716, 'leverage': 717, 'clip': 718, 'hence': 719, 'client': 720, 'statu': 721, 'privacy': 722, 'availability': 723, 'respect': 724, 'rule': 725, 'laser': 726, 'floquet': 727, 'grid': 728, 'box': 729, 'track': 730, 'custom': 731, 'intersection': 732, 'neighbor': 733, 'complex': 734, 'form': 735, 'regulation': 736, 'light': 737, 'assessment': 738, 'investigation': 739, 'software': 740, 'illustrate': 741, 'execution': 742, 'acces': 743, 'help': 744, 'attractor': 745, 'guarantee': 746, 'account': 747, 'fracture': 748, 'absorption': 749, 'construct': 750, 'band': 751, 'driver': 752, 'resonance': 753, 'defense': 754, 'secure': 755, 'dmft': 756, 'instability': 757, 'car': 758, 'loop': 759, 'share': 760, 'vaccine': 761, 'arm': 762, 'hpv': 763, 'protocol': 764, 'transformer': 765, 'p': 766, 'rnn': 767, 'theorem': 768, 'description': 769, 'bond': 770, 'probability': 771, 'position': 772, 'spde': 773, 'dm': 774, 'wimp': 775, 'pfimp': 776, 'fermion': 777, 'boson': 778, 'singlet': 779, 'inflation': 780, 'palatini': 781, 'peak': 782, 'deformation': 783, 'risk': 784, 'damage': 785, 'resilience': 786, 'attack': 787, 'landscape': 788, 'cyber': 789, 'conformation': 790, 'translation': 791, 'geom': 792, 'polarization': 793, 'plane': 794, 'prompt': 795, 'downstream': 796, 'manner': 797, 'vlm': 798, 'base': 799, 'su': 800, 'schrieffer': 801, 'half': 802, 'heisenberg': 803, 'glas': 804, 'stres': 805, 'definition': 806, 'path': 807, 'vqa': 808, 'reason': 809, 'reasoning': 810, 'drug': 811, 'learn': 812, 'deal': 813, 'transformation': 814, 'ri': 815, 'uav': 816, 'improve': 817, 'magnitude': 818, 'ring': 819, 'gate': 820, 'volt': 821, 'voltage': 822, 'variability': 823, 'cause': 824, 'flow': 825, 'actor': 826, 'chain': 827, 'coordination': 828, 'mobility': 829, 'challenge': 830, 'catalog': 831, 'latent': 832, 'stain': 833, 'diagnosi': 834, 'block': 835, 'insulator': 836, 'ion': 837, 'represent': 838, 'robust': 839, 'length': 840, 'flip': 841, 'dipole': 842, 'relaxation': 843, 'rise': 844, 'employ': 845, 'shape': 846, 'hamilton': 847, 'jacobi': 848, 'connection': 849, 'advance': 850, 'coupling': 851, 'scd': 852, 'protection': 853, 'electricity': 854, 'incentive': 855, 'benefit': 856, 'coherence': 857, 'efficient': 858, 'rank': 859, 'l': 860, 'prove': 861, 'pv': 862, 'groundhog': 863, 'multiple': 864, 'inverse': 865, 'supply': 866, 'desalination': 867, 'hst': 868, 'transform': 869, 'fault': 870, 'pilot': 871, 'minimum': 872, 'traffic': 873, 'incidence': 874, 'provide': 875, 'uca': 876, 'codebook': 877, 'rdm': 878, 'cd': 879, 'pathway': 880, 'latter': 881, 'amount': 882, 'discus': 883, 'awarenes': 884, 'sac': 885, 'perception': 886, 'web': 887, 'category': 888, 'lensing': 889, 'answer': 890, 'exponent': 891, 'volatility': 892, 'profile': 893, 'shear': 894, 'create': 895, 'spread': 896, 'instrument': 897, 'detector': 898, 'elevation': 899, 'lepton': 900, 'probe': 901, 'pim': 902, 'evidence': 903, 'generator': 904, 'picture': 905, 'action': 906, 'hyperchao': 907, 'chao': 908, 'drive': 909, 'buyer': 910, 'budget': 911, 'expression': 912, 'j': 913, 'ia': 914, 'supernova': 915, 'sne': 916, 'explosion': 917, 'dark': 918, 'dense': 919, 'identity': 920, 'f': 921, 'surrogate': 922, 'rl': 923, 'condensate': 924, 'exciton': 925, 'pod': 926, 'sketch': 927, 'person': 928, 'origin': 929, 'codec': 930, 'wd': 931, 'predictor': 932, 'character': 933, 'score': 934, 'fidelity': 935, 'promise': 936, 'shift': 937, 'ius': 938, 'continuity': 939, 'digit': 940, 'cbc': 941, 'sotum': 942, 'classifier': 943, 'imbalance': 944, 'iv': 945, 'discretization': 946, 'cut': 947, 'dr': 948, 'reverse': 949, 'fine': 950, 'layout': 951, 'morphology': 952, 'cover': 953, 'surveillance': 954, 'alpha': 955, 'covariance': 956, 'variance': 957, 'aggregation': 958, 'family': 959, 'dg': 960, 'causal': 961, 'minimization': 962, 'audio': 963, 'subsystem': 964, 'monitor': 965, 'ladder': 966, 'semi': 967, 'utility': 968, 'wireles': 969, 'wavefront': 970, 'mimo': 971, 'coalescence': 972, 'strain': 973, 'der': 974, 'convexity': 975, 'delay': 976, 'cc': 977, 'pcm': 978, 'speech': 979, 'cent': 980, 'td': 981, 'ac': 982, 'opportunity': 983, 'schrdinger': 984, 'pressure': 985, 'hermiticity': 986, 'therefore': 987, 'cloud': 988, 'cim': 989, 'logic': 990, 'machinery': 991, 'van': 992, 'vertex': 993, 'cardinality': 994, 'confidence': 995, 'refrigeration': 996, 'odometry': 997, 'disentanglement': 998, 'tremor': 999, 'lane': 1000, 'seepage': 1001, 'rock': 1002, 'superconductivity': 1003, 'bh': 1004, 'age': 1005, 'guidance': 1006, 'homogenization': 1007, 'thinking': 1008, 'photon': 1009, 'outcome': 1010, 'nucleosynthesi': 1011, 'electrode': 1012, 'piecewise': 1013, 'pdm': 1014, 'radio': 1015, 'da': 1016, 'rec': 1017, 'hbf': 1018, 'division': 1019, 'subdivision': 1020, 'samc': 1021, 'vbcm': 1022, 'erasure': 1023, 'exominer': 1024}\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import re\n",
        "from textblob import Word\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from string import punctuation\n",
        "\n",
        "# Ensure necessary NLTK resources are downloaded\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "lm = WordNetLemmatizer()\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "remove_limit = 5\n",
        "\n",
        "\n",
        "def clean_str(string):\n",
        "    \"\"\"\n",
        "    Clean and normalize a given string by removing unwanted characters,\n",
        "    normalizing contractions, removing stopwords, abbreviations, and applying lemmatization and singularization.\n",
        "    \"\"\"\n",
        "    if not isinstance(string, str):\n",
        "        return \"\"\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    stop_words = set(stopwords.words('english'))\n",
        "    custom_stop_words = {\"paper\", \"research\", \"study\", \"approach\", \"propose\"}  # Custom words to remove\n",
        "    abbreviations = {\"e.g.\": \"for example\", \"i.e.\": \"that is\", \"etc.\": \"and so on\", \"vs.\": \"versus\", \"approx.\": \"approximately\"}  # Abbreviations to remove\n",
        "\n",
        "    # Replace abbreviations\n",
        "    for abbr, replacement in abbreviations.items():\n",
        "        string = string.replace(abbr, replacement)\n",
        "    # Remove URLs\n",
        "    string = re.sub(r'http\\S+|www\\S+', '', string)\n",
        "    # Remove digits\n",
        "    string = re.sub(r'[0-9]+', '', string)\n",
        "    # Remove hyphens and replace with space\n",
        "    string = re.sub(r'-', ' ', string)\n",
        "    # Remove punctuation\n",
        "    string = re.sub(r'[^A-Za-z\\s]', '', string)\n",
        "    # Normalize contractions\n",
        "    string = re.sub(r\"\\'s\", \" is\", string)\n",
        "    string = re.sub(r\"\\'ve\", \" have\", string)\n",
        "    string = re.sub(r\"n\\'t\", \" not\", string)\n",
        "    string = re.sub(r\"\\'re\", \" are\", string)\n",
        "    string = re.sub(r\"\\'d\", \" would\", string)\n",
        "    string = re.sub(r\"\\'ll\", \" will\", string)\n",
        "    # Remove extra spaces\n",
        "    string = re.sub(r'\\s{2,}', ' ', string)\n",
        "    # Tokenize text\n",
        "    words = nltk.word_tokenize(string)\n",
        "    # Remove stopwords and punctuation\n",
        "    words = [word.lower() for word in words if word.lower() not in stop_words and word.lower() not in custom_stop_words and word.lower() not in punctuation]\n",
        "    # Part-of-Speech tagging and filtering nouns\n",
        "    tagged_list = nltk.pos_tag(words)\n",
        "    nouns_list = [t[0] for t in tagged_list if t[-1] == 'NN']\n",
        "    # Singularize and lemmatize words\n",
        "    words = [Word(word).singularize() for word in nouns_list]\n",
        "    words = [lemmatizer.lemmatize(word, pos='n') for word in words]\n",
        "\n",
        "    return \" \".join(words).strip().lower()\n",
        "\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 5. Build word frequency over all abstracts\n",
        "# ------------------------------------------------------------------------------\n",
        "original_word_freq = {}\n",
        "sentences = list(all_abstracts.values())\n",
        "# Create a list of all input sentences\n",
        "random.seed(42)\n",
        "random.shuffle(sentences)\n",
        "train_input = int(0.8 * len(sentences))\n",
        "train_size = sentences[:train_input]\n",
        "test_size = sentences[train_input:]\n",
        "\n",
        "print(len(train_size))\n",
        "print(len(test_size))\n",
        "\n",
        "for s in sentences:\n",
        "    cleaned = clean_str(s)\n",
        "    for w in cleaned.split():\n",
        "        original_word_freq[w] = original_word_freq.get(w, 0) + 1\n",
        "# ------------------------------------------------------------------------------\n",
        "# 6. Tokenize, filter stopwords & rare words, and build vocabulary\n",
        "# ------------------------------------------------------------------------------\n",
        "tokenize_sentences = []\n",
        "word_list_dict = {}\n",
        "\n",
        "for s in sentences:\n",
        "    cleaned    = clean_str(s)\n",
        "    words      = cleaned.split()\n",
        "    filtered   = []\n",
        "    for w in words:\n",
        "        if (w not in stop_words) and (original_word_freq.get(w, 0) >= remove_limit):\n",
        "            filtered.append(w)\n",
        "            word_list_dict[w] = word_list_dict.get(w, 0)  # just to collect unique words\n",
        "    tokenize_sentences.append(filtered)\n",
        "\n",
        "word_list   = list(word_list_dict.keys())\n",
        "vocab_length  = len(word_list)\n",
        "print(\"Vocabulary size:\", vocab_length)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 7. Map words to IDs and convert sentences to sequences\n",
        "# ------------------------------------------------------------------------------\n",
        "word_id_map = {w: i+1 for i, w in enumerate(word_list)}\n",
        "print(word_id_map)\n",
        "# reserve index 0 for padding\n",
        "\n",
        "# # sequences = [\n",
        "# #     [word_id_map[w] for w in doc]\n",
        "# #     for doc in tokenize_sentences\n",
        "# # ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "BFSLI3t43xZo"
      },
      "outputs": [],
      "source": [
        "# from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# def filter_and_tokenize_titles(titles, stop_words, word_freq, freq_threshold):\n",
        "#     cleaned_titles = []\n",
        "#     for raw in titles:\n",
        "#         # 1) Clean the string and split into tokens\n",
        "#         tokens = clean_str(raw).split()\n",
        "#         # 2) Filter out stopwords and low‐frequency tokens\n",
        "#         filtered = [\n",
        "#             tok for tok in tokens\n",
        "#             if tok not in stop_words and word_freq.get(tok, 0) >= freq_threshold\n",
        "#         ]\n",
        "#         cleaned_titles.append(filtered)\n",
        "#     return cleaned_titles\n",
        "\n",
        "# #Usage example:\n",
        "# #Assuming all_titles_lists, stop_words, original_word_freq, remove_limit are defined\n",
        "# clean_title = filter_and_tokenize_titles(\n",
        "#     all_titles_lists,\n",
        "#     stop_words=stop_words,\n",
        "#     word_freq=original_word_freq,\n",
        "#     freq_threshold=remove_limit\n",
        "# )\n",
        "\n",
        "# print(clean_title[:10])\n",
        "# # # # Display the cleaned abstracts\n",
        "# # # paper = list(all_abstracts.values())\n",
        "# # # print(paper)\n",
        "# # # clean_abstract = filter_and_tokenize_titles( # Fixed typo: filter_and_tokenize_titles\n",
        "# # #     paper,\n",
        "# # #     stop_words=stop_words,\n",
        "# # #     word_freq=original_word_freq,\n",
        "# # #     freq_threshold=remove_limit\n",
        "# # # )\n",
        "\n",
        "# # print(clean_title[:10])\n",
        "# # #print(clean_abstract[:2])\n",
        "\n",
        "\n",
        "# # # 2) Fit the MultiLabelBinarizer\n",
        "# # mlb = MultiLabelBinarizer()\n",
        "# # binary_matrix = mlb.fit_transform(four_per_title)\n",
        "\n",
        "# # # 3) Create a DataFrame for readability\n",
        "# # df_labels = pd.DataFrame(binary_matrix, columns=mlb.classes_)\n",
        "\n",
        "# # print(\"Classes (columns):\", mlb.classes_)\n",
        "# # print(\"\\nMultilabel indicator matrix:\")\n",
        "# # print(df_labels)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qOazYLsl3xZp"
      },
      "outputs": [],
      "source": [
        "# # 1) Your existing filter function\n",
        "# def filter_and_tokenize_titles(titles, stop_words, word_freq, freq_threshold):\n",
        "#     cleaned_titles = []\n",
        "#     for raw in titles:\n",
        "#         tokens = clean_str(raw).split()\n",
        "#         filtered = [\n",
        "#             tok for tok in tokens\n",
        "#             if tok not in stop_words and word_freq.get(tok, 0) >= freq_threshold\n",
        "#         ]\n",
        "#         cleaned_titles.append(filtered)\n",
        "#     return cleaned_titles\n",
        "\n",
        "# # 2) Truncation/padding helper\n",
        "# def pick_k_tokens(token_lists, k=4, pad_token=\"\"):\n",
        "#     \"\"\"\n",
        "#     From each list in token_lists, take the first k tokens.\n",
        "#     If a list has fewer than k tokens, pad with pad_token.\n",
        "#     \"\"\"\n",
        "#     out = []\n",
        "#     for toks in token_lists:\n",
        "#         # take first k\n",
        "#         picked = toks[:k]\n",
        "#         # if shorter, pad\n",
        "#         if len(picked) < k:\n",
        "#             picked += [pad_token] * (k - len(picked))\n",
        "#         out.append(picked)\n",
        "#     return out\n",
        "\n",
        "# # 3) Run them in sequence\n",
        "# clean_title = filter_and_tokenize_titles(\n",
        "#     all_titles_lists,\n",
        "#     stop_words=stop_words,\n",
        "#     word_freq=original_word_freq,\n",
        "#     freq_threshold=remove_limit\n",
        "# )\n",
        "\n",
        "# # now pick exactly 4 tokens per title\n",
        "# four_per_title = pick_k_tokens(clean_title, k=4, pad_token=\"\")\n",
        "\n",
        "# print(four_per_title)\n",
        "\n",
        "\n",
        "# # 2) Fit the MultiLabelBinarizer\n",
        "# mlb = MultiLabelBinarizer()\n",
        "# doc_labels = mlb.fit_transform(four_per_title)\n",
        "\n",
        "# labels = doc_labels.flatten().tolist()\n",
        "# labels = torch.LongTensor(labels).to(device)\n",
        "\n",
        "# print(labels)\n",
        "\n",
        "# # 3) Create a DataFrame for readability\n",
        "# # labels = pd.DataFrame(binary_matrix, columns=mlb.classes_)\n",
        "\n",
        "# # # print(\"Classes (columns):\", mlb.classes_)\n",
        "# # # print(\"\\nMultilabel indicator matrix:\")\n",
        "# # print(labels)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "K6qDEpow-Acl"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Top-20 terms: ['field', 'detection', 'model', 'analysi', 'quantum', 'control', 'theory', 'learning', 'image', 'phase']\n",
            "doc_labels: 647\n",
            "[[0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]]\n",
            "Labels: [[0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 1, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 1, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [0, 0, 0, 0, 0, 0, 1, 0, 0, 0], [1, 0, 1, 0, 1, 0, 1, 0, 0, 0], [0, 0, 1, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 1, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]]\n",
            "Train size: 517 Test size: 130\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# … assume you already ran:\n",
        "#   tokenize_sentences: List[List[str]]\n",
        "#   all_titles_lists:   List[str]  (raw titles)\n",
        "#   clean_str(), etc.\n",
        "\n",
        "# 1) Extract top-K TF–IDF terms from titles\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "K = 10\n",
        "vec    = TfidfVectorizer(stop_words=\"english\")\n",
        "tfidf  = vec.fit_transform([ clean_str(t) for t in all_titles_lists ])\n",
        "terms  = np.array(vec.get_feature_names_out())\n",
        "scores = np.asarray(tfidf.sum(axis=0)).ravel()\n",
        "top_terms = terms[scores.argsort()[-K:][::-1]].tolist()\n",
        "print(\"Top-20 terms:\", top_terms)\n",
        "\n",
        "\n",
        "doc_labels = []\n",
        "\n",
        "for doc in sentences:\n",
        "    label = []\n",
        "    for term in top_terms:\n",
        "        if term in doc:\n",
        "            label.append(1)\n",
        "        else:\n",
        "            label.append(0)\n",
        "    doc_labels.append(label)\n",
        "\n",
        "\n",
        "print(\"doc_labels:\", len(doc_labels))\n",
        "print(doc_labels[:5])\n",
        "\n",
        "print(\"Labels:\", doc_labels[:10])\n",
        "\n",
        "# 3) Train/test split\n",
        "train_labels, test_labels = train_test_split(\n",
        "    doc_labels, test_size=0.2, random_state=42\n",
        ")\n",
        "print(\"Train size:\", len(train_labels), \"Test size:\", len(test_labels))\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Assuming original_labels_train is a list of lists, where each inner list contains the labels for a single sample\n",
        "mlb = MultiLabelBinarizer()\n",
        "train_labels = mlb.fit_transform(train_labels)\n",
        "test_labels = mlb.transform(test_labels)\n",
        "\n",
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming you want to flatten the labels into a single list\n",
        "labels = train_labels.flatten().tolist() + test_labels.flatten().tolist()  #CS_test=1172  #SS_test =1023\n",
        "labels = torch.LongTensor(labels).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-0vPMjTA3xZp"
      },
      "outputs": [],
      "source": [
        "# # Convert titles to a list of lists\n",
        "\n",
        "\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# import pandas as pd\n",
        "\n",
        "# def top_k_tfidf_per_paper(all_title_lists, k=5):\n",
        "#     flat = [t for titles in all_title_lists for t in titles]\n",
        "#     vec  = TfidfVectorizer(stop_words=\"english\")\n",
        "#     M    = vec.fit_transform(flat).toarray()\n",
        "#     names = vec.get_feature_names_out()\n",
        "\n",
        "#     rows = []\n",
        "#     pos  = 0\n",
        "#     for idx, titles in enumerate(all_title_lists):\n",
        "#         n    = len(titles)\n",
        "#         mat  = M[pos:pos+n]\n",
        "#         avg  = mat.mean(axis=0)\n",
        "#         topi = avg.argsort()[-k:][::-1]\n",
        "#         raw_kws = [names[i] for i in topi]\n",
        "#         # clean each keyword\n",
        "#         clean_kws = [clean_str(kw) for kw in raw_kws]\n",
        "#         rows.append({\"paper_index\":idx, \"keywords_list\":clean_kws})\n",
        "#         pos += n\n",
        "\n",
        "#     return pd.DataFrame(rows)\n",
        "\n",
        "# top_k_keywords = top_k_tfidf_per_paper(all_titles_lists, k=5)\n",
        "# # Now len(top_k_keywords) == 5\n",
        "# print(top_k_keywords)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq8xFTd53xZp"
      },
      "source": [
        "## Label"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "7G4b0vXK3xZp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "node_size: 1671\n"
          ]
        }
      ],
      "source": [
        "# Helper: if x is a list (or any sequence), use its length; otherwise assume it’s already an int\n",
        "def to_int(x):\n",
        "    try:\n",
        "        return len(x)\n",
        "    except TypeError:\n",
        "        return x\n",
        "\n",
        "train_n = to_int(train_size)\n",
        "test_n  = to_int(test_size)\n",
        "\n",
        "node_size = train_n + vocab_length + test_n\n",
        "print(\"node_size:\", node_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "r8aRtXZF3xZp"
      },
      "outputs": [],
      "source": [
        "row, col, weight = [], [], []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ilDqr7253xZp"
      },
      "source": [
        "## PMI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "sFwvkVcD3xZp"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d68806567b30423595b47c9d186dbfa9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Processing documents:   0%|          | 0/647 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Built graph edges: 122796 entries\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------------------------------------------------------\n",
        "if 'train_size' not in globals():\n",
        "    raise NameError(\"You must define `train_size` (int or list) before this block.\")\n",
        "\n",
        "if isinstance(train_size, list):\n",
        "    train_size_int = len(train_size)\n",
        "elif isinstance(train_size, int):\n",
        "    train_size_int = train_size\n",
        "else:\n",
        "    raise TypeError(f\"`train_size` must be int or list, got {type(train_size)}\")\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 1) Sliding‐window co‐occurrence setup\n",
        "# ------------------------------------------------------------------------------\n",
        "window_size = graph_window_sizes   # must be an int\n",
        "total_W      = 0\n",
        "word_occurrence      = {}\n",
        "word_pair_occurrence = {}\n",
        "\n",
        "\n",
        "def ordered_word_pair(a, b):\n",
        "    return (b, a) if a > b else (a, b)\n",
        "\n",
        "def update_word_and_word_pair_occurrence(ids):\n",
        "    unique_ids = set(ids)\n",
        "    for wid in unique_ids:\n",
        "        word_occurrence[wid] = word_occurrence.get(wid, 0) + 1\n",
        "    uid_list = list(unique_ids)\n",
        "    for i in range(len(uid_list)):\n",
        "        for j in range(i+1, len(uid_list)):\n",
        "            w1, w2 = ordered_word_pair(uid_list[i], uid_list[j])\n",
        "            pair = (w1, w2)\n",
        "            word_pair_occurrence[pair] = word_pair_occurrence.get(pair, 0) + 1\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 2) Build co‐occurrences via sliding window\n",
        "# ------------------------------------------------------------------------------\n",
        "for doc_ids in tqdm(tokenize_sentences, desc=\"Processing documents\"):\n",
        "    ids = [word_id_map[w] for w in doc_ids]\n",
        "    window = ids[:window_size]\n",
        "    total_W += 1\n",
        "    update_word_and_word_pair_occurrence(window)\n",
        "\n",
        "    for idx in range(window_size, len(ids)):\n",
        "        window.pop(0)\n",
        "        window.append(ids[idx])\n",
        "        total_W += 1\n",
        "        update_word_and_word_pair_occurrence(window)\n",
        "\n",
        "# ------------------------------------------------------------------------------\n",
        "# 3) Compute positive PMI and populate edge lists\n",
        "# ------------------------------------------------------------------------------\n",
        "for (i, j), count in word_pair_occurrence.items():\n",
        "    freq_i = word_occurrence[i]\n",
        "    freq_j = word_occurrence[j]\n",
        "    pmi = math.log((count * total_W) / (freq_i * freq_j))\n",
        "    if pmi > 0:\n",
        "        # offset by train_size_int, add both directions\n",
        "        row.append(train_size_int + i)\n",
        "        col.append(train_size_int + j)\n",
        "        weight.append(pmi)\n",
        "        row.append(train_size_int + j)\n",
        "        col.append(train_size_int + i)\n",
        "        weight.append(pmi)\n",
        "\n",
        "print(f\"Built graph edges: {len(weight)} entries\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JOup1oYU3xZp"
      },
      "source": [
        "## TF_IDF"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hN7uHKDj3xZp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF edges added: 136177 entries\n"
          ]
        }
      ],
      "source": [
        "# 1. Build inverted index: word -> list of document indices\n",
        "word_doc_list = {word: [] for word in word_list}\n",
        "for doc_idx, tokens in enumerate(tokenize_sentences):\n",
        "    for word in set(tokens):\n",
        "        word_doc_list[word].append(doc_idx)\n",
        "\n",
        "# 2. Document Frequency (DF)\n",
        "word_doc_freq = {word: len(docs) for word, docs in word_doc_list.items()}\n",
        "\n",
        "# 3. Term Frequency (TF): mapping (doc_idx, word_id) -> frequency\n",
        "doc_word_freq = {}\n",
        "for doc_idx, tokens in enumerate(tokenize_sentences):\n",
        "    for word in tokens:\n",
        "        wid = word_id_map[word]\n",
        "        key = (doc_idx, wid)\n",
        "        doc_word_freq[key] = doc_word_freq.get(key, 0) + 1\n",
        "\n",
        "# 4. Populate adjacency lists with TF-IDF weights\n",
        "for doc_idx, tokens in enumerate(tokenize_sentences):\n",
        "    seen = set()\n",
        "    for word in tokens:\n",
        "        if word in seen:\n",
        "            continue\n",
        "        wid = word_id_map[word]\n",
        "        tf = doc_word_freq[(doc_idx, wid)]\n",
        "        df = word_doc_freq[word]\n",
        "        idf = math.log(len(tokenize_sentences) / df)\n",
        "        weight_val = tf * idf\n",
        "\n",
        "        # determine row index using train_size_int\n",
        "        row_idx = doc_idx if doc_idx < train_size_int else doc_idx + vocab_length\n",
        "        col_idx = train_size_int + wid\n",
        "\n",
        "        row.append(row_idx)\n",
        "        col.append(col_idx)\n",
        "        weight.append(weight_val)\n",
        "\n",
        "        seen.add(word)\n",
        "\n",
        "print(f\"TF-IDF edges added: {len(weight)} entries\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vyn-UirD3xZp"
      },
      "source": [
        "## Citation Calculation (C_pp Method)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "jrrFJrbi3xZp"
      },
      "outputs": [],
      "source": [
        "\n",
        "# 0) Convert train_size/test_size to ints (as before)\n",
        "train_n = len(train_size) if isinstance(train_size, list) else train_size\n",
        "test_n  = len(test_size)  if isinstance(test_size, list)  else test_size\n",
        "node_size = train_n + vocab_length + test_n\n",
        "\n",
        "# 1) Clean your edges into simple ID pairs\n",
        "clean_edges = []\n",
        "for src, tgt in all_edges:\n",
        "    cited_by = src.split(\":\",1)[0].strip()\n",
        "    main     = tgt.split(\":\",1)[0].strip()\n",
        "    clean_edges.append((cited_by, main))\n",
        "\n",
        "# 2) Build counts and out‐degrees\n",
        "C, out_deg = {}, {}\n",
        "for cited_by, main in clean_edges:\n",
        "    C[(main, cited_by)] = C.get((main, cited_by), 0) + 1\n",
        "    out_deg[cited_by]   = out_deg.get(cited_by, 0) + 1\n",
        "\n",
        "# 3) Build the node_index over ALL document nodes (Main and Cite)\n",
        "all_doc_ids = sorted({nid for pair in clean_edges for nid in pair})\n",
        "node_index  = {nid: idx for idx, nid in enumerate(all_doc_ids)}\n",
        "\n",
        "# 4) Now build your row/col/weight lists using integer indices\n",
        "#rows, cols, weight = [], [], []\n",
        "for (main, cited_by), cnt in C.items():\n",
        "    i = node_index[cited_by]         # integer for source\n",
        "    j = node_index[main]             # integer for target\n",
        "    w = cnt / out_deg[cited_by]      # normalized weight\n",
        "    row.append(i)\n",
        "    col.append(j)\n",
        "    weight.append(w)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f446MpiV3xZp"
      },
      "source": [
        "## Build Adjacency Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "oLC9-GWI3xZp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "node_size: 1671\n",
            "adjacency shape: (1671, 1671)\n",
            "  (0, 518)\t3.4278238567774775\n",
            "  (0, 519)\t10.747468011665582\n",
            "  (0, 520)\t3.1765094284965714\n",
            "  (0, 521)\t3.5279073153344602\n",
            "  (0, 522)\t4.8629083820668\n",
            "  (0, 523)\t3.833288964885642\n",
            "  (0, 524)\t1.7809984122717568\n",
            "  (0, 525)\t2.1548581809645904\n",
            "  (0, 526)\t3.4766140209469096\n",
            "  (0, 527)\t2.4650131092684298\n",
            "  (0, 528)\t3.2942924641529547\n",
            "  (0, 548)\t1.0\n",
            "  (1, 518)\t6.855647713554955\n",
            "  (1, 529)\t9.420425352977091\n",
            "  (1, 530)\t4.07445102170253\n",
            "  (1, 531)\t10.17210386676202\n",
            "  (1, 532)\t3.2142497564794184\n",
            "  (1, 533)\t10.17210386676202\n",
            "  (1, 534)\t4.8629083820668\n",
            "  (1, 535)\t7.0558146306689205\n",
            "  (1, 536)\t4.6805868252728455\n",
            "  (1, 537)\t4.392904752821065\n",
            "  (1, 538)\t9.052872290891175\n",
            "  (1, 539)\t5.08605193338101\n",
            "  (1, 540)\t3.4766140209469096\n",
            "  :\t:\n",
            "  (1668, 1195)\t5.373734005832791\n",
            "  (1668, 1229)\t4.392904752821065\n",
            "  (1668, 1302)\t4.07445102170253\n",
            "  (1668, 1311)\t8.550243434329362\n",
            "  (1668, 1319)\t4.07445102170253\n",
            "  (1668, 1336)\t4.6805868252728455\n",
            "  (1668, 1359)\t5.08605193338101\n",
            "  (1668, 1410)\t4.8629083820668\n",
            "  (1668, 1419)\t5.7791991139409555\n",
            "  (1669, 762)\t4.07445102170253\n",
            "  (1669, 785)\t3.9874396447129\n",
            "  (1669, 792)\t2.711146178807338\n",
            "  (1669, 794)\t8.06446998174792\n",
            "  (1669, 821)\t3.5279073153344602\n",
            "  (1669, 1164)\t4.275121717164681\n",
            "  (1669, 1171)\t3.9874396447129\n",
            "  (1669, 1172)\t3.9073969370393637\n",
            "  (1669, 1288)\t3.833288964885642\n",
            "  (1669, 1420)\t4.07445102170253\n",
            "  (1669, 1512)\t15.25815580014303\n",
            "  (1670, 564)\t1.995009480022694\n",
            "  (1670, 582)\t2.580525996390274\n",
            "  (1670, 600)\t3.2942924641529547\n",
            "  (1670, 1178)\t3.5279073153344602\n",
            "  (1670, 1232)\t4.392904752821065\n"
          ]
        }
      ],
      "source": [
        "# 6) Build the full adjacency with the correct shape\n",
        "adj = sp.csr_matrix((weight, (row, col)), shape=(node_size, node_size))\n",
        "\n",
        "print(\"node_size:\", node_size)\n",
        "print(\"adjacency shape:\", adj.shape)\n",
        "print(adj)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "My04VsBq3xZp"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Public\\Documents\\ESTsoft\\CreatorTemp\\ipykernel_35888\\4011746467.py:25: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ..\\torch\\csrc\\utils\\tensor_new.cpp:620.)\n",
            "  return torch.sparse.FloatTensor(indices, values, shape).to(device)\n"
          ]
        }
      ],
      "source": [
        "def normalize_adj(adj):\n",
        "    \"\"\"Symmetrically normalize adjacency matrix.\"\"\"\n",
        "    adj = sp.coo_matrix(adj)\n",
        "    rowsum = np.array(adj.sum(1))\n",
        "    d_inv_sqrt = np.power(rowsum, -0.5).flatten()\n",
        "    d_inv_sqrt[np.isinf(d_inv_sqrt)] = 0.\n",
        "    d_mat_inv_sqrt = sp.diags(d_inv_sqrt)\n",
        "    # D^{-1/2} A D^{-1/2}\n",
        "    return (\n",
        "        adj.dot(d_mat_inv_sqrt)\n",
        "           .transpose()\n",
        "           .dot(d_mat_inv_sqrt)\n",
        "           .tocoo(),\n",
        "        d_inv_sqrt\n",
        "    )\n",
        "\n",
        "def sparse_mx_to_torch_sparse_tensor(sparse_mx):\n",
        "    \"\"\"Convert a scipy sparse matrix to a torch sparse tensor.\"\"\"\n",
        "    sparse_mx = sparse_mx.tocoo().astype(np.float32)\n",
        "    indices = torch.from_numpy(\n",
        "        np.vstack((sparse_mx.row, sparse_mx.col)).astype(np.int64)\n",
        "    )\n",
        "    values = torch.from_numpy(sparse_mx.data)\n",
        "    shape = torch.Size(sparse_mx.shape)\n",
        "    return torch.sparse.FloatTensor(indices, values, shape).to(device)\n",
        "\n",
        "# Assume `adj` is your scipy CSR of size (node_size, node_size)\n",
        "adj, norm_factors = normalize_adj(adj + sp.eye(adj.shape[0]))\n",
        "adj = sparse_mx_to_torch_sparse_tensor(adj)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "NB7U_IqK3xZq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Features shape: tensor([0.0000e+00, 1.0000e+00, 2.0000e+00,  ..., 1.6680e+03, 1.6690e+03,\n",
            "        1.6700e+03], device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "if NODE == 0:\n",
        "    features = np.arange(node_size)\n",
        "    features = torch.FloatTensor(features).to(device)\n",
        "else:\n",
        "\n",
        "    from flair.embeddings import TransformerDocumentEmbeddings, TransformerWordEmbeddings\n",
        "    from flair.data import Sentence\n",
        "    doc_embedding = TransformerDocumentEmbeddings('bert-base-uncased', fine_tune=False)\n",
        "    word_embedding = TransformerWordEmbeddings('bert-base-uncased', layers='-1',subtoken_pooling=\"mean\")\n",
        "\n",
        "    sent_embs = []\n",
        "    word_embs = {}\n",
        "\n",
        "    for ind in tqdm(range(train_size+test_size)):\n",
        "        sent = tokenize_sentences[ind]\n",
        "        sentence = Sentence(\" \".join(sent[:512]),use_tokenizer=False)\n",
        "        doc_embedding.embed(sentence)\n",
        "        sent_embs.append(sentence.get_embedding().tolist())\n",
        "        words = Sentence(\" \".join(sent[:512]),use_tokenizer=False)\n",
        "        word_embedding.embed(words)\n",
        "        for token in words:\n",
        "            word = token.text\n",
        "            embedding = token.embedding.tolist()\n",
        "            if word not in word_embs:\n",
        "                word_embs[word] = embedding\n",
        "            else:\n",
        "                word_embs[word] = np.minimum(word_embs[word], embedding)\n",
        "\n",
        "    word_embs_list = []\n",
        "    for word in word_list:\n",
        "        word_embs_list.append(word_embs[word])\n",
        "\n",
        "    features = sent_embs[:train_size] + word_embs_list + sent_embs[train_size:]\n",
        "\n",
        "\n",
        "    def preprocess_features(features):\n",
        "        \"\"\"Row-normalize feature matrix and convert to tuple representation\"\"\"\n",
        "        rowsum = np.array(features.sum(1))\n",
        "        r_inv = np.power(rowsum, -1).flatten()\n",
        "        r_inv[np.isinf(r_inv)] = 0.\n",
        "        r_mat_inv = sp.diags(r_inv)\n",
        "        features = r_mat_inv.dot(features)\n",
        "        return features\n",
        "\n",
        "    features = preprocess_features(sp.csr_matrix(features)).todense()\n",
        "    features = torch.FloatTensor(features).to(device)\n",
        "\n",
        "print(\"Features shape:\", features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "no8ElwbE3xZq"
      },
      "source": [
        "## GCN Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "i78vKMLf3xZq"
      },
      "outputs": [],
      "source": [
        "class GraphConvolution(Module):\n",
        "    \"\"\"\n",
        "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, in_features, out_features,  drop_out = 0, activation=None, bias=True):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.zeros(1, out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters(in_features, out_features)\n",
        "        self.dropout = torch.nn.Dropout(drop_out)\n",
        "        self.activation =  activation\n",
        "\n",
        "    def reset_parameters(self,in_features, out_features):\n",
        "        stdv = np.sqrt(6.0/(in_features+out_features))\n",
        "        # stdv = 1. / math.sqrt(self.weight.size(1))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        # if self.bias is not None:\n",
        "        #     torch.nn.init.zeros_(self.bias)\n",
        "            # self.bias.data.uniform_(-stdv, stdv)\n",
        "\n",
        "\n",
        "    def forward(self, input, adj, feature_less = False):\n",
        "        if feature_less:\n",
        "            support = self.weight\n",
        "            support = self.dropout(support)\n",
        "        else:\n",
        "            input = self.dropout(input)\n",
        "            support = torch.mm(input, self.weight)\n",
        "        output = torch.spmm(adj, support)\n",
        "        if self.bias is not None:\n",
        "            output = output + self.bias\n",
        "        if self.activation is not None:\n",
        "            output = self.activation(output)\n",
        "        return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v3m2_Av63xZq"
      },
      "source": [
        "## GCN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "wXFnEf1K3xZq"
      },
      "outputs": [],
      "source": [
        "class GCN(nn.Module):\n",
        "    def __init__(self, nfeat, nhid, nclass, dropout, n_layers = 2):\n",
        "        super(GCN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.gc_list = []\n",
        "        if n_layers >= 2:\n",
        "            self.gc1 = GraphConvolution(nfeat, nhid, dropout, activation = nn.ReLU())\n",
        "            self.gc_list = nn.ModuleList([GraphConvolution(nhid, nhid, dropout, activation = nn.ReLU()) for _ in range(self.n_layers-2)])\n",
        "            self.gcf = GraphConvolution(nhid, nclass, dropout)\n",
        "        else:\n",
        "            self.gc1 = GraphConvolution(nfeat, nclass, dropout)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        if self.n_layers>=2:\n",
        "            x = self.gc1(x, adj, feature_less = True)\n",
        "            for i in range(self.n_layers-2):\n",
        "                x = self.gc_list[i](x,adj)\n",
        "            x = self.gcf(x,adj)\n",
        "        else:\n",
        "            x = self.gc1(x, adj, feature_less = True)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dzzjPHdh3xZq"
      },
      "outputs": [],
      "source": [
        "def cal_accuracy(predictions,labels):\n",
        "    pred = torch.argmax(predictions,-1).cpu().tolist()\n",
        "    lab = labels.cpu().tolist()\n",
        "    cor = 0\n",
        "    for i in range(len(pred)):\n",
        "        if pred[i] == lab[i]:\n",
        "            cor += 1\n",
        "    return cor/len(pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "2SKz5zZ93xZq"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "\n",
        "# Define num_class with the correct value\n",
        "num_class = 10 # Assume you have 10 classes, replace with your actual number of classes.\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "model = GCN(nfeat=node_size, nhid=HIDDEN_DIM, nclass=num_class, dropout=DROP_OUT,n_layers=NUM_LAYERS).to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcUNnQW93xZq"
      },
      "source": [
        "## Training and validation Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "RwbTtq633xZq"
      },
      "outputs": [],
      "source": [
        "# def generate_train_val(train_pro=0.9):\n",
        "#     real_train_size = int(train_pro*train_size)\n",
        "#     val_size = train_size-real_train_size\n",
        "\n",
        "#     idx_train = np.random.choice(train_size, real_train_size,replace=False)\n",
        "#     idx_train.sort()\n",
        "#     idx_val = []\n",
        "#     pointer = 0\n",
        "#     for v in range(train_size):\n",
        "#         if pointer<len(idx_train) and idx_train[pointer] == v:\n",
        "#             pointer +=1\n",
        "#         else:\n",
        "#             idx_val.append(v)\n",
        "#     idx_test = range(train_size+vocab_length, node_size)\n",
        "#     return idx_train, idx_val, idx_test\n",
        "\n",
        "# idx_train, idx_val, idx_test = generate_train_val()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "LdATbtx53xZq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "465 52 130\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Helper to coerce to integer if it’s a list/sequence\n",
        "def to_int(x):\n",
        "    try:\n",
        "        return len(x)\n",
        "    except TypeError:\n",
        "        return int(x)\n",
        "\n",
        "def generate_train_val(train_pro=0.9):\n",
        "    # 1) Make sure train_n is an integer count\n",
        "    train_n = to_int(train_size)\n",
        "\n",
        "    # 2) Compute how many in train vs val\n",
        "    real_train_n = int(train_pro * train_n)\n",
        "    val_n        = train_n - real_train_n\n",
        "\n",
        "    # 3) Randomly pick train indices\n",
        "    idx_train = np.random.choice(train_n, real_train_n, replace=False)\n",
        "    idx_train.sort()\n",
        "\n",
        "    # 4) The rest go to validation\n",
        "    idx_val = [i for i in range(train_n) if i not in idx_train]\n",
        "\n",
        "    # 5) Test set indices start after (train + vocab) up to node_size\n",
        "    #    (coerce node_size to int as well)\n",
        "    total_nodes = to_int(node_size)\n",
        "    test_start  = train_n + vocab_length\n",
        "    idx_test    = list(range(test_start, total_nodes))\n",
        "\n",
        "    return idx_train.tolist(), idx_val, idx_test\n",
        "\n",
        "# Usage\n",
        "idx_train, idx_val, idx_test = generate_train_val()\n",
        "print(len(idx_train), len(idx_val), len(idx_test))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DkAvJf4Q3xZq"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "p1BMpleACOMc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch_geometric in c:\\users\\romeo\\anaconda3\\lib\\site-packages (2.6.1)\n",
            "Requirement already satisfied: aiohttp in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from torch_geometric) (3.9.5)\n",
            "Requirement already satisfied: fsspec in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from torch_geometric) (2024.3.1)\n",
            "Requirement already satisfied: jinja2 in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from torch_geometric) (3.1.4)\n",
            "Requirement already satisfied: numpy in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from torch_geometric) (1.26.4)\n",
            "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from torch_geometric) (5.9.0)\n",
            "Requirement already satisfied: pyparsing in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from torch_geometric) (3.0.9)\n",
            "Requirement already satisfied: requests in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from torch_geometric) (2.32.2)\n",
            "Requirement already satisfied: tqdm in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (1.2.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from aiohttp->torch_geometric) (1.9.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from jinja2->torch_geometric) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from requests->torch_geometric) (2024.8.30)\n",
            "Requirement already satisfied: colorama in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from tqdm->torch_geometric) (0.4.6)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "TeeJtVg83xZq"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 0001 loss_train: 2.3026 acc_train: 0.0516 loss_val: 2.2843 acc_val: 0.9231 time: 0.1319s\n",
            "Epoch: 0002 loss_train: 2.2851 acc_train: 0.9183 loss_val: 2.2658 acc_val: 0.9231 time: 0.0062s\n",
            "Epoch: 0003 loss_train: 2.2675 acc_train: 0.9183 loss_val: 2.2468 acc_val: 0.9231 time: 0.0055s\n",
            "Epoch: 0004 loss_train: 2.2496 acc_train: 0.9183 loss_val: 2.2271 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0005 loss_train: 2.2312 acc_train: 0.9183 loss_val: 2.2069 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0006 loss_train: 2.2125 acc_train: 0.9183 loss_val: 2.1862 acc_val: 0.9231 time: 0.0050s\n",
            "Epoch: 0007 loss_train: 2.1935 acc_train: 0.9183 loss_val: 2.1648 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0008 loss_train: 2.1740 acc_train: 0.9183 loss_val: 2.1430 acc_val: 0.9231 time: 0.0030s\n",
            "Epoch: 0009 loss_train: 2.1544 acc_train: 0.9183 loss_val: 2.1207 acc_val: 0.9231 time: 0.0050s\n",
            "Epoch: 0010 loss_train: 2.1337 acc_train: 0.9183 loss_val: 2.0979 acc_val: 0.9231 time: 0.0042s\n",
            "Epoch: 0011 loss_train: 2.1134 acc_train: 0.9183 loss_val: 2.0747 acc_val: 0.9231 time: 0.0050s\n",
            "Epoch: 0012 loss_train: 2.0923 acc_train: 0.9183 loss_val: 2.0513 acc_val: 0.9231 time: 0.0035s\n",
            "Epoch: 0013 loss_train: 2.0715 acc_train: 0.9183 loss_val: 2.0277 acc_val: 0.9231 time: 0.0056s\n",
            "Epoch: 0014 loss_train: 2.0500 acc_train: 0.9183 loss_val: 2.0039 acc_val: 0.9231 time: 0.0038s\n",
            "Epoch: 0015 loss_train: 2.0278 acc_train: 0.9183 loss_val: 1.9802 acc_val: 0.9231 time: 0.0043s\n",
            "Epoch: 0016 loss_train: 2.0055 acc_train: 0.9183 loss_val: 1.9566 acc_val: 0.9231 time: 0.0035s\n",
            "Epoch: 0017 loss_train: 1.9832 acc_train: 0.9183 loss_val: 1.9330 acc_val: 0.9231 time: 0.0060s\n",
            "Epoch: 0018 loss_train: 1.9603 acc_train: 0.9183 loss_val: 1.9094 acc_val: 0.9231 time: 0.0043s\n",
            "Epoch: 0019 loss_train: 1.9365 acc_train: 0.9183 loss_val: 1.8858 acc_val: 0.9231 time: 0.0050s\n",
            "Epoch: 0020 loss_train: 1.9133 acc_train: 0.9183 loss_val: 1.8622 acc_val: 0.9231 time: 0.0055s\n",
            "Epoch: 0021 loss_train: 1.8892 acc_train: 0.9183 loss_val: 1.8383 acc_val: 0.9231 time: 0.0055s\n",
            "Epoch: 0022 loss_train: 1.8646 acc_train: 0.9183 loss_val: 1.8143 acc_val: 0.9231 time: 0.0047s\n",
            "Epoch: 0023 loss_train: 1.8400 acc_train: 0.9183 loss_val: 1.7899 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0024 loss_train: 1.8145 acc_train: 0.9183 loss_val: 1.7653 acc_val: 0.9231 time: 0.0070s\n",
            "Epoch: 0025 loss_train: 1.7898 acc_train: 0.9183 loss_val: 1.7404 acc_val: 0.9231 time: 0.0050s\n",
            "Epoch: 0026 loss_train: 1.7620 acc_train: 0.9183 loss_val: 1.7152 acc_val: 0.9231 time: 0.0034s\n",
            "Epoch: 0027 loss_train: 1.7369 acc_train: 0.9183 loss_val: 1.6897 acc_val: 0.9231 time: 0.0060s\n",
            "Epoch: 0028 loss_train: 1.7105 acc_train: 0.9183 loss_val: 1.6639 acc_val: 0.9231 time: 0.0041s\n",
            "Epoch: 0029 loss_train: 1.6845 acc_train: 0.9183 loss_val: 1.6378 acc_val: 0.9231 time: 0.0030s\n",
            "Epoch: 0030 loss_train: 1.6563 acc_train: 0.9183 loss_val: 1.6115 acc_val: 0.9231 time: 0.0055s\n",
            "Epoch: 0031 loss_train: 1.6279 acc_train: 0.9183 loss_val: 1.5849 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0032 loss_train: 1.6015 acc_train: 0.9183 loss_val: 1.5581 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0033 loss_train: 1.5741 acc_train: 0.9183 loss_val: 1.5311 acc_val: 0.9231 time: 0.0041s\n",
            "Epoch: 0034 loss_train: 1.5447 acc_train: 0.9183 loss_val: 1.5040 acc_val: 0.9231 time: 0.0060s\n",
            "Epoch: 0035 loss_train: 1.5168 acc_train: 0.9183 loss_val: 1.4767 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0036 loss_train: 1.4881 acc_train: 0.9183 loss_val: 1.4493 acc_val: 0.9231 time: 0.0030s\n",
            "Epoch: 0037 loss_train: 1.4603 acc_train: 0.9183 loss_val: 1.4219 acc_val: 0.9231 time: 0.0035s\n",
            "Epoch: 0038 loss_train: 1.4318 acc_train: 0.9183 loss_val: 1.3944 acc_val: 0.9231 time: 0.0050s\n",
            "Epoch: 0039 loss_train: 1.4038 acc_train: 0.9183 loss_val: 1.3669 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0040 loss_train: 1.3742 acc_train: 0.9183 loss_val: 1.3395 acc_val: 0.9231 time: 0.0055s\n",
            "Epoch: 0041 loss_train: 1.3467 acc_train: 0.9183 loss_val: 1.3122 acc_val: 0.9231 time: 0.0055s\n",
            "Epoch: 0042 loss_train: 1.3193 acc_train: 0.9183 loss_val: 1.2850 acc_val: 0.9231 time: 0.0046s\n",
            "Epoch: 0043 loss_train: 1.2903 acc_train: 0.9183 loss_val: 1.2579 acc_val: 0.9231 time: 0.0034s\n",
            "Epoch: 0044 loss_train: 1.2629 acc_train: 0.9183 loss_val: 1.2311 acc_val: 0.9231 time: 0.0042s\n",
            "Epoch: 0045 loss_train: 1.2317 acc_train: 0.9183 loss_val: 1.2045 acc_val: 0.9231 time: 0.0055s\n",
            "Epoch: 0046 loss_train: 1.2064 acc_train: 0.9183 loss_val: 1.1782 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0047 loss_train: 1.1789 acc_train: 0.9183 loss_val: 1.1523 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0048 loss_train: 1.1518 acc_train: 0.9183 loss_val: 1.1266 acc_val: 0.9231 time: 0.0074s\n",
            "Epoch: 0049 loss_train: 1.1251 acc_train: 0.9183 loss_val: 1.1014 acc_val: 0.9231 time: 0.0060s\n",
            "Epoch: 0050 loss_train: 1.1022 acc_train: 0.9183 loss_val: 1.0766 acc_val: 0.9231 time: 0.0036s\n",
            "Epoch: 0051 loss_train: 1.0755 acc_train: 0.9183 loss_val: 1.0523 acc_val: 0.9231 time: 0.0049s\n",
            "Epoch: 0052 loss_train: 1.0509 acc_train: 0.9183 loss_val: 1.0284 acc_val: 0.9231 time: 0.0055s\n",
            "Epoch: 0053 loss_train: 1.0286 acc_train: 0.9183 loss_val: 1.0051 acc_val: 0.9231 time: 0.0050s\n",
            "Epoch: 0054 loss_train: 1.0063 acc_train: 0.9183 loss_val: 0.9822 acc_val: 0.9231 time: 0.0035s\n",
            "Epoch: 0055 loss_train: 0.9794 acc_train: 0.9183 loss_val: 0.9599 acc_val: 0.9231 time: 0.0060s\n",
            "Epoch: 0056 loss_train: 0.9562 acc_train: 0.9183 loss_val: 0.9382 acc_val: 0.9231 time: 0.0055s\n",
            "Epoch: 0057 loss_train: 0.9342 acc_train: 0.9183 loss_val: 0.9170 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0058 loss_train: 0.9110 acc_train: 0.9183 loss_val: 0.8964 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0059 loss_train: 0.8886 acc_train: 0.9183 loss_val: 0.8764 acc_val: 0.9231 time: 0.0050s\n",
            "Epoch: 0060 loss_train: 0.8714 acc_train: 0.9183 loss_val: 0.8570 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0061 loss_train: 0.8513 acc_train: 0.9183 loss_val: 0.8382 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0062 loss_train: 0.8341 acc_train: 0.9183 loss_val: 0.8199 acc_val: 0.9231 time: 0.0055s\n",
            "Epoch: 0063 loss_train: 0.8154 acc_train: 0.9183 loss_val: 0.8023 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0064 loss_train: 0.7960 acc_train: 0.9183 loss_val: 0.7852 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0065 loss_train: 0.7792 acc_train: 0.9183 loss_val: 0.7688 acc_val: 0.9231 time: 0.0030s\n",
            "Epoch: 0066 loss_train: 0.7627 acc_train: 0.9183 loss_val: 0.7529 acc_val: 0.9231 time: 0.0052s\n",
            "Epoch: 0067 loss_train: 0.7484 acc_train: 0.9183 loss_val: 0.7375 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0068 loss_train: 0.7296 acc_train: 0.9183 loss_val: 0.7228 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0069 loss_train: 0.7122 acc_train: 0.9183 loss_val: 0.7085 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0070 loss_train: 0.7009 acc_train: 0.9183 loss_val: 0.6949 acc_val: 0.9231 time: 0.0060s\n",
            "Epoch: 0071 loss_train: 0.6869 acc_train: 0.9183 loss_val: 0.6817 acc_val: 0.9231 time: 0.0035s\n",
            "Epoch: 0072 loss_train: 0.6720 acc_train: 0.9183 loss_val: 0.6690 acc_val: 0.9231 time: 0.0030s\n",
            "Epoch: 0073 loss_train: 0.6580 acc_train: 0.9183 loss_val: 0.6569 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0074 loss_train: 0.6491 acc_train: 0.9183 loss_val: 0.6452 acc_val: 0.9231 time: 0.0065s\n",
            "Epoch: 0075 loss_train: 0.6354 acc_train: 0.9183 loss_val: 0.6340 acc_val: 0.9231 time: 0.0050s\n",
            "Epoch: 0076 loss_train: 0.6266 acc_train: 0.9183 loss_val: 0.6232 acc_val: 0.9231 time: 0.0044s\n",
            "Epoch: 0077 loss_train: 0.6171 acc_train: 0.9183 loss_val: 0.6129 acc_val: 0.9231 time: 0.0052s\n",
            "Epoch: 0078 loss_train: 0.6033 acc_train: 0.9183 loss_val: 0.6030 acc_val: 0.9231 time: 0.0035s\n",
            "Epoch: 0079 loss_train: 0.5945 acc_train: 0.9183 loss_val: 0.5935 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0080 loss_train: 0.5813 acc_train: 0.9183 loss_val: 0.5843 acc_val: 0.9231 time: 0.0042s\n",
            "Epoch: 0081 loss_train: 0.5738 acc_train: 0.9183 loss_val: 0.5756 acc_val: 0.9231 time: 0.0050s\n",
            "Epoch: 0082 loss_train: 0.5648 acc_train: 0.9183 loss_val: 0.5672 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0083 loss_train: 0.5554 acc_train: 0.9183 loss_val: 0.5592 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0084 loss_train: 0.5498 acc_train: 0.9183 loss_val: 0.5514 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0085 loss_train: 0.5401 acc_train: 0.9183 loss_val: 0.5441 acc_val: 0.9231 time: 0.0050s\n",
            "Epoch: 0086 loss_train: 0.5343 acc_train: 0.9183 loss_val: 0.5370 acc_val: 0.9231 time: 0.0050s\n",
            "Epoch: 0087 loss_train: 0.5248 acc_train: 0.9183 loss_val: 0.5302 acc_val: 0.9231 time: 0.0052s\n",
            "Epoch: 0088 loss_train: 0.5196 acc_train: 0.9183 loss_val: 0.5236 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0089 loss_train: 0.5133 acc_train: 0.9183 loss_val: 0.5174 acc_val: 0.9231 time: 0.0041s\n",
            "Epoch: 0090 loss_train: 0.5058 acc_train: 0.9183 loss_val: 0.5113 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0091 loss_train: 0.4998 acc_train: 0.9183 loss_val: 0.5056 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0092 loss_train: 0.4916 acc_train: 0.9183 loss_val: 0.5000 acc_val: 0.9231 time: 0.0072s\n",
            "Epoch: 0093 loss_train: 0.4877 acc_train: 0.9183 loss_val: 0.4947 acc_val: 0.9231 time: 0.0042s\n",
            "Epoch: 0094 loss_train: 0.4871 acc_train: 0.9183 loss_val: 0.4896 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0095 loss_train: 0.4775 acc_train: 0.9183 loss_val: 0.4847 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0096 loss_train: 0.4713 acc_train: 0.9183 loss_val: 0.4799 acc_val: 0.9231 time: 0.0050s\n",
            "Epoch: 0097 loss_train: 0.4669 acc_train: 0.9183 loss_val: 0.4754 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0098 loss_train: 0.4616 acc_train: 0.9183 loss_val: 0.4710 acc_val: 0.9231 time: 0.0035s\n",
            "Epoch: 0099 loss_train: 0.4599 acc_train: 0.9183 loss_val: 0.4668 acc_val: 0.9231 time: 0.0060s\n",
            "Epoch: 0100 loss_train: 0.4572 acc_train: 0.9183 loss_val: 0.4627 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0101 loss_train: 0.4489 acc_train: 0.9183 loss_val: 0.4588 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0102 loss_train: 0.4470 acc_train: 0.9183 loss_val: 0.4551 acc_val: 0.9231 time: 0.0030s\n",
            "Epoch: 0103 loss_train: 0.4453 acc_train: 0.9183 loss_val: 0.4514 acc_val: 0.9231 time: 0.0064s\n",
            "Epoch: 0104 loss_train: 0.4396 acc_train: 0.9183 loss_val: 0.4479 acc_val: 0.9231 time: 0.0035s\n",
            "Epoch: 0105 loss_train: 0.4361 acc_train: 0.9183 loss_val: 0.4445 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0106 loss_train: 0.4328 acc_train: 0.9183 loss_val: 0.4413 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0107 loss_train: 0.4265 acc_train: 0.9183 loss_val: 0.4381 acc_val: 0.9231 time: 0.0055s\n",
            "Epoch: 0108 loss_train: 0.4263 acc_train: 0.9183 loss_val: 0.4351 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0109 loss_train: 0.4192 acc_train: 0.9183 loss_val: 0.4321 acc_val: 0.9231 time: 0.0041s\n",
            "Epoch: 0110 loss_train: 0.4198 acc_train: 0.9183 loss_val: 0.4293 acc_val: 0.9231 time: 0.0055s\n",
            "Epoch: 0111 loss_train: 0.4161 acc_train: 0.9183 loss_val: 0.4265 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0112 loss_train: 0.4157 acc_train: 0.9183 loss_val: 0.4239 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0113 loss_train: 0.4121 acc_train: 0.9183 loss_val: 0.4213 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0114 loss_train: 0.4103 acc_train: 0.9183 loss_val: 0.4188 acc_val: 0.9231 time: 0.0051s\n",
            "Epoch: 0115 loss_train: 0.4080 acc_train: 0.9183 loss_val: 0.4163 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0116 loss_train: 0.4051 acc_train: 0.9183 loss_val: 0.4140 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0117 loss_train: 0.4016 acc_train: 0.9183 loss_val: 0.4117 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0118 loss_train: 0.3989 acc_train: 0.9183 loss_val: 0.4095 acc_val: 0.9231 time: 0.0060s\n",
            "Epoch: 0119 loss_train: 0.3957 acc_train: 0.9183 loss_val: 0.4073 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0120 loss_train: 0.3964 acc_train: 0.9183 loss_val: 0.4052 acc_val: 0.9231 time: 0.0041s\n",
            "Epoch: 0121 loss_train: 0.3939 acc_train: 0.9183 loss_val: 0.4032 acc_val: 0.9231 time: 0.0050s\n",
            "Epoch: 0122 loss_train: 0.3914 acc_train: 0.9183 loss_val: 0.4012 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0123 loss_train: 0.3884 acc_train: 0.9183 loss_val: 0.3993 acc_val: 0.9231 time: 0.0042s\n",
            "Epoch: 0124 loss_train: 0.3870 acc_train: 0.9183 loss_val: 0.3974 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0125 loss_train: 0.3829 acc_train: 0.9183 loss_val: 0.3956 acc_val: 0.9231 time: 0.0053s\n",
            "Epoch: 0126 loss_train: 0.3816 acc_train: 0.9183 loss_val: 0.3938 acc_val: 0.9231 time: 0.0043s\n",
            "Epoch: 0127 loss_train: 0.3826 acc_train: 0.9183 loss_val: 0.3921 acc_val: 0.9231 time: 0.0035s\n",
            "Epoch: 0128 loss_train: 0.3813 acc_train: 0.9183 loss_val: 0.3904 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0129 loss_train: 0.3774 acc_train: 0.9183 loss_val: 0.3887 acc_val: 0.9231 time: 0.0055s\n",
            "Epoch: 0130 loss_train: 0.3759 acc_train: 0.9183 loss_val: 0.3871 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0131 loss_train: 0.3762 acc_train: 0.9183 loss_val: 0.3856 acc_val: 0.9231 time: 0.0033s\n",
            "Epoch: 0132 loss_train: 0.3746 acc_train: 0.9183 loss_val: 0.3840 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0133 loss_train: 0.3722 acc_train: 0.9183 loss_val: 0.3825 acc_val: 0.9231 time: 0.0061s\n",
            "Epoch: 0134 loss_train: 0.3709 acc_train: 0.9183 loss_val: 0.3811 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0135 loss_train: 0.3723 acc_train: 0.9183 loss_val: 0.3796 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0136 loss_train: 0.3660 acc_train: 0.9183 loss_val: 0.3783 acc_val: 0.9231 time: 0.0030s\n",
            "Epoch: 0137 loss_train: 0.3662 acc_train: 0.9183 loss_val: 0.3769 acc_val: 0.9231 time: 0.0055s\n",
            "Epoch: 0138 loss_train: 0.3673 acc_train: 0.9183 loss_val: 0.3756 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0139 loss_train: 0.3638 acc_train: 0.9183 loss_val: 0.3742 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0140 loss_train: 0.3634 acc_train: 0.9183 loss_val: 0.3730 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0141 loss_train: 0.3592 acc_train: 0.9183 loss_val: 0.3717 acc_val: 0.9231 time: 0.0055s\n",
            "Epoch: 0142 loss_train: 0.3603 acc_train: 0.9183 loss_val: 0.3705 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0143 loss_train: 0.3601 acc_train: 0.9183 loss_val: 0.3693 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0144 loss_train: 0.3566 acc_train: 0.9183 loss_val: 0.3681 acc_val: 0.9231 time: 0.0050s\n",
            "Epoch: 0145 loss_train: 0.3568 acc_train: 0.9183 loss_val: 0.3670 acc_val: 0.9231 time: 0.0041s\n",
            "Epoch: 0146 loss_train: 0.3576 acc_train: 0.9183 loss_val: 0.3658 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0147 loss_train: 0.3542 acc_train: 0.9183 loss_val: 0.3647 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0148 loss_train: 0.3542 acc_train: 0.9183 loss_val: 0.3637 acc_val: 0.9231 time: 0.0060s\n",
            "Epoch: 0149 loss_train: 0.3542 acc_train: 0.9183 loss_val: 0.3626 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0150 loss_train: 0.3522 acc_train: 0.9183 loss_val: 0.3615 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0151 loss_train: 0.3511 acc_train: 0.9183 loss_val: 0.3605 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0152 loss_train: 0.3496 acc_train: 0.9183 loss_val: 0.3595 acc_val: 0.9231 time: 0.0065s\n",
            "Epoch: 0153 loss_train: 0.3510 acc_train: 0.9183 loss_val: 0.3585 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0154 loss_train: 0.3501 acc_train: 0.9183 loss_val: 0.3575 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0155 loss_train: 0.3463 acc_train: 0.9183 loss_val: 0.3565 acc_val: 0.9231 time: 0.0055s\n",
            "Epoch: 0156 loss_train: 0.3466 acc_train: 0.9183 loss_val: 0.3556 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0157 loss_train: 0.3450 acc_train: 0.9183 loss_val: 0.3547 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0158 loss_train: 0.3435 acc_train: 0.9183 loss_val: 0.3538 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0159 loss_train: 0.3464 acc_train: 0.9183 loss_val: 0.3529 acc_val: 0.9231 time: 0.0050s\n",
            "Epoch: 0160 loss_train: 0.3432 acc_train: 0.9183 loss_val: 0.3520 acc_val: 0.9231 time: 0.0050s\n",
            "Epoch: 0161 loss_train: 0.3425 acc_train: 0.9183 loss_val: 0.3511 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0162 loss_train: 0.3419 acc_train: 0.9183 loss_val: 0.3503 acc_val: 0.9231 time: 0.0052s\n",
            "Epoch: 0163 loss_train: 0.3392 acc_train: 0.9183 loss_val: 0.3494 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0164 loss_train: 0.3402 acc_train: 0.9183 loss_val: 0.3486 acc_val: 0.9231 time: 0.0043s\n",
            "Epoch: 0165 loss_train: 0.3371 acc_train: 0.9183 loss_val: 0.3478 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0166 loss_train: 0.3391 acc_train: 0.9183 loss_val: 0.3470 acc_val: 0.9231 time: 0.0055s\n",
            "Epoch: 0167 loss_train: 0.3387 acc_train: 0.9183 loss_val: 0.3462 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0168 loss_train: 0.3369 acc_train: 0.9183 loss_val: 0.3454 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0169 loss_train: 0.3396 acc_train: 0.9183 loss_val: 0.3447 acc_val: 0.9231 time: 0.0060s\n",
            "Epoch: 0170 loss_train: 0.3362 acc_train: 0.9183 loss_val: 0.3439 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0171 loss_train: 0.3371 acc_train: 0.9183 loss_val: 0.3432 acc_val: 0.9231 time: 0.0041s\n",
            "Epoch: 0172 loss_train: 0.3354 acc_train: 0.9183 loss_val: 0.3424 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0173 loss_train: 0.3356 acc_train: 0.9183 loss_val: 0.3417 acc_val: 0.9231 time: 0.0063s\n",
            "Epoch: 0174 loss_train: 0.3336 acc_train: 0.9183 loss_val: 0.3410 acc_val: 0.9231 time: 0.0060s\n",
            "Epoch: 0175 loss_train: 0.3349 acc_train: 0.9183 loss_val: 0.3403 acc_val: 0.9231 time: 0.0043s\n",
            "Epoch: 0176 loss_train: 0.3339 acc_train: 0.9183 loss_val: 0.3396 acc_val: 0.9231 time: 0.0065s\n",
            "Epoch: 0177 loss_train: 0.3325 acc_train: 0.9183 loss_val: 0.3389 acc_val: 0.9231 time: 0.0055s\n",
            "Epoch: 0178 loss_train: 0.3309 acc_train: 0.9183 loss_val: 0.3382 acc_val: 0.9231 time: 0.0055s\n",
            "Epoch: 0179 loss_train: 0.3298 acc_train: 0.9183 loss_val: 0.3376 acc_val: 0.9231 time: 0.0050s\n",
            "Epoch: 0180 loss_train: 0.3308 acc_train: 0.9183 loss_val: 0.3369 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0181 loss_train: 0.3280 acc_train: 0.9183 loss_val: 0.3363 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0182 loss_train: 0.3301 acc_train: 0.9183 loss_val: 0.3356 acc_val: 0.9231 time: 0.0030s\n",
            "Epoch: 0183 loss_train: 0.3279 acc_train: 0.9183 loss_val: 0.3350 acc_val: 0.9231 time: 0.0065s\n",
            "Epoch: 0184 loss_train: 0.3267 acc_train: 0.9183 loss_val: 0.3344 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0185 loss_train: 0.3261 acc_train: 0.9183 loss_val: 0.3338 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0186 loss_train: 0.3266 acc_train: 0.9183 loss_val: 0.3332 acc_val: 0.9231 time: 0.0060s\n",
            "Epoch: 0187 loss_train: 0.3262 acc_train: 0.9183 loss_val: 0.3326 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0188 loss_train: 0.3271 acc_train: 0.9183 loss_val: 0.3320 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0189 loss_train: 0.3267 acc_train: 0.9183 loss_val: 0.3314 acc_val: 0.9231 time: 0.0035s\n",
            "Epoch: 0190 loss_train: 0.3259 acc_train: 0.9183 loss_val: 0.3309 acc_val: 0.9231 time: 0.0050s\n",
            "Epoch: 0191 loss_train: 0.3262 acc_train: 0.9183 loss_val: 0.3303 acc_val: 0.9231 time: 0.0055s\n",
            "Epoch: 0192 loss_train: 0.3253 acc_train: 0.9183 loss_val: 0.3297 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0193 loss_train: 0.3231 acc_train: 0.9183 loss_val: 0.3292 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0194 loss_train: 0.3241 acc_train: 0.9183 loss_val: 0.3287 acc_val: 0.9231 time: 0.0052s\n",
            "Epoch: 0195 loss_train: 0.3232 acc_train: 0.9183 loss_val: 0.3281 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0196 loss_train: 0.3222 acc_train: 0.9183 loss_val: 0.3276 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0197 loss_train: 0.3222 acc_train: 0.9183 loss_val: 0.3271 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0198 loss_train: 0.3221 acc_train: 0.9183 loss_val: 0.3265 acc_val: 0.9231 time: 0.0045s\n",
            "Epoch: 0199 loss_train: 0.3206 acc_train: 0.9183 loss_val: 0.3260 acc_val: 0.9231 time: 0.0040s\n",
            "Epoch: 0200 loss_train: 0.3198 acc_train: 0.9183 loss_val: 0.3255 acc_val: 0.9231 time: 0.0050s\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import csv\n",
        "import torch\n",
        "\n",
        "def train_model(show_result = True):\n",
        "    val_loss = []\n",
        "    train_loss = [] # List to store training losses\n",
        "    train_acc = []  # List to store training accuracies\n",
        "    val_acc = []    # List to store validation accuracies\n",
        "\n",
        "    # Ensure labels are on the correct device\n",
        "    labels_tensor = labels.to(device)  # Move labels to the desired device if needed\n",
        "    #If labels is already a CUDA tensor, this line will have no effect, but won't cause harm either.\n",
        "    # If labels is a CPU tensor, it will be moved to the GPU.\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        t = time.time()\n",
        "        model.train()\n",
        "        optimizer.zero_grad()\n",
        "        output= model(features, adj)\n",
        "        loss_train_epoch = criterion(output[idx_train], labels_tensor[idx_train])\n",
        "        acc_train_epoch = cal_accuracy(output[idx_train], labels_tensor[idx_train])\n",
        "        loss_train_epoch.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Store training loss and accuracy for this epoch\n",
        "        train_loss.append(loss_train_epoch.item())\n",
        "        train_acc.append(acc_train_epoch)\n",
        "\n",
        "        model.eval()\n",
        "        output = model(features, adj)\n",
        "\n",
        "        loss_val_epoch = criterion(output[idx_val], labels_tensor[idx_val])\n",
        "        val_loss.append(loss_val_epoch.item())\n",
        "        acc_val_epoch = cal_accuracy(output[idx_val], labels_tensor[idx_val])\n",
        "\n",
        "        # Store validation accuracy for this epoch\n",
        "        val_acc.append(acc_val_epoch)\n",
        "\n",
        "        if show_result:\n",
        "            print(  'Epoch: {:04d}'.format(epoch+1),\n",
        "                    'loss_train: {:.4f}'.format(loss_train_epoch.item()),\n",
        "                    'acc_train: {:.4f}'.format(acc_train_epoch),\n",
        "                    'loss_val: {:.4f}'.format(loss_val_epoch.item()),\n",
        "                    'acc_val: {:.4f}'.format(acc_val_epoch),\n",
        "                    'time: {:.4f}s'.format(time.time() - t))\n",
        "\n",
        "        if epoch > EARLY_STOPPING and np.min(val_loss[-EARLY_STOPPING:]) > np.min(val_loss[:-EARLY_STOPPING]) :\n",
        "            if show_result:\n",
        "                print(\"Early Stopping...\")\n",
        "            break\n",
        "\n",
        "    return train_loss, train_acc, val_loss, val_acc # Return the collected metrics\n",
        "\n",
        "# Call train_model and store the returned metrics\n",
        "loss_train, acc_train, loss_val, acc_val = train_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "tYnZVMt-3xZq"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1400x700 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plotting the metrics\n",
        "epochs = list(range(1, len(loss_train) + 1))\n",
        "\n",
        "dataset = 'CS'\n",
        "plt.figure(figsize=(14, 7))\n",
        "\n",
        "# Plot for Loss\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs, acc_train, 'b', label='Training accuracy')\n",
        "plt.plot(epochs, acc_val, 'r', label='Validation accuracy')\n",
        "plt.plot(epochs, loss_train, 'b', label='Training loss')\n",
        "plt.plot(epochs, loss_val, 'r', label='Validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy and Loss')\n",
        "plt.ylim(0, 1.0)\n",
        "plt.xlim(0, 200)\n",
        "plt.legend()\n",
        "\n",
        "# Plot for Accuracy\n",
        "# plt.subplot(1, 2, 2)\n",
        "\n",
        "# plt.title('Training and Validation Accuracy')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Accuracy')\n",
        "# plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzUDA-jC3xZq"
      },
      "source": [
        "## Evaluate for 10 Times Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "25RNKqgi3xZq"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "K4hBpNSf3xZq"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "'numpy.ndarray' object has no attribute 'cpu'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[34], line 16\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m acc, f11, f12, f13\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#print(test())\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Call the test function and print the results\u001b[39;00m\n\u001b[1;32m---> 16\u001b[0m acc, f1_macro, f1_micro, f1_weighted \u001b[38;5;241m=\u001b[39m test()\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy:\u001b[39m\u001b[38;5;124m\"\u001b[39m, acc)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mF1 Score (Macro):\u001b[39m\u001b[38;5;124m\"\u001b[39m, f1_macro)\n",
            "Cell \u001b[1;32mIn[34], line 7\u001b[0m, in \u001b[0;36mtest\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m predictions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39margmax(output[idx_test],\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mtolist()\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Move test_labels to CPU and convert to NumPy array\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m test_labels_np \u001b[38;5;241m=\u001b[39m test_labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m      8\u001b[0m acc \u001b[38;5;241m=\u001b[39m accuracy_score(test_labels_np, predictions)  \u001b[38;5;66;03m# Use the NumPy array\u001b[39;00m\n\u001b[0;32m      9\u001b[0m f11 \u001b[38;5;241m=\u001b[39m f1_score(test_labels_np,predictions, average\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmacro\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;66;03m# Use the NumPy array\u001b[39;00m\n",
            "\u001b[1;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'cpu'"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import f1_score, accuracy_score\n",
        "def test():\n",
        "    model.eval()\n",
        "    output = model(features, adj)\n",
        "    predictions = torch.argmax(output[idx_test],-1).cpu().tolist()\n",
        "    # Move test_labels to CPU and convert to NumPy array\n",
        "    test_labels_np = test_labels.cpu().numpy()\n",
        "    acc = accuracy_score(test_labels_np, predictions)  # Use the NumPy array\n",
        "    f11 = f1_score(test_labels_np,predictions, average='macro') # Use the NumPy array\n",
        "    f12 = f1_score(test_labels_np,predictions, average = 'micro') # Use the NumPy array\n",
        "    f13 = f1_score(test_labels_np,predictions, average = 'weighted') # Use the NumPy array\n",
        "    return acc, f11, f12, f13\n",
        "\n",
        "#print(test())\n",
        "# Call the test function and print the results\n",
        "acc, f1_macro, f1_micro, f1_weighted = test()\n",
        "print(\"Accuracy:\", acc)\n",
        "print(\"F1 Score (Macro):\", f1_macro)\n",
        "print(\"F1 Score (Micro):\", f1_micro)\n",
        "print(\"F1 Score (Weighted):\", f1_weighted)\n",
        "print(\"std:\", np.std(np.array(val_loss)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6dgAhfGnltx"
      },
      "source": [
        "## Data process for LLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorboard\n",
            "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting absl-py>=0.4 (from tensorboard)\n",
            "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
            "Collecting grpcio>=1.48.2 (from tensorboard)\n",
            "  Downloading grpcio-1.73.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from tensorboard) (3.4.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from tensorboard) (1.26.4)\n",
            "Requirement already satisfied: packaging in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from tensorboard) (24.2)\n",
            "Requirement already satisfied: pillow in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from tensorboard) (10.3.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from tensorboard) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from tensorboard) (69.5.1)\n",
            "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard)\n",
            "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from tensorboard) (3.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\romeo\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard) (2.1.3)\n",
            "Downloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
            "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
            "   ---------------------------------------- 0.1/5.5 MB 1.6 MB/s eta 0:00:04\n",
            "   --- ------------------------------------ 0.5/5.5 MB 6.0 MB/s eta 0:00:01\n",
            "   ------- -------------------------------- 1.0/5.5 MB 8.0 MB/s eta 0:00:01\n",
            "   ----------- ---------------------------- 1.6/5.5 MB 9.3 MB/s eta 0:00:01\n",
            "   ---------------- ----------------------- 2.3/5.5 MB 11.1 MB/s eta 0:00:01\n",
            "   --------------------- ------------------ 2.9/5.5 MB 11.6 MB/s eta 0:00:01\n",
            "   ------------------------- -------------- 3.6/5.5 MB 11.9 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 4.2/5.5 MB 12.2 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 4.8/5.5 MB 12.3 MB/s eta 0:00:01\n",
            "   ---------------------------------------  5.5/5.5 MB 12.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 5.5/5.5 MB 12.2 MB/s eta 0:00:00\n",
            "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
            "   ---------------------------------------- 0.0/135.8 kB ? eta -:--:--\n",
            "   ---------------------------------------- 135.8/135.8 kB 7.8 MB/s eta 0:00:00\n",
            "Downloading grpcio-1.73.1-cp312-cp312-win_amd64.whl (4.3 MB)\n",
            "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
            "   ------ --------------------------------- 0.7/4.3 MB 13.9 MB/s eta 0:00:01\n",
            "   ------------ --------------------------- 1.3/4.3 MB 13.8 MB/s eta 0:00:01\n",
            "   ----------------- ---------------------- 1.9/4.3 MB 13.7 MB/s eta 0:00:01\n",
            "   ----------------------- ---------------- 2.6/4.3 MB 13.6 MB/s eta 0:00:01\n",
            "   ----------------------------- ---------- 3.2/4.3 MB 13.7 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 3.9/4.3 MB 13.7 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 4.3/4.3 MB 13.2 MB/s eta 0:00:00\n",
            "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
            "Installing collected packages: tensorboard-data-server, grpcio, absl-py, tensorboard\n",
            "Successfully installed absl-py-2.3.1 grpcio-1.73.1 tensorboard-2.20.0 tensorboard-data-server-0.7.2\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cL473kazo3NB"
      },
      "outputs": [],
      "source": [
        "# print(len(all_titles_lists))\n",
        "# print(len(sentences))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "MMRUn20Pts5k"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[['similarity', 'maintenance', 'framework', 'machinery'], ['hole', 'vacuum', 'environment', 'influence', 'deformability', 'waveform', 'interpretation', 'wave', 'analysi', 'work', 'focu', 'generation', 'vacuum', 'evolution', 'deformability', 'measurability']], [['review', 'learning', 'diagnosi', 'machinery'], ['type', 'center', 'gc', 'region', 'vicinity', 'hole', 'smbh', 'type', 'hypervelocity', 'star', 'counterpart', 'orbit', 'sgr', 'type', 'hvs', 'escape', 'speed', 'halo', 'smbh', 'sgr', 'distribution', 'deficit', 'hvs', 'velocity', 'deficit', 'deficiency', 'ma', 'hole', 'imbh', 'ma', 'binary', 'merger', 'way', 'sausage', 'enceladu', 'dwarf', 'galaxy', 'recoil', 'sgr', 'velocity', 'change', 'hv', 'ejection', 'scenario', 'formation', 'star', 'cluster', 'gc', 'distribution', 'size', 'stellar']], [['intersection', 'signal', 'processing', 'machine', 'learning', 'use', 'case', 'analysi'], ['quantization', 'teleparallel', 'relativity', 'tegr', 'space', 'time', 'weyl', 'dw', 'formulation', 'quantization', 'quantization', 'equation', 'tegr', 'quantization', 'analysi', 'formulation', 'dw', 'theory', 'treatment', 'operator', 'hermicity', 'number', 'term', 'hamiltonian', 'operator', 'constant', 'value']], [['sb', 'pdm', 'tool', 'maintenance'], ['existence', 'ma', 'multus', 'messenger', 'star', 'merger', 'existence', 'flavor', 'conversion', 'phenomenology', 'flavor', 'scenario', 'neutrino', 'emission', 'angle', 'accretion', 'evolution', 'merger', 'toru', 'geometry', 'neutron', 'richnes', 'remnant', 'occurrence', 'number', 'direction', 'toru', 'production', 'proximity', 'region', 'hole', 'toru', 'time', 'shallower', 'baryon', 'density', 'flavor', 'conversion', 'parameter', 'space', 'flavor', 'mixing', 'production', 'rate']], [['alarm', 'prevention', 'domain', 'knowledge', 'machine', 'detection', 'water', 'distribution'], ['theory', 'gravity', 'contribution', 'curvature', 'system', 'friedmann', 'robertson', 'walker', 'formulate', 'jordan', 'frame', 'einstein', 'frame', 'show', 'function', 'expansion', 'matter', 'centre', 'show', 'einstein', 'frame', 'measure', 'state', 'state', 'singularity', 'show', 'jordan', 'frame', 'formulation', 'theory']], [['comparison', 'adaptation', 'classification', 'production', 'environment'], ['conjecture', 'dombi', 'number', 'theory', 'property', 'mathbbn', 'setminu', 'sequence', 'n', 'rightarrow', 'text', 'abc', 'number']], [['vibration', 'condition', 'monitoring'], ['world', 'way', 'computation', 'way', 'quantum', 'problem', 'accurate', 'simulation', 'quantum', 'day', 'quantum', 'hardware', 'time', 'quantum', 'computer', 'model', 'simulation', 'hemocyanin', 'molecule', 'respiratory', 'cancer', 'mechanism', 'hemocyanin', 'quantum', 'eigensolver', 'vqe', 'quantum', 'field', 'theory', 'anderson', 'impurity', 'model', 'aim', 'structure', 'hemocyanin', 'body', 'effort', 'electron', 'introduction', 'quantum', 'encourage', 'use', 'quantum', 'efficiency', 'chemistry']], [['evriimsel', 'sinir', 'mimarisi', 'zaman', 'kullanlarak', 'byk', 'gl', 'motor', 'arzalarnn', 'tespitus'], ['propellant', 'kind', 'ratio', 'composition', 'microstructure', 'propellant', 'materium', 'complexity', 'composition', 'structure', 'observation', 'simulation', 'behavior', 'analysi', 'charge', 'design', 'observation', 'lack', 'model', 'analysi', 'verification', 'development', 'engineering', 'extent', 'throughput', 'capture', 'analysi', 'prediction', 'optimization', 'network', 'model', 'calculation', 'calculation', 'direction', 'multus', 'scale', 'behavior']], [['estimation', 'life', 'turbofan', 'engine', 'learning'], ['ma', 'sky', 'survey', 'era', 'suprime', 'cam', 'program', 'hsc', 'ssp', 'sa', 'ray', 'ma', 'concentration', 'relation', 'sample', 'ma', 'modot', 'sim', 'contamination', 'ma', 'ma', 'cluster', 'richnes', 'ray', 'count', 'rate', 'galactic', 'region', 'count', 'rate', 'ssp', 'framework', 'ma', 'concentration', 'relation', 'cluster', 'sample', 'ma', 'calibration', 'ma', 'concentration', 'parameter', 'space', 'redshift', 'ma', 'concentration', 'relation', 'agreement', 'matter', 'ray', 'wl', 'analysi', 'era', 'wl', 'sn', 'effect', 'ray', 'ma', 'miscentering', 'effect', 'sn', 'ellipticity', 'langle', 'varepsilon', 'angle', 'msim', 'modot']], [['detection', 'representation', 'response'], ['vision', 'localization', 'localization', 'satellite', 'location', 'vector', 'navigation', 'vector', 'dof', 'cro', 'modal', 'feature', 'extraction', 'module', 'latency', 'flight', 'deployment', 'vector', 'feature', 'extraction', 'module', 'representation', 'map', 'robustnes', 'appearance', 'module', 'dof', 'estimation', 'parameter', 'cro', 'modal', 'vecmaplocnet', 'introduce', 'dataset', 'experimentation', 'vecmaplocnet', 'performance', 'localization', 'accuracy', 'estimation', 'efficiency', 'm', 'latency', 'device', 'jetson', 'performance', 'world', 'generalization', 'ability', 'localization', 'error', 'orientation', 'error']], [['holder', 'fokker', 'planck'], ['dozen', 'b', 'way', 'halo', 'escape', 'speed', 'hypervelocity', 'show', 'velocity', 'distribution', 'deficiency', 'km', 'hvs', 'hole', 'mbh', 'conclusion', 'los', 'cone', 'regime', 'population', 'centre', 'hvs', 'star', 'formation', 'history', 'velocity', 'distribution', 'mismatch', 'flight', 'velocity', 'distribution', 'halo', 'centre', 'dust']], [['fokkerplanck', 'equation', 'domain', 'hypocoercivity', 'time', 'behavior'], ['image', 'retrieval', 'intent', 'image', 'text', 'alignment', 'fusion', 'network', 'information', 'network', 'attention', 'image', 'gap', 'network', 'information', 'text', 'weight', 'allocation', 'feature', 'proces', 'feature', 'space', 'fashioniq', 'state', 'art', 'image', 'retrieval']], [['cutoff', 'boltzmann', 'equation', 'domain'], ['review', 'intelligence', 'vision', 'language', 'transparency', 'analysi', 'question', 'image', 'dialogue', 'background', 'language', 'intelligence', 'ai', 'concern', 'transparency', 'core', 'vision', 'language', 'analyze', 'fairnes', 'explainability', 'literature', 'state', 'art', 'transparency', 'explainability', 'vision', 'language', 'trust', 'attention', 'gradient', 'issue', 'fairnes', 'mitigation', 'dialogue', 'deployment', 'vision', 'language', 'conclusion', 'importance', 'transparency', 'vision', 'language', 'framework']], [['boundednes', 'type'], ['reliability', 'density', 'theory', 'counterpart', 'parameterization', 'approximate', 'energy', 'construction', 'employment', 'validation', 'review', 'conjecture', 'incorporation', 'correlation', 'energy', 'entropy', 'identification', 'energy', 'applicability', 'claim', 'conjecture', 'formalism', 'incorporation', 'correlation', 'structure', 'chemical', 'accuracy']], [['obstacle', 'problem', 'kolmogorovfokkerplanck', 'operator'], ['correlation', 'pairwise', 'query', 'pairwise', 'way', 'number', 'information', 'acquisition', 'information', 'gain', 'performance', 'performance']], [['nash', 'inequality', 'behavior', 'fokker', 'planck', 'equation'], ['number', 'plate', 'detection', 'system', 'world', 'system', 'number', 'plate', 'detection', 'classification', 'enhance', 'recognition', 'denormalization', 'system', 'speed', 'accuracy', 'ratio', 'stage', 'addition', 'variety', 'augmentation', 'variety', 'stanford', 'dataset', 'time', 'community']], [[], ['obstacle', 'problem', 'kolmogorov', 'operator', 'control', 'contribution', 'regularity', 'result', 'literature', 'regularity', 'distance', 'regularity', 'improvement', 'regularity', 'variable', 'theory', 'use', 'improvement', 'regularity', 'solution', 'regularity', 'result', 'thicknes', 'condition', 'surface', 'result', 'step', 'program', 'regularity', 'monotonicity', 'formula', 'commutator', 'estimate', 'regularity']], [['gradient', 'fokker', 'planck'], ['power', 'consumption', 'computer', 'computing', 'von', 'neumann', 'bottleneck', 'vnb', 'exchange', 'memory', 'processing', 'unit', 'power', 'consumption', 'intelligence', 'change', 'paradigm', 'comply', 'demand', 'power', 'non', 'candidate', 'transition', 'generation', 'hardware', 'possibility', 'store', 'proces', 'information', 'place', 'vnb', 'evaluate', 'state', 'grade', 'channel', 'performance', 'framework', 'memory', 'analog', 'weight', 'system', 'platform', 'performance', 'power', 'consumption', 'imply', 'memory', 'lim', 'framework', 'memory', 'computation', 'boolean', 'projection', 'estimation', 'paradigm', 'work', 'platform', 'test', 'memristor', 'dnn', 'bnn', 'architecture', 'term', 'goal', 'ai']], [['vlasovmaxwelllandau', 'system', 'reflection', 'condition'], ['energy', 'cl', 'br', 'method', 'field', 'occupation', 'distribution', 'input', 'dissociation', 'database', 'quality', 'energy', 'curve', 'spectroscopic', 'energy']], [['regularization', 'obstacle', 'problem', 'kolmogorov', 'operator'], ['panel', 'time', 'heterogeneity', 'method', 'optimization', 'estimator', 'slope', 'coefficient', 'pairwise', 'power', 'infinity', 'estimator', 'require', 'bound', 'number', 'estimation', 'regression', 'application', 'association', 'income', 'democracy']], [['regularity', 'type'], ['sequence', 'bf', 'group', 'let', 'bar', 'g', 'bar', 'sequence', 'bar', 'gg', 'bar', 'gigi', 'gi', 'leq', 'g', 'sequence', 'bf', 'g', 'g', 'element', 'g', 'g', 'bf', 'bar', 'g', 'group', 'odd', 'r', 'g', 'show', 'group', 'group']], [['rate', 'model', 'electron', 'fluence', 'ray', 'absorption', 'edge', 'spectrum'], ['learning', 'interest', 'part', 'dl', 'capacity', 'curse', 'dimensionality', 'cod', 'sense', 'number', 'approximation', 'accuracy', 'dimension', 'result', 'number', 'power', 'approximate', 'pde', 'cod', 'sense', 'number', 'describe', 'dnn', 'dimension', 'approximation', 'accuracy', 'literature', 'heat', 'relu', 'activation', 'time', 'sense', 'cod', 'value', 'dnn', 'cod', 'contribution', 'work', 'generalize', 'result', 'statement', 'sense', 'activation', 'function', 'relu', 'relu', 'activation']], [['post', 'panel'], ['classify', 'navigation', 'satellite', 'system', 'term', 'term', 'use', 'displacement', 'time', 'series', 'laboratory', 'period', 'basin', 'show', 'phase', 'water', 'surface', 'altimetry', 'gravity', 'recovery', 'climate', 'grace', 'grace', 'gravity', 'land', 'water', 'storage', 'glw', 'v', 'set', 'grace', 'watergap', 'model', 'wghm', 'term', 'term', 'wavelet', 'analysi', 'scale', 'correlation', 'gns', 'grace', 'derivedglw', 'resolution', 'grace', 'hydrology', 'model', 'benchmark', 'increase', 'number', 'term', 'advantage', 'broader', 'earthquake', 'response']], [['simple', 'estimator'], ['graph', 'representation', 'order', 'feynman', 'field', 'theory', 'qft', 'combination', 'momentum', 'frequency', 'dyson', 'schwinger', 'parquet', 'structure', 'tensor', 'redundancy', 'evaluation', 'diagram', 'implementation', 'field', 'renormalization', 'scheme', 'qft', 'integration', 'taylor', 'mode', 'differentiation', 'key', 'technique', 'machine', 'order', 'graph', 'operationalize', 'diagram', 'compiler', 'machine', 'methodology', 'effectivenes', 'uniform', 'electron', 'ga', 'problem', 'accuracy', 'quasiparticle', 'ma', 'metal', 'density', 'work', 'machine', 'avenue', 'body']], [['inference', 'heterogeneity'], ['introduce', 'lambda', 'map', 'lambda', 'show', 'quantum', 'separability', 'textbf', 'example', 'entanglement', 'criterion', 'measurement', 'lambda']], [['confidence', 'group', 'membership'], ['measurement', 'signal', 'processing', 'machine', 'performance', 'reliability', 'fusion', 'point', 'evolution', 'signal', 'need', 'bridge', 'knowledge', 'gap', 'literature', 'bridge', 'gap', 'extraction', 'knowledge', 'signal', 'processing', 'assumption', 'obstacle', 'range', 'article', 'processing', 'reader', 'background', 'knowledge', 'signal', 'processing', 'pipeline', 'offering', 'depth', 'review', 'feature', 'extraction', 'literature', 'work', 'review', 'classification', 'taxonomy', 'feature', 'extraction', 'use', 'condition', 'energy', 'analysi', 'epilepsy', 'detection', 'addition', 'culture', 'repository', 'python', 'processing', 'effort', 'support', 'collaborative', 'reproducibility']], [['regularization'], ['entanglement', 'problem', 'quantum', 'information', 'processing', 'transpose', 'pt', 'characterize', 'entanglement', 'ann', 'phy', 'berlin', 'region', 'pt', 'qubit', 'region', 'qubit', 'region', 'pt', 'moment', 'qubit', 'region', 'surface', 'region', 'measurability', 'pt', 'criterion', 'detection', 'qubit', 'entanglement']], [['variance', 'information', 'group', 'structure', 'estimation', 'panel'], ['mechanism', 'pulse', 'growth', 'dispersion', 'bulk', 'side', 'lattice', 'skin', 'effect', 'amplification', 'decay', 'presence', 'dissipation', 'transmission', 'line', 'reveal', 'nonlinearity', 'tuning', 'parameter', 'interplay', 'nonreciprocity', 'dispersion', 'dissipation', 'nonreciprocity', 'strength', 'mechanism', 'propagation', 'signal', 'processing', 'energy', 'transmission']], [['method', 'validity', 'moment', 'panel'], ['field', 'method', 'et', 'al', 'phy', 'rev', 'lett', 'detail', 'method', 'spin', 'distribution', 'occupation', 'dissociation', 'energy', 'entropy', 'energy', 'geometry', 'h', 'hydrogen']], [['latent', 'panel', 'review'], ['compression', 'introduce', 'representation', 'inr', 'video', 'deep', 'learning', 'network', 'perspective', 'compression', 'potential', 'inr', 'network', 'architecture', 'adaptability', 'video', 'compression', 'capture', 'overcome', 'representation', 'video', 'compression', 'canerv', 'inr', 'video', 'compression', 'network', 'structure', 'optimisation', 'video', 'sequence', 'capture', 'information', 'video', 'sequence', 'level', 'adjustment', 'dsa', 'capture', 'sequence', 'frame', 'level', 'adjustment', 'dfa', 'information', 'video', 'detail', 'restoration', 'devise', 'structure', 'level', 'adaptation', 'hsa', 'outperform', 'hvvc', 'state', 'art', 'inr', 'compression', 'video']], [['selection'], ['cutoff', 'equation', 'bounce', 'reflection', 'diffuse', 'reflection', 'ma', 'energy', 'entropy', 'ma', 'density', 'solution', 'macroscopic', 'effect', 'sense', 'proof', 'proof', 'equation']], [['multus', 'block', 'probe', 'variance', 'estimator', 'optimization'], ['work', 'obstacle', 'problem', 'kolmogorovfokkerplanck', 'operator', 'introduction', 'anisotropic', 'space', 'existence', 'solution', 'obstacle', 'problem', 'perturbation', 'argument', 'case', 'interest', 'work', 'inequality']], [['loop', 'algorithm', 'convex', 'sum', 'optimization'], ['traction', 'separation', 'relationship', 'interface', 'component', 'understand', 'model', 'delamination', 'behavior', 'layer', 'experimental', 'traction', 'separation', 'field', 'input', 'article', 'function', 'inversion', 'dgi', 'input', 'field', 'output', 'los', 'function', 'mean', 'field', 'beam', 'end', 'traction', 'portion', 'boundary', 'beam', 'hyperparameter', 'training', 'order', 'elucidate', 'influence', 'mode', 'mode', 'zone', 'extraction', 'field', 'part', 'validation', 'proces', 'consideration', 'traction', 'separation', 'zone', 'error', 'error', 'cantilever', 'beam', 'interaction', 'image', 'correlation', 'traction', 'separation', 'dgi', 'network', 'extraction', 'range', 'traction', 'separation']], [['momentum', 'convex', 'finite', 'sum', 'optimization'], ['prediction', 'health', 'lead', 'organization', 'maintenance', 'maintenance', 'condition', 'maintenance', 'goal', 'time', 'condition', 'performance', 'health', 'equipment', 'dataset', 'world', 'maintenance', 'system', 'failure', 'system', 'degradation', 'model', 'situation', 'time', 'degradation', 'model', 'term', 'model', 'method', 'network', 'cnn', 'training', 'modular', 'aero', 'propulsion', 'system', 'simulation', 'space', 'administration', 'estimate', 'life', 'rul', 'turbofan', 'engine', 'way', 'network', 'performance', 'rul', 'engine', 'failure', 'comparison', 'method', 'rul', 'prediction', 'rul', 'prediction', 'root', 'mean', 'square', 'error', 'time', 'improvement', 'model', 'prediction']], [['optimization'], ['diverse', 'life', 'speed', 'training', 'field', 'inr', 'video', 'state', 'art', 'type', 'parametric', 'speed', 'comparison', 'consider', 'redundant', 'use', 'parameter', 'efficiency', 'bitrate', 'style', 'addres', 'problem', 'video', 'representation', 'modulation', 'nvtm', 'framework', 'capture', 'video', 'information', 'nvtm', 'representation', 'parameter', 'proces', 'speed', 'video', 'quality', 'style', 'method', 'speed', 'increase', 'type', 'compression', 'performance', 'video', 'compression', 'h', 'inr', 'compression', 'performance', 'algorithm', 'resolution', 'frame', 'interpolation', 'video']], [['scale', 'optimization', 'ndcg', 'learning'], ['integration', 'energy', 'ga', 'role', 'carbon', 'energy', 'energy', 'hydrogen', 'ga', 'hcng', 'ratio', 'flexibility', 'market', 'feedback', 'strategy', 'hydrogen', 'blending', 'ratio', 'certificate', 'trading', 'framework', 'model', 'power', 'penetration', 'efficiency', 'efficiency', 'model', 'operation', 'maintenance', 'strategy', 'equivalence', 'performance', 'reduction', 'influence', 'hydrogen', 'production', 'market', 'case', 'reduction', 'decrease', 'energy', 'utilization']], [['field', 'prediction', 'fiber', 'learning'], ['image', 'retrieval', 'target', 'combination', 'reference', 'modification', 'text', 'feature', 'fusion', 'sample', 'quality', 'training', 'cro', 'alignment', 'sample', 'relevance', 'tripartite', 'alignment', 'network', 'momentum', 'distillation', 'mechanism', 'knowledge', 'teacher', 'network', 'super', 'vision', 'guide', 'optimization', 'student', 'network', 'feature', 'encoder', 'tuning', 'stage', 'design', 'response', 'knowledge', 'distillation', 'feature', 'knowledge', 'distillation', 'alignment', 'target', 'fusion', 'target', 'combiner', 'training', 'stage', 'lightweight', 'combiner', 'network', 'cro', 'entropy', 'los', 'function', 'matching', 'image', 'performance', 'state', 'art', 'momentum', 'distillation', 'multimodal', 'learning']], [['attention', 'learning', 'stres', 'strain', 'response', 'prediction', 'inverse', 'design'], ['change', 'detection', 'task', 'remote', 'computer', 'vision', 'level', 'image', 'area', 'variation', 'interference', 'time', 'gap', 'subtle', 'extbfcebsnet', 'novel', 'change', 'background', 'network', 'dependency', 'change', 'detection', 'feature', 'extraction', 'channel', 'swap', 'module', 'csm', 'model', 'dependency', 'excitation', 'suppression', 'module', 'fesm', 'capture', 'integrity', 'change', 'channel', 'attention', 'module', 'enhance', 'ability', 'change', 'street', 'state', 'art', 'performance']], [['element', 'simulation'], ['nonequilibrium', 'body', 'thermalization', 'time', 'fermi', 'ga', 'bc', 'crossover', 'unitarity', 'size', 'evolution', 'momentum', 'distribution', 'difference', 'stage', 'state', 'crossover', 'momentum', 'momentum', 'distribution', 'wavelength', 'momentum', 'momentum', 'curve', 'side', 'thermalization', 'state', 'energy', 'oscillation', 'bound', 'thermalization', 'body']], [['parametric', 'order', 'model', 'framework', 'plasticity'], ['plant', 'disease', 'detection', 'role', 'food', 'security', 'plant', 'shot', 'shot', 'dml', 'technique', 'fewzero', 'shot', 'dml', 'extract', 'layer', 'pre', 'network', 'dependence', 'feature', 'method', 'plant', 'los', 'phase', 'convergence', 'rate', 'network', 'plant', 'village', 'source', 'target', 'knowledge', 'source', 'domain', 'target', 'zero', 'shot', 'domain', 'network', 'gallery', 'network', 'target', 'domain', 'sample', 'network', 'step', 'method', 'classification', 'accuracy', 'fewone', 'clas']], [['image', 'intelligence', 'shape', 'optimisation', 'sheet', 'metal', 'forming'], ['star', 'hole', 'smbh', 'star', 'interaction', 'disruption', 'event', 'tde', 'center', 'star', 'flash', 'evolution', 'code', 'examine', 'phase', 'cooling', 'period', 'hydrogen', 'stage', 'yr', 'increase', 'fraction', 'g', 'result', 'phase', 'stage', 'temperature', 'luminosity', 'sequence', 'ma', 'metal', 'spectroscopic', 'analysi', 'way']], [['prediction', 'damage', 'morphology', 'angle', 'interlock', 'impact', 'learning', 'method'], ['automobile', 'market', 'design', 'response', 'demand', 'design', 'market', 'ai', 'application', 'similarity', 'verification', 'task', 'wheel', 'world', 'problem', 'cro', 'entropy', 'los', 'pairwise', 'space', 'jan', 'verification', 'system', 'design', 'proces', 'hyundai', 'motor', 'company', 'design', 'team', 'verification', 'time', 'min', 'motor', 'advantage', 'verification', 'system']], [['mesh', 'generation', 'random', 'inclusion', 'volume'], ['century', 'concept', 'minkowski', 'spacetime', 'pure', 'point', 'view', 'issue', 'minkowski', 'spacetime', 'framework', 'diffeomorphism', 'gravity', 'type', 'coordinate', 'structure', 'result', 'minkowski', 'spacetime', 'polar', 'curvature', 'tensor', 'riccus', 'tensor', 'curvature', 'result', 'curvature', 'behavior', 'nature', 'idea', 'conclusion', 'nc', 'structure']], [['machine', 'stres', 'characterization', 'friction', 'stir'], ['sheaf', 'theory', 'tool', 'theory', 'flexibility', 'precision', 'graph', 'theory', 'air', 'quality', 'monitoring', 'dust', 'particle', 'density', 'measure', 'air', 'quality', 'measurement', 'standard', 'period', 'index', 'measurement', 'location', 'effect', 'device', 'theory', 'detect', 'count', 'air', 'quality', 'change', 'factor', 'number', 'index', 'propagating', 'index', 'cost', 'air', 'correction', 'time', 'method', 'sheaf', 'theory', 'air', 'quality']], [['engineering', 'eigenvalue', 'quotient'], ['control', 'pre', 'treatment', 'unit', 'choice', 'role', 'performance', 'interpretability', 'control', 'control', 'procedure', 'number', 'select', 'factor', 'model', 'model', 'selection', 'consistency', 'result', 'show', 'procedure', 'mean', 'convergence', 'rate', 'simulation', 'show', 'control', 'bia', 'post', 'treatment', 'performance', 'control', 'revisit', 'passage', 'proposition', 'californium', 'number']], [['field', 'prediction', 'fibre', 'polymer', 'network', 'cnn'], ['realize', 'range', 'equilibrium', 'phenomenon', 'time', 'time', 'rondeau', 'order', 'phase', 'matter', 'random', 'time', 'dissipation', 'counteract', 'demonstrate', 'time', 'rondeau', 'body', 'system', 'synchronization', 'limit', 'time', 'rondeau', 'order', 'presence', 'body', 'interaction', 'synchronization', 'synchronization', 'phase', 'transition', 'interaction', 'strength', 'transition', 'stability', 'analysi']], [['machine', 'regression', 'damage', 'initiation', 'frp'], ['fintech', 'system', 'cluster', 'fintech', 'quantity', 'user', 'consistency', 'practice', 'specify', 'runtime', 'busines', 'development', 'cycle', 'information', 'barrier', 'communication', 'burden', 'time', 'development', 'cycle', 'datum', 'affect', 'development', 'proces', 'code', 'constraint', 'code', 'constraint', 'traceability', 'analysi', 'constraint', 'change', 'target', 'code', 'application', 'dclink', 'world', 'change', 'group', 'target']], [['complexity', 'multiplication', 'field'], ['sum', 'optimization', 'fcco', 'structure', 'optimization', 'paradigm', 'range', 'machine', 'clas', 'non', 'convex', 'fcco', 'outer', 'convex', 'convex', 'convex', 'state', 'art', 'result', 'face', 'iteration', 'complexity', 'oepsilon', 'assumption', 'inner', 'expectation', 'reliance', 'vanilla', 'sgd', 'type', 'learning', 'momentum', 'fcco', 'convergence', 'state', 'art', 'iteration', 'complexity', 'oepsilon', 'inequality', 'optimization', 'convex', 'inequality', 'hinge', 'penalty', 'formulation', 'state', 'art', 'complexity', 'oepsilon', 'level', 'solution', 'effectivenes', 'algorithm']], [['complexity'], ['relation', 'electroencephalography', 'eeg', 'rhythm', 'brain', 'generation', 'replication', 'brain', 'rhythm', 'silico', 'brain', 'information', 'theory', 'information', 'decomposition', 'id', 'emergence', 'excitatoryinhibitory', 'ei', 'network', 'integrate', 'fire', 'term', 'plasticity', 'model', 'range', 'eeg', 'rhythm', 'frequency', 'information', 'relation', 'emergent', 'rhythm', 'suitability', 'information', 'transfer', 'storage', 'operation', 'randomnes', 'example', 'silico', 'information', 'transfer', 'inhibitory', 'excitatory', 'neuron', 'information', 'storage', 'frequency', 'versu', 'frequency', 'information', 'information', 'tool', 'use', 'information', 'analysi']], [['riemann', 'roch', 'clas', 'field'], ['concept', 'creation', 'network', 'seamles', 'acquisition', 'transfer', 'review', 'convergence', 'cp', 'industry', 'transportation', 'sector', 'impact', 'transportation', 'integration', 'industry', 'cp', 'transportation', 'efficiency', 'safety', 'sustainability', 'framework', 'transportation', 'industry', 'technology', 'integration', 'transportation', 'transportation', 'industry', 'cp', 'integration', 'need', 'encryption', 'security', 'communication', 'exchange', 'transportation', 'infrastructure']], [['map', 'system', 'localization'], ['level', 'authorization', 'security', 'database', 'gap', 'understanding', 'gap', 'world', 'bola', 'level', 'authorization', 'application', 'development', 'tool', 'tool', 'combination', 'analysi', 'level', 'authorization', 'bolaray', 'database', 'identification', 'rate', 'date']], [['gns', 'localization', 'satellite', 'image', 'matching'], ['image', 'classification', 'area', 'computer', 'vision', 'learning', 'image', 'segmentation', 'tumor', 'detection', 'classification', 'accuracy', 'generalization', 'learning', 'image', 'classification', 'method', 'addres', 'model', 'extraction', 'module', 'learning', 'module', 'space', 'inter', 'clas', 'clas', 'los', 'function', 'los', 'triplet', 'los', 'accuracy', 'generalization', 'sampling', 'strategy', 'contrast', 'sample', 'difficulty', 'performance', 'googlenet', 'demonstrate', 'effectivenes', 'los', 'strategy', 'training', 'evaluation', 'model', 'performance', 'method', 'accuracy', 'generalization']], [['vecmaplocnet', 'vision', 'localization', 'vector'], ['article', 'design', 'example', 'number', 'treatment', 'randomization', 'treatment', 'control', 'variety', 'control', 'diamond', 'hainmueller', 'abadie', 'control', 'group', 'treatment', 'treatment', 'analyze', 'control', 'control', 'estimation', 'randomization', 'treatment']], [['vlm', 'nav', 'maple', 'navigation', 'vision', 'vision', 'language', 'model'], ['order', 'element', 'g', 'group', 'g', 'g', 'conjugate', 'gi', 'integer', 'coprime', 'order', 'g', 'determine', 'algebraic', 'group', 'type', 'anbn', 'cn', 'field', 'pgeq', 'gin', 'order', 'semisimple', 'element', 'phi', 'representation', 'g', 'phig', 'eigenvalue']], [['novel', 'framework', 'detection'], ['design', 'development', 'evaluation', 'realization', 'balance', 'rehabilitation', 'bar', 'framework', 'participation', 'information', 'co', 'improvement', 'sensory', 'motor', 'rehabilitation', 'design', 'integration', 'phase', 'muscle', 'activation', 'movement', 'sensation', 'development', 'phase', 'sensory', 'independence', 'input', 'phase', 'distance', 'manipulator', 'actuation', 'load', 'bearing', 'capacity', 'feasibility', 'simulation', 'dof', 'platform', 'design', 'suitability', 'bar', 'framework', 'force', 'time', 'monitoring', 'preparation', 'phase']], [['gns', 'geolocalization', 'uav', 'terrain', 'constraint', 'optimization'], ['map', 'toru', 'bifurcation', 'theory', 'map', 'formation', 'shilnikov', 'consideration', 'toru', 'bifurcation', 'show', 'system', 'toru', 'bifurcation', 'mode', 'strip', 'bifurcation', 'use', 'poincar', 'section', 'method', 'lyapunov', 'construction', 'dimensional', 'parameter', 'continuation', 'newtonraphson', 'method', 'locate']], [['flight', 'initialization'], ['scheme', 'detection', 'ranginglidar', 'point', 'precision', 'scene', 'way', 'focu', 'range', 'imagesri', 'format', 'image', 'compression', 'compression', 'efficiency', 'performance', 'pixel', 'value', 'distribution', 'representationinr', 'compression', 'method', 'point', 'method', 'depth', 'mask', 'patch', 'wise', 'pixel', 'wise', 'inr', 'quantization', 'show', 'method', 'image', 'point', 'ru', 'inr', 'compression', 'reconstruction', 'detection', 'quality', 'latency']], [['dataset', 'baseline', 'algorithm', 'framework', 'localization', 'reference', 'map'], ['vehicle', 'control', 'component', 'cruise', 'control', 'role', 'distance', 'vehicle', 'time', 'th', 'factor', 'distance', 'enhance', 'performance', 'vehicle', 'control', 'vehicle', 'control', 'scheme', 'synthesi', 'time', 'headway', 'csvth', 'model', 'model', 'th', 'function', 'transition', 'function', 'realize', 'capability', 'th', 'dbv', 'performance', 'mpc', 'control', 'controller', 'weight', 'mpc', 'adaptability', 'controller', 'controller', 'simulation', 'environment', 'rationality', 'csvth', 'model', 'simulation', 'model', 'economy', 'vehicle', 'performance', 'comfort']], [['patch', 'attack', 'detection'], ['quantum', 'eigensolver', 'vqe', 'task', 'compute', 'use', 'training', 'time', 'problem', 'convergence', 'quality', 'transfer', 'distance', 'source', 'solution', 'target', 'solution', 'vqe', 'maxcut', 'problem', 'problem', 'size', 'non', 'transfer', 'learning', 'transfer', 'learning', 'training', 'time', 'post', 'training', 'use', 'transfer', 'learning', 'percentage', 'quality', 'time', 'solution', 'advantage', 'trade', 'training', 'effort', 'solution', 'quality']], [['quantization', 'length'], ['model', 'random', 'clas', 'random', 'density', 'order', 'differential', 'http', 'galerkin', 'chebyshev', 'approximation', 'surface', 'element', 'method', 'chebyshev', 'error', 'convergence', 'smoothnes', 'field', 'convergence']], [['primer', 'velocity', 'phase', 'space', 'souriau', 'formalism'], ['algorithm', 'mobka', 'ql', 'mutation', 'scheduling', 'energy', 'mutation', 'enhance', 'solution', 'diversity', 'accelerate', 'convergence', 'model', 'carbon', 'capture', 'system', 'power', 'ga', 'pg', 'thermal', 'wind', 'power', 'energy', 'storage', 'energy', 'efficiency', 'heat', 'power', 'ratio', 'cogeneration', 'system', 'demand', 'control', 'power', 'chp', 'output', 'integration', 'ccspg', 'curtailment', 'methane', 'hydrogen', 'fuel', 'mitigate', 'energy', 'load', 'energy', 'region', 'dispatch', 'system', 'energy', 'efficiency', 'heat', 'power', 'ratio', 'chp', 'energy']], [['quantization', 'length', 'position', 'noncommutativity'], ['intelligence', 'ai', 'role', 'earth', 'science', 'prevalence', 'impact', 'discovery', 'earth', 'emphasi', 'accuracy', 'analysi', 'knowledge', 'regression', 'model', 'kg', 'dsr', 'knowledge', 'proces', 'network', 'kg', 'dsr', 'penman', 'monteith', 'equation', 'surface', 'resistance', 'parameterization', 'parameterization', 'theory', 'surface', 'resistance', 'parameterization', 'future', 'climate', 'role', 'proces', 'paradigm', 'land', 'surface']], [['nature', 'minkowski', 'spacetime', 'behavior'], ['interest', 'field', 'aim', 'ability', 'relu', 'analysi', 'decoder', 'framework', 'encoder', 'nature', 'domain', 'information', 'step', 'approximation', 'analysi', 'world', 'input', 'random', 'noise', 'input', 'encoder', 'therein']], [['pathwise', 'mckean', 'vlasov'], ['spin', 'system', 'permutation', 'pott', 'spin', 'rotation', 'clock', 'phase', 'diagram', 'renormalization', 'group', 'solution', 'order', 'approximation', 'inclusion', 'phase', 'order', 'phase', 'zero', 'temperature', 'order', 'bifurcation', 'temperature', 'phase', 'diagram', 'topology']], [['persistence', 'neutrality', 'replicator'], ['introduce', 'textttgwfast', 'novel', 'code', 'wave', 'generation', 'wave', 'telescope', 'explorer', 'ce', 'use', 'perform', 'network', 'ce', 'run', 'lvk', 'collaboration', 'neutron', 'hole', 'distribution', 'noise', 'ratio', 'snr', 'accuracy', 'reconstruction', 'distance', 'localization', 'distribution', 'accuracy', 'localization', 'distance', 'measurement', 'examine', 'distribution', 'attention', 'dependence', 'choice', 'snr', 'compare', 'literature', 'companion', 'code', 'textttwfpy', 'state', 'art', 'wave', 'textttpython']], [['application', 'database', 'web'], ['climate', 'importance', 'monitoring', 'climate', 'water', 'storage', 'information', 'scale', 'satellite', 'positioning', 'system', 'gravity', 'recovery', 'climate', 'experiment', 'grace', 'use', 'amazon', 'basin', 'gp', 'grace', 'spatio', 'agreement', 'precipitation', 'precipitation', 'evapotranspiration', 'spei', 'severity', 'index', 'dsi', 'grace', 'station', 'station', 'basi', 'identify', 'wet', 'basin', 'technique', 'resolution', 'gp', 'dsi', 'andor', 'grace', 'advantage', 'methodology', 'gp', 'dsi', 'grace', 'dsi', 'novelty', 'term', 'grace', 'gp', 'drought', 'multivariate', 'drought', 'severity', 'index', 'mdsi', 'concept', 'frank', 'series', 'gp', 'grace', 'dsi', 'index', 'ssi', 'river', 'discharge']], [[], ['progress', 'database', 'management', 'basi', 'hardware', 'work', 'building', 'optimization', 'experience', 'automation', 'technique', 'specification', 'code', 'generation', 'result', 'validation', 'conclude', 'case', 'processing']], [['integrity'], ['school', 'summer', 'varenna', 'italy', 'body', 'structure', 'overview', 'emphasi', 'body', 'problem', 'complexity', 'focu', 'model', 'framework', 'language', 'field', 'theory', 'density', 'theory', 'field', 'complexity', 'nucleus']], [['acces', 'control'], ['intelligence', 'ai', 'information', 'ai', 'ai', 'ai', 'ai', 'ai', 'ai', 'generation', 'power', 'recognition', 'information', 'fueling', 'computer', 'vision', 'language', 'processing', 'recommendation', 'time', 'decision', 'reinforcement', 'planning', 'ai', 'intelligence', 'context', 'control', 'world', 'vision', 'self', 'setting', 'training', 'machine', 'consciousnes', 'innovation', 'performance', 'autonomy', 'governance', 'society']], [['level', 'authorization'], ['nash', 'type', 'inequality', 'inequality', 'space', 'space', 'application', 'addres', 'behavior', 'fokker', 'planck', 'space', 'result', 'regularity', 'solution', 'grazing', 'set']], [['dclink', 'constraint'], ['feedback', 'control', 'strategy', 'enhance', 'performance', 'precision', 'motion', 'lead', 'compensator', 'filter', 'tune', 'phase', 'reset', 'nonlinearity', 'order', 'control', 'design', 'phase', 'margin', 'gain', 'gain', 'phase', 'margin', 'control', 'filter', 'frequency', 'design', 'clegg', 'integrator', 'cu', 'order', 'element', 'control', 'strategy', 'case', 'motion', 'stage', 'case', 'control', 'response', 'case', 'control', 'strategy', 'gain', 'element', 'state', 'performance', 'precision', 'disturbance', 'rejection', 'transient', 'response']], [['dependency', 'optimization'], ['quantum', 'eigensolver', 'vqe', 'platform', 'determine', 'term', 'quantum', 'determine', 'ground', 'state', 'wavefunction', 'ritz', 'principle', 'point', 'group', 'symmetry', 'framework', 'treat', 'energy', 'representation', 'spin', 'multiplicity', 'method', 'construction', 'symmetry', 'reference', 'constituent', 'multiplicity', 'operator', 'spin', 'collapse', 'symmetry', 'energy', 'construction', 'pool', 'spin', 'methodology', 'search', 'algorithm', 'symmetry', 'space', 'circuit', 'structure', 'term', 'quantum', 'chemical', 'phenomenon', 'exploration', 'chemical', 'space']], [['auto'], ['gait', 'balance', 'impact', 'independence', 'quality', 'life', 'life', 'expectancy', 'number', 'balance', 'side', 'use', 'rehabilitation', 'tool', 'recover', 'gait', 'balance', 'rehabilitation', 'classification', 'balance', 'rehabilitation', 'review', 'patient', 'perturbation', 'end', 'literature', 'number', 'end', 'rehabilitation', 'balance', 'gait', 'analysi', 'standpoint', 'training', 'mode', 'parallel', 'end', 'effector']], [['query', 'datum', 'generation'], ['phase', 'model', 'renormalization', 'group', 'theory', 'lattice', 'approximate', 'migdalkadanoff', 'procedure', 'phase', 'order', 'parameter', 'permutation', 'symmetry', 'symmetry', 'line', 'disorder', 'line', 'order', 'phase', 'order', 'phase', 'bifurcation', 'point', 'order', 'phase']], [['conformation', 'generation'], ['performance', 'field', 'communication', 'function', 'aperture', 'array', 'design', 'antenna', 'system', 'field', 'beam', 'beamdepth', 'limit', 'array', 'aperture', 'contrast', 'field', 'region', 'aperture', 'number', 'separation', 'dependence', 'array', 'aperture', 'number', 'power', 'law', 'dependence', 'aperture', 'design', 'aperture', 'field', 'communication']], [['drug', 'discovery'], ['algorithm', 'ga', 'generate', 'gait', 'analysi', 'training', 'platform', 'trajectory', 'planning', 'gait', 'pattern', 'simulator', 'robot', 'reference', 'joint', 'torque', 'force', 'analysi', 'method', 'validity', 'method', 'analysi', 'comparison', 'motion', 'capture', 'evaluation', 'motion', 'extremity']], [['intelligence', 'conformation', 'description', 'language'], ['hopping', 'flux', 'aharonov', 'bohm', 'effect', 'non', 'effect', 'observation', 'persistent', 'flux', 'hatano', 'nelson', 'intradimer', 'explore', 'model', 'model', 'disorder', 'random', 'model', 'conduct', 'analysi', 'energy', 'spectrum', 'persistent', 'presence', 'disorder', 'amplification', 'random', 'configuration', 'investigate', 'absence', 'disorder', 'correspondence', 'existence', 'edge', 'condition']], [['graph', 'diffusion', 'model', 'molecule', 'design'], ['boundednes', 'clas', 'degenerate', 'kolmogorov', 'type', 'lie', 'group', 'structure', 'product', 'iteration', 'renormalization', 'formula', 'energy', 'type', 'estimate', 'solution', 'incorporate', 'order', 'divergence', 'theory']], [['space', 'modeling'], ['seobnrvthm', 'accurate', 'waveform', 'model', 'quasi', 'neutron', 'body', 'formalism', 'hole', 'approximant', 'seobnrvhm', 'predecessor', 'seobnrvt', 'order', 'post', 'order', 'time', 'merger', 'relativity', 'merger', 'mode', 'ansatz', 'v', 'predecessor', 'model', 'bn', 'ma', 'geq', 'modot', 'parameter', 'estimation', 'perform', 'bn', 'virgo', 'collaboration', 'gw', 'gw', 'model', 'sacrum', 'nr', 'uncertainty', 'validate', 'model', 'state', 'art', 'bn', 'waveform', 'bn', 'coverage', 'spin', 'foundation', 'development', 'seobnr', 'waveform', 'precession', 'eccentricity', 'virgo', 'kagra', 'collaboration', 'future', 'ground']], [['generation', 'sequence', 'structure', 'diffusion'], ['slip', 'navigation', 'satellite', 'subduction', 'zealand', 'activity', 'term', 'sse', 'displacement', 'gp', 'network', 'inversion', 'filter', 'method', 'slip', 'migration', 'slip', 'acceleration', 'deceleration', 'manawatu', 'slip', 'slip', 'surface', 'displacement', 'kapitus', 'correlation', 'coefficient', 'activity', 'region', 'slip', 'acceleration', 'manawatu', 'slip', 'correlation']], [['conformer', 'generation', 'fragment', 'diffusion'], ['effect', 'view', 'detection', 'structure', 'chart', 'proces', 'parameter', 'phase', 'monte', 'carlo', 'estimation', 'presence', 'chart', 'efficacy', 'sensitivity', 'average', 'performance', 'superiority', 'scheme', 'applicability', 'effectivenes', 'set', 'manufacturing']], [['score', 'structure', 'optimization', 'accurate', 'energy'], ['quantum', 'simulate', 'energy', 'water', 'methane', 'diagonalization', 'sqd', 'qubit', 'agreement', 'space', 'configuration', 'interaction', 'cascus', 'cluster', 'capacity', 'mark', 'progress', 'application', 'quantum', 'chemical', 'way', 'modeling', 'chemical']], [['gadiff', 'graph', 'attention', 'diffusion', 'model'], ['decision', 'model', 'point', 'environment', 'uncertainty', 'savage', 'core', 'decision', 'time', 'belief', 'chamber', 'decision', 'identification', 'model', 'composition', 'echo', 'core', 'belief', 'influence', 'version', 'model', 'identification', 'relate', 'model', 'influence', 'stickines', 'belief', 'society']], [['moltiverse', 'conformer', 'generation'], ['density', 'theory', 'k', 'dft', 'electron', 'density', 'matrix', 'theory', 'rdmft', 'describe', 'field', 'cost', 'density', 'capture', 'correlation', 'exchange', 'correlation', 'capture', 'correlation', 'performance', 'dfa', 'rdmft', 'framework', 'performance', 'dft', 'xc', 'response', 'xc', 'correlation', 'dfa', 'rdmft', 'dft']], [['regression', 'relu'], ['time', 'heterogeneity', 'post', 'inference', 'target', 'group', 'structure', 'gap', 'case', 'panel', 'way', 'heterogeneity', 'machine', 'inference', 'procedure', 'moment', 'theory', 'performance', 'application', 'policy', 'revisit', 'line', 'theory']], [['sobolev', 'norm', 'inconsistency', 'interpolation'], ['healthcare', 'time', 'localization', 'safety', 'efficiency', 'article', 'deepsense', 'healthcare', 'cnn', 'lstm', 'framework', 'resource', 'management', 'enhance', 'field', 'nf', 'iot', 'localization', 'monitoring', 'healthcare', 'feature', 'extraction', 'term', 'memory', 'lstm', 'deepsense', 'healthcare', 'temporal', 'localization', 'accuracy', 'resource', 'management', 'module', 'load', 'resource', 'allocation', 'activity', 'energy', 'efficiency', 'evaluate', 'framework', 'baseline', 'seed', 'activity', 'healthcare', 'localization', 'accuracy', 'energy', 'efficiency', 'latency', 'activity', 'deepsense', 'healthcare', 'solution', 'patient']], [['approximation', 'application', 'regression'], ['kohn', 'sham', 'theory', 'theory', 'k', 'dft', 'density', 'theory', 'rdmft', 'correlation', 'rdmft', 'capture', 'correlation', 'feature', 'combine', 'rdmft', 'correlation', 'correlation', 'convergence', 'basi', 'dependence', 'implementing', 'dft', 'dft', 'treatment']], [['analysi'], ['time', 'use', 'type', 'fact', 'distribution', 'system', 'type', 'power', 'consumption', 'consumer', 'optimization', 'method', 'multus', 'time', 'use', 'price', 'demand', 'response', 'consumer', 'classification', 'model', 'classification', 'model', 'multus', 'type', 'network', 'autoencoder', 'clustering', 'algorithm', 'model', 'power', 'consumption', 'algorithm', 'time', 'use', 'consumer', 'time', 'group', 'algorithm', 'effectivenes', 'adaptability', 'method', 'application', 'example', 'time', 'use', 'tariff', 'optimization', 'distribution', 'network', 'simulation', 'power', 'power', 'company', 'load', 'rate', 'power', 'company', 'addition', 'method', 'tou', 'tariff', 'optimization', 'reduction', 'rate', 'power', 'demand', 'rate', 'power', 'company']], [['random', 'feature', 'information'], ['diffusion', 'succes', 'image', 'generation', 'vision', 'image', 'segmentation', 'image', 'segmentation', 'model', 'interpretability', 'model', 'accuracy', 'situation', 'diffusion', 'model', 'interpretability']], [['approximation', 'radon', 'transform'], ['thesi', 'memory', 'wavelet', 'memory', 'accuracy', 'lgt', 'cdf', 'ma', 'conservation', 'filtering', 'simulation', 'attention', 'performance', 'compression', 'performance', 'trade', 'memory', 'performance', 'bu', 'bandwidth', 'speed', 'performance', 'energy', 'consumption']], [['phase', 'analysi', 'presence'], ['scaling', 'structure', 'computer', 'algorithm', 'quantum', 'eigensolver', 'vqe', 'algorithm', 'compute', 'ground', 'state', 'energy', 'hydrogen', 'helium', 'principle', 'quantum', 'trial', 'wavefunction', 'technique', 'optimization', 'quantum', 'resource', 'energy', 'fock', 'trend', 'number', 'energy', 'decrease', 'percentage', 'error', 'moreover', 'convergence', 'ground', 'state', 'energy', 'hydrogen', 'helium', 'energy', 'expectation', 'value', 'unity', 'state', 'accuracy', 'scalability', 'molecular', 'system', 'chemistry', 'material', 'science', 'computer', 'qubit', 'presence', 'noise', 'require', 'basi', 'qubit', 'chemistry', 'ansatz', 'optimization', 'way', 'calculation']], [['proces', 'monitoring', 'industry', 'industry', 'practice'], ['core', 'solution', 'concept', 'game', 'theory', 'work', 'shapley', 'game', 'purpose', 'fold', 'game', 'unimodularity', 'integrality', 'core', 'demonstrate', 'versatility', 'notion', 'core', 'use', 'investment', 'management', 'game', 'game', 'nature', 'game', 'game', 'agent', 'strategy', 'money', 'investment', 'strategy', 'money', 'investment', 'scenario', 'strategy', 'imputation', 'frameworkof', 'core', 'game', 'graph', 'maximum', 'set', 'problem', 'role', 'game', 'time', 'graph', 'core', 'game', 'shapley', 'characterization', 'core', 'assignment', 'game', 'difference', 'characterization', 'unimodularity', 'integrality']], [['chart', 'novel'], ['demand', 'pork', 'pig', 'health', 'welfare', 'management', 'productivity', 'priority', 'scale', 'pig', 'health', 'detection', 'performance', 'generalization', 'accuracy', 'rgb', 'detection', 'performance', 'brightnes', 'similarity', 'facility', 'dog', 'depth', 'image', 'generation', 'foundation', 'depth', 'anything', 'method', 'information', 'environment', 'foreground', 'depth', 'background', 'region', 'interest', 'rous', 'region', 'rou', 'rgb', 'input', 'color', 'space', 'value', 'saturation', 'background', 'object', 'background', 'information', 'cost', 'cpu', 'gpu', 'detection', 'accuracy', 'ap', 'image', 'generation', 'time', 'processing', 'cpu', 'gpu', 'image', 'generation', 'time', 'depth', 'anything']], [['quality', 'identification', 'gscv', 'rf', 'rfe'], ['production', 'environment', 'life', 'span', 'machine', 'condition', 'maintenance', 'significance', 'performance', 'condition', 'monitoring', 'system', 'system', 'scratch', 'adaptation', 'condition', 'monitoring', 'proces', 'demonstrator', 'vibration', 'sensor', 'classification', 'task', 'identify', 'vibration', 'production', 'medium', 'scale', 'analysi', 'benchmark', 'model', 'network', 'performance', 'relation', 'reference', 'model', 'training', 'production', 'environment', 'model', 'enhance', 'robustnes', 'self', 'training', 'option', 'model', 'interaction', 'medium', 'scale', 'hand', 'self', 'training', 'learning', 'strategy', 'operator', 'label']], [[], ['ml', 'model', 'method', 'initialization', 'training', 'configuration', 'work', 'methodology', 'generate', 'ml', 'methodology', 'generation', 'extension', 'multitask', 'ml', 'system', 'image', 'classification', 'model', 'task', 'system', 'work', 'state', 'connecting', 'condition', 'activation', 'mixture', 'sample', 'router', 'module', 'demonstrate', 'sample', 'parallel', 'boost', 'quality', 'fraction']], [['communication', 'sgd', 'age', 'worker', 'selection'], ['level', 'density', 'time', 'energy', 'bach', 'ga', 'model', 'dp', 'bf', 'gm', 'interaction', 'temperature', 'energy', 'order', 'calculate', 'level', 'density', 'temperature', 'entropy', 'heat', 'capacity', 'cm', 'mc', 'density', 'rotation', 'vibration', 'variation', 'level', 'density', 'temperature', 'heat', 'capacity', 'function', 'excitation', 'energy', 'consideration', 'rotation', 'vibration', 'variation', 'heat', 'capacity', 'function', 'excitation', 'energy', 'pair', 'work', 'discontinuity', 'heat', 'volume', 'excitation', 'cm', 'mev', 'mc', 'transition', 'superfluid', 'state', 'matter']], [['convergence', 'client', 'participation'], ['video', 'method', 'video', 'compression', 'encode', 'video', 'content', 'network', 'video', 'compression', 'model', 'compression', 'issue', 'attempt', 'lottery', 'ticket', 'hypothesi', 'lth', 'sub', 'existence', 'reveal', 'transferability', 'cost', 'training', 'efficiency', 'devise', 'method', 'transferability', 'design', 'cyclic', 'strategy', 'accelerate', 'performance', 'method', 'performance', 'db', 'sparsity', 'e', 'hnerv']], [['superconductivity', 'electron', 'ga', 'irrelevance', 'kohn', 'luttinger', 'mechanism'], ['framework', 'selection', 'moment', 'group', 'moment', 'condition', 'validity', 'method', 'panel', 'number', 'moment', 'group', 'validity', 'moment', 'method', 'lasso', 'regularization', 'gmm', 'estimation', 'estimator', 'classification', 'moment', 'selection', 'consistency', 'distribution', 'post', 'regularization', 'estimator', 'oracle', 'sample', 'performance', 'method', 'carlo', 'simulation', 'experiment', 'method', 'impact', 'productivity', 'migration', 'china']], [['ground', 'state', 'phase', 'diagram', 'leg', 'j', 'ladder'], ['segmentation', 'burden', 'optimization', 'lack', 'clas', 'introduce', 'novel', 'hierarchy', 'method', 'sparsity', 'feature', 'space', 'information', 'granularity', 'structure', 'sparsity', 'transport', 'omh', 'segmentation', 'performance', 'code']], [['time', 'basi', 'impurity', 'model', 'coupling', 'expansion'], ['number', 'k', 'dombi', 'sequence', 'rkann', 'explicit', 'counterexample', 'density']], [['lehmann', 'representation', 'point'], ['text', 'segmentation', 'te', 'task', 'level', 'image', 'level', 'egocentric', 'wearer', 'interference', 'view', 'leverage', 'language', 'image', 'clip', 'model', 'pre', 'view', 'view', 'relation', 'problem', 'hence', 'cognition', 'network', 'ctdn', 'wearer', 'image', 'text', 'cognition', 'module', 'ctm', 'knowledge', 'pre', 'model', 'model', 'cognition', 'foreground', 'module', 'fdm', 'foreground', 'background', 'activation', 'foreground', 'relation', 'te', 'margin']], [['calculation', 'energy', 'field', 'theory', 'minimization'], ['fedavg', 'optimization', 'algorithm', 'convergence', 'client', 'participation', 'client', 'participation', 'cro', 'device', 'battery', 'statu', 'network', 'connectivity', 'participation', 'frequency', 'privacy', 'time', 'result', 'client', 'availability', 'pattern', 'knowledge', 'framework', 'analyze', 'convergence', 'fedavg', 'client', 'participation', 'client', 'sgd', 'analysi', 'client', 'participation', 'convergence', 'rate', 'vanilla', 'fedavg', 'client', 'participation', 'design', 'client', 'sampling']], [['crossover', 'phonon', 'plasmon'], ['environment', 'state', 'respect', 'magnu', 'hamiltonian', 'argument', 'rule', 'show', 'frame', 'function', 'time', 'bohr', 'system', 'modulation', 'frequency', 'frequency', 'laser', 'rydberg', 'corroborate', 'model', 'rydberg', 'order', 'floquet', 'gibb', 'state', 'system', 'state', 'equation', 'modulation']], [['superconductivity', 'wse'], ['element', 'analysi', 'representative', 'volume', 'component', 'machine', 'microstructure', 'property', 'number', 'face', 'volume', 'inclusion', 'algorithm', 'mesh', 'grid', 'box', 'track', 'space', 'accelerate', 'custom', 'inclusion', 'intersection', 'algorithm', 'prevent', 'inclusion', 'area', 'distribution', 'integration', 'propagation', 'method', 'adherence', 'user', 'inclusion', 'neighbor', 'orientation', 'function', 'pair', 'distribution', 'function', 'volume', 'fraction', 'time', 'validation', 'metal', 'matrix', 'cfrp', 'steel', 'agreement', 'fea']], [['rank', 'function', 'field', 'theory'], ['order', 'plant', 'fcop', 'contribution', 'role', 'complex', 'plant', 'system', 'stability', 'robustnes', 'phenomenon', 'transfer', 'function', 'plant', 'structure', 'form', 'order', 'plant', 'iop', 'order', 'plant', 'fop', 'technique', 'order', 'iopd', 'controller', 'analysi', 'plant', 'controller', 'integrator', 'reveal', 'controller', 'phase', 'integrator', 'part', 'state', 'error', 'iop', 'integrator', 'state', 'error', 'time', 'increase', 'phase', 'margin', 'phase', 'crossover', 'frequency', 'order', 'phase', 'crossover', 'frequency', 'iop', 'order', 'modification', 'effect', 'order', 'version', 'order', 'system', 'part', 'case']], [['energy', 'peak', 'particle', 'function', 'electron', 'ga', 'metallic'], ['development', 'non', 'nh', 'wave', 'emergence', 'non', 'skin', 'effect', 'effect', 'winding', 'number', 'energy', 'phenomenon', 'nhse', 'platform', 'system', 'transmission', 'regulation', 'light', 'exploration', 'energy', 'progress', 'property', 'modulation', 'future']], [['graph'], ['review', 'reliability', 'assessment', 'power', 'energy', 'investigation', 'optimization', 'evaluation', 'machine', 'performance', 'reliability', 'analysi', 'examination', 'machine', 'learning', 'time', 'reliability', 'precision', 'review', 'test', 'ml', 'addres', 'reliability', 'evaluation', 'support', 'industry', 'reliability', 'assessment', 'power']], [['proces', 'distribution', 'generalization'], ['show', 'line', 'integer', 'software', 'tool', 'walnut', 'illustrate', 'number', 'oei']], [['causality', 'post', 'training'], ['computer', 'problem', 'hardware', 'creation', 'execution', 'environment', 'tee', 'software', 'environment', 'circumstance', 'host', 'o', 'security', 'integrity', 'software', 'integrity', 'security', 'driven', 'use', 'acces', 'control', 'iot', 'use', 'implementation', 'security', 'tee', 'use', 'analysi', 'help', 'tee', 'community', 'design', 'hardware']], [['graph', 'structure'], ['bifurcation', 'lyapunov', 'order', 'posse', 'property', 'attractor', 'realization', 'possibility', 'bifurcation', 'period', 'neimark', 'sacker', 'example', 'mira', 'map']], [['complexity', 'science', 'help', 'world'], ['attention', 'delamination', 'guarantee', 'majority', 'topology', 'optimization', 'distribution', 'bulk', 'optimization', 'account', 'role', 'material', 'work', 'optimization', 'identification', 'fracture', 'ability', 'structure', 'withstand', 'interface', 'applicability', 'material', 'penalty', 'simp', 'topology', 'optimization', 'structure', 'substrate', 'field', 'delamination']], [['distribution', 'robustnes', 'presence'], ['femtosecond', 'ray', 'electron', 'laser', 'extreme', 'excitation', 'system', 'course', 'duration', 'absorption', 'pulse', 'fluence', 'non', 'ray', 'absorption', 'edge', 'spectroscopy', 'valence', 'excitation', 'level', 'femtosecond', 'rate', 'model', 'evolution', 'system', 'construct', 'absorption', 'emission', 'non', 'absorption', 'auger', 'decay', 'valence', 'band', 'thermalization', 'rate', 'model', 'proces', 'fluence', 'density', 'model', 'agreement', 'fluence', 'redistribution', 'driver', 'absorption', 'vicinity', 'resonance', 'describe', 'fluence', 'dependence', 'capability', 'describe', 'core', 'excitation', 'tool', 'design', 'evaluation', 'future', 'fel', 'development', 'non', 'ray', 'spectroscopy']], [['disco', 'distance', 'correlation'], ['formulation', 'clas', 'monge', 'transportation', 'problem', 'transportation', 'problem', 'cost', 'function', 'consideration', 'time', 'continuation', 'thesi']], [['number', 'theory'], ['interconnection', 'digitalization', 'energy', 'cybersecurity', 'power', 'power', 'defense', 'balance', 'privacy', 'preservation', 'scalability', 'responsivenes', 'fl', 'privacy', 'model', 'training', 'review', 'analysi', 'fl', 'defense', 'power', 'cp', 'threat', 'realworld', 'fl', 'structure', 'synchronization', 'personalization', 'examine', 'privacy', 'privacy', 'secure', 'multiparty', 'computation', 'encryption', 'execution', 'deployment', 'cro', 'layer', 'fl', 'standardization', 'review', 'cro', 'sector', 'collaboration', 'defense', 'cornerstone', 'secure', 'privacy']], [['dombi', 'counterexample', 'density'], ['method', 'calculate', 'self', 'energy', 'field', 'theory', 'dmft', 'instability', 'equation', 'equation', 'optimization', 'problem', 'energy', 'measurement', 'order', 'expansion', 'time', 'quantum', 'monte', 'carlo', 'framework', 'use', 'lehmann', 'representation', 'energy', 'optimization', 'problem', 'number', 'benchmark', 'method', 'bethe', 'lattice']], [['monotone', 'representation'], ['car', 'problem', 'controller', 'comfort', 'safety', 'state', 'response', 'transient', 'response', 'controller', 'cost', 'response', 'comfort', 'safety', 'industry', 'design', 'detail', 'analysi', 'plant', 'stability', 'stability', 'performance', 'loop', 'system', 'selection', 'control', 'efficacy', 'controller', 'driving']], [[], ['multus', 'agent', 'system', 'agent', 'system', 'server', 'optimize', 'system', 'information', 'communication', 'solution', 'resource', 'allocation', 'agent', 'system', 'way', 'computation', 'unit', 'resource', 'share', 'cost', 'cost', 'control', 'population', 'capacity', 'application', 'energy', 'transportation', 'name', 'convergence', 'time', 'approximation', 'example', 'vehicle', 'point', 'allocation', 'efficacy', 'solution']], [['mathmatique'], ['vaccine', 'efficacy', 'arm', 'comparing', 'rate', 'incident', 'infection', 'vaccine', 'hpv', 'hpv', 'cro', 'hpv', 'vaccine', 'hpv', 'v', 'ratio', 'prevalence', 'time', 'trial', 'enrollment', 'compare', 'bivalent', 'hpv', 'vaccine', 'arm', 'costum', 'rica', 'trial', 'vaccine', 'control', 'arm', 'hpv', 'arm', 'trial', 'protocol', 'cohort', 'cu', 'arm', 'v', 'cu', 'arm', 'intention', 'treat', 'cohort', 'cu', 'arm', 'v', 'cu', 'arm', 'number', 'hpv', 'serology', 'statu']], [['dombi', 'counterexample', 'density'], ['approximation', 'regression', 'estimation', 'transformer', 'sequence', 'sequence', 'smoothnes', 'index', 'approximation', 'error', 'p', 'p', 'r', 'depth', 'transformer', 'network', 'number', 'result', 'case', 'p', 'number', 'fnn', 'rnn', 'explicit', 'convergence', 'regression', 'problem', 'dependence', 'time', 'complexity', 'strategy', 'approximation', 'representation', 'theorem', 'show', 'attention', 'layer', 'transformer', 'perform', 'column', 'network', 'sequence', 'sequence', 'hlder', 'interpretability', 'attention']], [['detection', 'generation', 'wave', 'gwfast'], ['information', 'entropy', 'occupation', 'role', 'description', 'correlation', 'density', 'theory', 'dmft', 'rev', 'lett', 'article', 'dmft', 'method', 'energy', 'bond', 'hbr', 'spectroscopic']], [['neutron', 'star', 'merger', 'rate', 'density', 'history', 'wave', 'gamma', 'ray', 'burst'], ['matrn', 'model', 'cornerstone', 'century', 'model', 'analysi', 'approximation', 'theory', 'machine', 'probability', 'theory', 'article', 'matrn', 'journey', 'importance', 'matrn', 'model', 'estimation', 'prediction', 'model', 'position', 'matrn', 'model', 'literature', 'computation', 'spde', 'vecchium', 'likelihood', 'approximation', 'computation', 'model', 'performance', 'compare', 'prediction', 'effect', 'computation', 'sobolev', 'regularity']], [['detectability', 'parameter', 'estimation', 'telescope'], ['matter', 'dm', 'interaction', 'sector', 'thermalise', 'interaction', 'particle', 'wimp', 'dm', 'fimp', 'pfimp', 'pfimp', 'search', 'wimp', 'loop', 'work', 'loop', 'graph', 'fermion', 'vector', 'boson', 'pfimp', 'model', 'model', 'fermion', 'dm', 'singlet', 'interaction', 'conversion', 'interaction', 'search', 'density', 'region', 'model']], [[], ['phase', 'space', 'field', 'inflation', 'jordan', 'frame', 'scalar', 'tensor', 'field', 'friedmann', 'walker', 'framework', 'show', 'inflation', 'master', 'trajectory', 'type', 'point', 'point', 'roll', 'time', 'palatini', 'formalism', 'point', 'structure', 'palatini', 'formalism', 'suitability', 'inflation', 'hand', 'phase', 'phase', 'space', 'roll', 'end', 'inflationary', 'expansion', 'master', 'solution', 'explicit', 'range', 'palatini', 'gravity', 'coleman', 'weinberg', 'correction', 'factor', 'palatini', 'order', 'palatini']], [['detection', 'analysi', 'fidelity', 'space', 'wave', 'antenna'], ['photoabsorption', 'cro', 'quasiparticle', 'amplitude', 'method', 'qfam', 'hartree', 'bogoliubov', 'rhb', 'point', 'interaction', 'pc', 'slo', 'model', 'agreement', 'resonance', 'gdr', 'peak', 'cro', 'lack', 'order', 'body', 'deformation', 'photoabsorption', 'cro', 'photoabsorption', 'cro', 'qfam']], [['distribution'], ['injection', 'threat', 'security', 'stability', 'power', 'risk', 'manipulation', 'instability', 'equipment', 'damage', 'scale', 'analysi', 'detection', 'defense', 'mechanism', 'resilience', 'detection', 'state', 'estimation', 'machine', 'integration', 'hybrid', 'accuracy', 'review', 'quantum', 'term', 'security', 'power', 'cp', 'review', 'attack', 'defense', 'integration', 'landscape', 'cyber']], [['coalescence', 'counting', 'separation'], ['conformation', 'generation', 'molecule', 'task', 'example', 'torsion', 'reconstruct', 'conformation', 'conformation', 'work', 'method', 'los', 'function', 'roto', 'translation', 'permutation', 'symmetric', 'model', 'bond', 'information', 'conformation', 'method', 'geom', 'analysi', 'example', 'homo', 'gap', 'groundtruth', 'addition', 'method', 'method', 'code']], [['environment'], ['generalization', 'discrete', 'lehmann', 'representation', 'point', 'correlation', 'time', 'frequency', 'representation', 'combination', 'time', 'frequency', 'temperature', 'energy', 'cutoff', 'algorithm', 'generate', 'expansion', 'system', 'show', 'form', 'representation', 'matsubara', 'polarization', 'order', 'accuracy', 'collection', 'framework', 'point', 'cost', 'memory', 'footprint']], [['cosmology', 'cro', 'correlation', 'wave', 'galaxy', 'generation', 'survey'], ['analogy', 'theory', 'gauge', 'origami', 'origami', 'space', 'space', 'quot', 'scheme', 'torsion', 'affine', 'space', 'quiver', 'clas', 'structure', 'sheaf', 'define', 'k', 'compute', 'partition', 'function', 'show', 'series', 'equivariant', 'genu', 'space', 'smooth', 'partition', 'function', 'plane', 'partition', 'function']], [['galaxy', 'catalog', 'wave', 'analysi'], ['prompt', 'enhance', 'performance', 'vision', 'language', 'clip', 'downstream', 'prompt', 'phase', 'prompt', 'framework', 'prompt', 'expertise', 'prompt', 'domain', 'knowledge', 'clip', 'teacher', 'model', 'domain', 'prompt', 'tune', 'downstream', 'manner', 'task', 'target', 'play', 'module', 'prompt', 'balance', 'performance', 'inference', 'speed', 'vlm', 'state', 'art', 'method', 'promptsrc', 'caspl', 'improvement', 'base', 'image', 'classification']], [['wave', 'propagation', 'future'], ['work', 'non', 'pt', 'su', 'schrieffer', 'heeger', 'model', 'non', 'pt', 'case', 'reciprocity', 'inter', 'intra', 'cell', 'pt', 'symmetry', 'site', 'locus', 'bulk', 'correspondence', 'bbc', 'interplay', 'dimerization', 'case', 'situation', 'number', 'half', 'integer', 'reciprocity', 'skin', 'effect', 'nature', 'pt', 'case', 'analogue', 'energy', 'spectrum', 'variant', 'number', 'function', 'strength', 'bbc']], [['contribution', 'wave', 'background', 'neutron'], ['phase', 'heisenberg', 'spin', 'glas', 'system', 'spin', 'spin', 'glas', 'system', 'temperature', 'spin', 'glas', 'phase', 'temperature', 'number', 'spin', 'dimension', 'phase', 'dirty', 'magnet', 'furthermore', 'application', 'variety', 'plethora', 'glas', 'phase', 'diagram', 'spin', 'glas', 'phase', 'diagram', 'topology', 'rescaling', 'glas', 'phase', 'diagram', 'renormalization', 'group', 'lattice', 'lattice', 'body', 'strength', 'spin', 'spin', 'glas']], [['matter', 'seobnrvthm', 'body', 'neutron'], ['material', 'behavior', 'result', 'network', 'information', 'material', 'state', 'energy', 'stres', 'evolution', 'scenario', 'advantage', 'work', 'material', 'order', 'tangent', 'operator', 'package', 'model', 'definition', 'collocation', 'equality', 'methodology', 'rate', 'von', 'plasticity', 'model', 'law', 'damage', 'behavior', 'law', 'order', 'demonstrate', 'applicability', 'methodology', 'path', 'dependency', 'scenario', 'damage', 'model', 'interface', 'model', 'fracture', 'grain', 'agreement', 'methodology', 'furthermore', 'effort', 'time']], [[], ['question', 'vqa', 'task', 'content', 'language', 'reason', 'manner', 'transformer', 'model', 'tokenization', 'attention', 'mechanism', 'attention', 'unit', 'focu', 'image', 'step', 'module', 'inference', 'excel', 'reasoning', 'performance', 'vqa', 'v', 'ablation', 'contribution', 'module', 'co', 'attention', 'mechanism', 'analysi', 'attention', 'proces', 'task', 'complexity', 'adaptation', 'transformer', 'reasoning']], [['inference', 'generation', 'wave'], ['generation', 'drug', 'design', 'point', 'interaction', 'ability', 'graph', 'diffusion', 'model', 'molecule', 'design', 'mdmd', 'mdmd', 'capture', 'diffusion', 'proces', 'quality', 'generation', 'generation', 'diverse', 'visualization', 'ability', 'learn', 'domain', 'consistency', 'space', 'mdmd', 'field', 'design']], [['test', 'search', 'wave'], ['attitude', 'problem', 'performance', 'interest', 'performance', 'control', 'scheme', 'problem', 'ppc', 'solution', 'singularity', 'problem', 'state', 'constraint', 'control', 'problem', 'state', 'trajectory', 'singularity', 'avoidance', 'performance', 'control', 'scheme', 'deal', 'mapping', 'error', 'transformation', 'error', 'transformation', 'procedure', 'time', 'constraint', 'constraint', 'strength', 'control', 'instability', 'control', 'problem', 'piece', 'wise', 'reference', 'performance', 'function', 'rpf', 'reference', 'trajectory', 'state', 'control', 'behavior', 'scheme', 'controller', 'time', 'stability', 'technique', 'surface', 'control', 'technique', 'enhance', 'performance', 'analysi', 'simulation', 'control', 'robustnes']], [['reasoning', 'overview'], ['ab', 'initio', 'hamiltonian', 'correlation', 'energy', 'order', 'moller', 'plesset', 'mp', 'perturbation', 'theory', 'electron', 'correlation', 'energy', 'electron', 'density', 'matrix', 'parameter', 'accuracy', 'electron', 'density', 'level', 'density', 'way', 'electron', 'configuration', 'interaction', 'bond', 'dissociation', 'parameter', 'correlation', 'correction', 'energy', 'correlation', 'performance', 'accuracy', 'valence', 'bond', 'theory', 'bond', 'dissociation', 'shell', 'row', 'correlation', 'energy', 'perturbation', 'bde', 'average']], [['transportation', 'review', 'integration', 'industry'], ['investigation', 'utilization', 'scale', 'antenna', 'array', 'elaa', 'terahertz', 'thz', 'band', 'field', 'transportation', 'scheme', 'system', 'performance', 'surface', 'ri', 'field', 'vehicle', 'uav', 'field', 'beam', 'pattern', 'depth', 'scheme', 'ri', 'uav', 'uav', 'radiation', 'range', 'energy', 'radiu', 'gain', 'ri', 'structure', 'gain', 'comparison', 'scheme', 'scheme', 'reference', 'distance', 'addition', 'feasibility', 'ri', 'gain', 'improve', 'system', 'performance', 'simulation', 'scheme', 'scheme', 'reference', 'distance']], [['question', 'choice'], ['spin', 'ground', 'state', 'energy', 'state', 'space', 'magnitude', 'spin', 'component', 'problem', 'penalty', 'enforce', 'calculation', 'penalty', 'magnitude', 'time', 'evolution', 'time', 'evolution', 'extrmspin', 'procedure', 'quantum', 'algorithm', 'ground', 'state', 'method', 'step', 'prepare', 'magnitude', 'state', 'step', 'post', 'processing', 'ground', 'state', 'number', 'penalty', 'ring', 'method', 'reduction', 'gate', 'complexity', 'usefulnes']], [['building', 'trustworthy', 'multimodal', 'review', 'fairnes', 'transparency', 'vision', 'language'], ['volt', 'var', 'optimization', 'maintaining', 'secure', 'voltage', 'power', 'balance', 'power', 'integration', 'energy', 'variability', 'intermittency', 'cause', 'voltage', 'vvo', 'optimization', 'algorithm', 'lack', 'time', 'adaptability', 'power', 'flow', 'distribution', 'guarantee', 'number', 'voltage', 'power', 'reinforcement', 'framework', 'importance', 'actor', 'learner', 'architecture', 'impala', 'vvo', 'power', 'flow', 'state', 'representation', 'reward', 'function', 'agent', 'control', 'power', 'flow', 'drl', 'application', 'scalability', 'time', 'decision', 'reduction', 'time', 'bu', 'system', 'distribution', 'feeder', 'solution', 'voltage', 'power', 'network', 'vvo', 'solution', 'power', 'penetration']], [['knowledge', 'framework'], ['topologystructure', 'drug', 'discovery', 'graph', 'gnn', 'framework', 'geometric', 'drug', 'role', 'modeling', 'review', 'overview', 'drug', 'discovery', 'property', 'prediction', 'screening', 'generation', 'knowledge', 'graph', 'construction', 'synthesi', 'planning', 'attention', 'gnn', 'uncertainty', 'quantification', 'graph', 'learning', 'multus', 'task', 'pre', 'training', 'review', 'gnn', 'world', 'drug', 'discovery', 'discussion', 'future']], [['question'], ['bulk', 'correspondence', 'hold', 'non', 'model', 'dimerization', 'value', 'eigenspectrum', 'model', 'bulk', 'correspondence', 'case', 'case', 'edge', 'energy', 'chain', 'limit', 'topology', 'spectrum', 'mathcalpt', 'case', 'model', 'limit']], [['transformer', 'question'], ['bound', 'state', 'drug', 'discovery', 'design', 'proteinligand', 'space', 'work', 'protocol', 'generation', 'biasing', 'force', 'eabf', 'algorithm', 'radiu', 'gyration', 'landscape', 'molecule', 'moltiverse', 'accuracy', 'quality', 'software', 'rdkit', 'conforge', 'balloon', 'icon', 'conformator', 'platinum', 'diverse', 'drug', 'analysi', 'conformer', 'generation', 'improvement', 'evaluation', 'flexibility', 'accuracy', 'algorithm', 'range', 'drug', 'discovery', 'representation', 'flexibility']], [['word', 'question'], ['integration', 'operation', 'control', 'distribution', 'voltage', 'stability', 'voltage', 'control', 'algorithm', 'control', 'mfac', 'control', 'time', 'power', 'voltage', 'coordination', 'power', 'output', 'safety', 'communication', 'network', 'topology', 'method', 'linearization', 'voltage', 'control', 'distribution', 'time', 'communication', 'network', 'model', 'algorithm', 'voltage', 'control', 'time', 'control', 'scenario', 'power', 'system', 'robustnes', 'algorithm', 'operating']], [['question', 'language'], ['device', 'mobility', 'scale', 'antenna', 'angle', 'arrival', 'information', 'localization', 'mobility', 'field', 'channel', 'range', 'problem', 'develop', 'novel', 'field', 'localization', 'architecture', 'motion', 'trajectory', 'channel', 'state', 'information', 'csi', 'antenna', 'channel', 'reciprocity', 'multiply', 'csi', 'downlink', 'csi', 'phase', 'stage', 'localization', 'line', 'multipath', 'multus', 'scale', 'scheme', 'estimation', 'aoa', 'distance', 'path', 'addition', 'range', 'aoa', 'accuracy', 'system', 'environment', 'simulation', 'test', 'field', 'localization', 'system', 'channel', 'localization', 'accuracy']], [['language', 'processing', 'analysi', 'busines', 'intelligence'], ['promising', 'relativity', 'gr', 'challenge', 'standard', 'gw', 'chimera', 'framework', 'inference', 'gravity', 'population', 'estimate', 'likelihood', 'analysi', 'generation', 'parameter', 'propagation', 'model', 'textttchimera', 'forecast', 'propagation', 'virgo', 'kagra', 'hole', 'value', 'catalog', 'population', 'catalog', 'size', 'propagation', 'population', 'precision', 'precision', 'h', 'xi', 'case', 'redshift', 'importance', 'future', 'spectroscopic', 'power', 'standard']], [['action', 'recognition', 'reasoning'], ['representation', 'inr', 'video', 'compression', 'field', 'video', 'compression', 'resolution', 'method', 'video', 'information', 'network', 'post', 'network', 'compression', 'integrate', 'compression', 'implicit', 'representation', 'end', 'end', 'framework', 'representation', 'compression', 'paradigm', 'latent', 'code', 'representation', 'video', 'compression', 'feature', 'synthesi', 'network', 'entropy', 'network', 'stage', 'training', 'proces', 'lnerv', 'compression', 'video', 'complexity', 'compression', 'decompression', 'lnerv']], [['language', 'reconstruction'], ['stain', 'normalization', 'step', 'segmentation', 'classification', 'performance', 'computer', 'diagnosi', 'cad', 'progress', 'domain', 'stain', 'normalization', 'vision', 'transformer', 'model', 'architecture', 'resolution', 'performance', 'stain', 'normalization', 'task', 'key', 'concept', 'utilization', 'swin', 'transformer', 'content', 'range', 'model', 'key', 'stain', 'swin', 'block', 'resstainswin', 'swin', 'transformer', 'block', 'stb', 'resolution', 'architecture', 'level', 'stb', 'block', 'performance', 'stainswin', 'model', 'state', 'art', 'histopathology', 'dataset', 'stainswin', 'margin', 'ssim', 'rmse', 'model', 'ssim', 'rmse', 'performance', 'miccai', 'improvement', 'segmentation', 'accuracy', 'reduction', 'stain', 'color', 'variation', 'method', 'ability', 'performance', 'color']], [['cosection', 'localization', 'quot', 'scheme', 'mathrmquotlsmathcale'], ['su', 'schrieffer', 'model', 'entrant', 'phase', 'transition', 'analysi', 'space', 'number', 'entrant', 'phase', 'phase', 'transition', 'insulator', 'phase', 'anderson', 'insulator', 'phase', 'entrant', 'phenomenon', 'anderson', 'insulator', 'phase', 'anderson', 'insulator', 'phase', 'phase', 'correspond', 'modulation', 'entrant', 'phase', 'bulk', 'gap', 'su', 'schrieffer', 'heeger', 'waveguide', 'ion', 'phase']], [['euler'], ['time', 'time', 'represent', 'novel', 'time', 'symmetry', 'formation', 'tqc', 'phase', 'quantum', 'chain', 'model', 'field', 'itf', 'demonstrate', 'robust', 'tc', 'respond', 'frequency', 'analysi', 'phase', 'magnetization', 'presence', 'interaction', 'diagonalization', 'chain', 'length', 'tqc', 'realization', 'tqc', 'investigation']], [['murphy', 'law', 'scheme'], ['flip', 'flop', 'dipole', 'dipole', 'interaction', 'ion', 'mechanism', 'relaxation', 'hyperfine', 'mechanism', 'rate', 'relaxation', 'microscopic', 'model', 'flip', 'ion', 'environment', 'ion', 'orientation', 'structure', 'ion', 'flop', 'rate', 'relaxation', 'sum', 'rise', 'distribution', 'rate', 'employ', 'model', 'calculate', 'flip', 'flop', 'population', 'decay', 'ground', 'state', 'hyperfine', 'k', 'method', 'measure', 'spectrum', 'rate', 'work', 'effect', 'field', 'flip', 'field', 'mt']], [['gauge', 'origami'], ['deformation', 'excitation', 'transition', 'strength', 'framework', 'approximation', 'rpa', 'deal', 'particle', 'hole', 'work', 'framework', 'impact', 'deformation', 'spin', 'isospin', 'ground', 'state', 'hartree', 'bogoliubov', 'rhb', 'model', 'point', 'energy', 'density', 'exchange', 'channel', 'quasiparticle', 'rpa', 'pnrqrpa', 'response', 'limit', 'spin', 'isospin', 'gamow', 'teller', 'gt', 'spin', 'dipole', 'sd', 'shell', 'gt', 'deformation', 'fragmentation', 'strength', 'function', 'mechanism', 'fragmentation', 'strength', 'momentum', 'shape', 'prolate', 'oblate', 'fragmentation', 'structure', 'strength', 'shape', 'pnrqrpa', 'work', 'deformation', 'interaction', 'betum', 'decay', 'electron', 'capture']], [[], ['aim', 'understand', 'relation', 'hamilton', 'jacobi', 'equation', 'field', 'hamilton', 'jacobi', 'equation', 'equation', 'space', 'vector', 'procedure', 'spacetime', 'hamilton', 'jacobi', 'equation', 'gaus', 'law', 'constraint', 'hamilton', 'jacobi', 'form', 'analysi', 'consideration', 'limit', 'connection', 'quantization', 'field', 'theory', 'formalism', 'time', 'dimension', 'quantization', 'weyl', 'formulation', 'space', 'time']], [['framework', 'control', 'synthesi', 'safety', 'guarantee'], ['correlation', 'pairwise', 'case', 'pairwise', 'advance', 'cost', 'way', 'learning', 'framework', 'task', 'example', 'flexibility', 'type', 'feedback', 'userannotator', 'adaptation', 'correlation', 'query', 'strategy', 'robustnes', 'noise', 'addition', 'number', 'query', 'demonstrate', 'effectivenes', 'framework', 'query']], [['framework', 'safety', 'constraint'], ['work', 'chain', 'spin', 'rydberg', 'density', 'matrix', 'renormalization', 'group', 'dmrg', 'technique', 'particle', 'magnetization', 'quantum', 'body', 'range', 'string', 'emergence', 'robustnes', 'haldane', 'phase', 'phase', 'spin', 'quantum', 'algorithm', 'machine', 'simulate', 'ground', 'state', 'system', 'agreement', 'diagonalization', 'dmrg']], [['experimentation', 'implementation', 'attack', 'resilience', 'mechanism'], ['analyze', 'ground', 'state', 'energy', 'box', 'impurity', 'particle', 'body', 'point', 'coupling', 'ground', 'state', 'energy', 'polaron', 'energy', 'chevy', 'energy', 'solution', 'equation', 'fermi', 'ga', 'energy', 'body', 'point', 'interaction', 'error', 'limit']], [['availability', 'threshold'], ['change', 'detection', 'scd', 'change', 'detection', 'coverland', 'use', 'change', 'information', 'concernful', 'progress', 'scd', 'integrity', 'article', 'transformer', 'network', 'dmctnet', 'network', 'information', 'dmctnet', 'vision', 'foundation', 'knowledge', 'representation', 'remote', 'feature', 'aggregator', 'module', 'decoder', 'change', 'information', 'change', 'volume', 'model', 'intersection', 'union', 'change', 'landsat', 'scd']], [['safety', 'resilient', 'control'], ['progress', 'theory', 'quantum', 'entanglement', 'quantum', 'state', 'interest', 'problem', 'existence', 'bound', 'entanglement', 'thesi', 'characterization', 'bipartite', 'entanglement', 'separability', 'transpose', 'transpose', 'ppt', 'topic', 'detection', 'entanglement', 'majority', 'language', 'thesi', 'detection']], [['resilience', 'index', 'safety', 'analysi'], ['coordination', 'power', 'ga', 'convex', 'weymouth', 'equation', 'privacy', 'protection', 'compatibility', 'addres', 'cooperation', 'mechanism', 'electricity', 'ga', 'equation', 'state', 'space', 'transition', 'section', 'method', 'gsm', 'weymouth', 'equation', 'convex', 'ieg', 'operation', 'model', 'programming', 'cqp', 'solution', 'proces', 'burden', 'incentive', 'decomposition', 'privacy', 'protection', 'value', 'benefit', 'allocation', 'cooperation', 'mechanism', 'situation', 'energy', 'information', 'exchange', 'accuracy']], [['prediction', 'non', 'skin', 'effect', 'atom'], ['field', 'time', 'applicability', 'scale', 'presence', 'quantum', 'coherence', 'framework', 'development', 'efficient', 'quantum', 'control', 'state', 'art', 'experimental', 'guide', 'term', 'progress']], [['control', 'mechanism'], []], [['effect'], ['sheaf', 'rank', 'r', 'surface', 'mathrmquotlsmathcale', 'length', 'l', 'coherent', 'sheaf', 'rank', 'generalization', 'hilbert', 'scheme', 'l', 'intersection', 'theory', 'scheme', 'curve', 'use', 'cosection', 'localization', 'clas', 'mathrmquotlsmathcale', 'l', 'clas', 'mathrmquotlcmathcalevertcsubsetmathrmquotlsmathcale', 'prove', 'structure', 'euler', 'r']], [['spin', 'orbit', 'dispersion', 'relation', 'einstein'], ['integration', 'generation', 'distribution', 'network', 'power', 'system', 'control', 'equipment', 'capability', 'manage', 'point', 'control', 'voltage', 'stability', 'volt', 'watt', 'vw', 'volt', 'var', 'vv', 'stability', 'distribution', 'pv', 'system', 'integration', 'medium', 'voltage', 'distribution', 'system', 'python', 'voltage', 'pv', 'system', 'output', 'capacity']], [['nonlinearity', 'tame'], ['network', 'network', 'dnn', 'recurrent', 'network', 'rnn', 'term', 'memory', 'network', 'lstm', 'zone', 'parameter', 'carbon', 'nanotube', 'complexity', 'parameter', 'acquisition', 'nanoparticle', 'bilinear', 'czm', 'model', 'prediction', 'target', 'model', 'carbon', 'nanotube', 'filler', 'simulation', 'proces', 'rnn', 'lstm', 'czm', 'load', 'displacement', 'los', 'analysi', 'indicator', 'comparison', 'k', 'validation', 'rnn', 'lstm', 'prediction', 'accuracy', 'performance', 'dnn', 'model', 'accuracy', 'model', 'model', 'rnn', 'lstm', 'prediction', 'accuracy', 'recognition', 'ability', 'time', 'series', 'recognition', 'czm', 'application']], [['localization'], ['change', 'detection', 'scd', 'field', 'r', 'community', 'contribution', 'observation', 'multitask', 'network', 'architecture', 'change', 'detection', 'bcd', 'sub', 'task', 'segmentation', 's', 'sub', 'resolution', 'path', 'methodology', 'encoding', 'resolution', 'encoder', 'structure', 'bt', 'hrscd', 'framework', 'shallow', 'module', 'bifam', 'imbue', 'feature', 'fusion', 'shallow', 'module', 'resolution', 'difference', 'extraction', 'hrde', 'resolution', 'enhance', 'precision', 'change', 'boost', 's', 'sub', 'accuracy', 'bcd', 'sub', 'task', 'state', 'art', 'scd']], [['photonic', 'band'], ['failure', 'management', 'service', 'signature', 'storage', 'assumption', 'corrupt', 'number', 'network', 'assumption', 'system', 'solution', 'viz', 'reboot', 'framework', 'groundhog', 'resiliency', 'threshold', 'system', 'device', 'network', 'groundhog', 'number', 'availability', 'system', 'framework', 'multiple', 'threshold', 'cryptosystem', 'tc', 'encryption', 'system', 'dise', 'boneh', 'lynn', 'shacham', 'system', 'fact', 'groundhog', 'cryptography', 'demonstrate', 'simpler', 'protocol', 'fact', 'protocol', 'security', 'reviewer', 'conjunction', 'groundhog', 'container', 'framework', 'combine', 'groundhog', 'system', 'case', 'world', 'dise', 'bl', 'passaround', 'show', 'groundhog', 'guarantee', 'availability', 'performance', 'tc', 'schemeswhile', 'explain', 'reasoning']], [['skin', 'effect'], ['matrix', 'inverse', 'problem', 'solution', 'order', 'system', 'problem', 'generalization', 'inverse', 'problem']], [['order', 'variation', 'change', 'time', 'series', 'motion'], ['multus', 'power', 'demand', 'supply', 'framework', 'model', 'reinforcement', 'island', 'energy', 'system', 'response', 'shortage', 'freshwater', 'addition', 'introduction', 'seawater', 'desalination', 'transmission', 'structure', 'transmission', 'hst', 'essence', 'problem', 'combination', 'output', 'timing', 'control', 'problem', 'decision', 'solution', 'framework', 'reinforcement', 'reinforcement', 'interaction', 'environment', 'prediction', 'multus', 'simulation', 'scheduling', 'framework', 'multus', 'power', 'demand', 'supply', 'performance', 'time', 'efficiency', 'addition', 'hst', 'model', 'exploration', 'utilization', 'efficiency', 'island', 'freshwater']], [['random'], ['nonuniform', 'network', 'initialization', 'function', 'regression', 'random', 'feature', 'initialization', 'addres', 'activation', 'softplu', 'use', 'analysi', 'sparse', 'representation', 'representation', 'space', 'corresponding', 'model', 'function', 'input', 'performance', 'feature']], [['time', 'series', 'image', 'phase', 'step'], ['representation', 'video', 'network', 'video', 'methodology', 'video', 'difficulty', 'spatial', 'motion', 'bia', 'network', 'frequency', 'hf', 'rate', 'frequency', 'lf', 'snerv', 'enhance', 'video', 'frequency', 'wavelet', 'transform', 'dwt', 'video', 'lf', 'hf', 'issue', 'balance', 'compactnes', 'encode', 'decoder', 'resolution', 'fusion', 'unit', 'frequency', 'restorer', 'hfr', 'backbone', 'facilitate', 'representation', 'snerv', 'video', 'extension', 'frequency', 'decomposition', 'domain', 'lf', 'network', 'sampling', 'reconstruction', 'field', 'video']], [['magnitude', 'variability', 'pattern', 'analysi'], ['cp', 'architecture', 'cyber', 'resilient', 'example', 'byzantine', 'fault', 'bft', 'safety', 'cp', 'cyber', 'use', 'timing', 'safety', 'framework', 'represent', 'bft', 'cyber', 'construct', 'hybrid', 'system', 'framework', 'control', 'policy', 'control', 'policy', 'validate', 'framework', 'case', 'control', 'demonstrate', 'safety', 'system']], [['change', 'detection'], ['complexity', 'digitalization', 'power', 'power', 'cp', 'cyber', 'market', 'attack', 'reconnaissance', 'manipulation', 'disruption', 'response', 'review', 'target', 'defense', 'mtd', 'paradigm', 'power', 'cp', 'security', 'multus', 'domain', 'mtd', 'randomization', 'topology', 'reconfiguration', 'market', 'rule', 'variability', 'control', 'mode', 'switchingand', 'attacker', 'stability', 'theloop', 'orchestration', 'monitoring', 'decision', 'support', 'coordinate', 'mtd', 'deployment', 'twin', 'validation', 'world', 'deployment', 'sector', 'collaboration', 'mtd', 'resilient', 'security']], [['language', 'antipersistent'], ['language', 'ability', 'perform', 'planning', 'evaluate', 'planning', 'variety', 'benchmark', 'feasibility', 'optimality', 'generalizability', 'example', 'example', 'constraint', 'decision', 'management', 'preview', 'task', 'state', 'pilot', 'memory', 'management', 'decision', 'generalization', 'planning']], [['information', 'brain'], ['article', 'relation', 'basi', 'minimum', 'estimate', 'measure', 'distribution', 'minimum', 'minimum']], [[], ['compute', 'euler', 'vector', 'form', 'quot', 'rank', 'vector', 'bundle', 'rank']], [['traction', 'separation', 'network'], ['car', 'behavior', 'backstepping', 'control', 'strategy', 'velocity', 'distance', 'control', 'model', 'absmcm', 'headway', 'model', 'vdhm', 'vehicle', 'vehicle', 'vehicle', 'infrastructure', 'information', 'car', 'model', 'factor', 'vehicle', 'acceleration', 'car', 'cruise', 'control', 'law', 'distance', 'diagram', 'model', 'traffic', 'flow', 'intelligent', 'driver', 'model', 'idm', 'baseline', 'compare', 'analyze', 'traffic', 'capacity', 'mcf', 'absmcm', 'traffic', 'flow', 'density', 'evolution', 'vehicle', 'control', 'strategy', 'simulation', 'flow', 'headway', 'distance', 'control', 'strategy', 'vissim', 'efficiency', 'traffic']], [['material'], ['multiple', 'input', 'output', 'scale', 'antenna', 'array', 'increase', 'spectrum', 'efficiency', 'field', 'capacity', 'user', 'multus', 'user', 'array', 'field', 'incidence', 'cell', 'benefit', 'field', 'symmetry', 'array', 'provide', 'uniform', 'field', 'region', 'field', 'relationship', 'model', 'field', 'beamforming', 'technique', 'uca', 'time', 'analysi', 'field', 'provide', 'field', 'region', 'distance', 'property', 'ring', 'codebook', 'field', 'region', 'addition', 'uca', 'field', 'direction', 'improvement', 'multus', 'user', 'capacity', 'simulation', 'feasibility', 'uca', 'field', 'field', 'region']], [['recurrent', 'network', 'rnn', 'term', 'memory', 'network', 'lstm', 'zone', 'law', 'carbon', 'nanotube', 'nano', 'silver'], ['knowledge', 'distillation', 'mechanism', 'teacher', 'model', 'student', 'model', 'transfer', 'model', 'student', 'proces', 'training', 'task', 'student', 'model', 'novel', 'framework', 'information', 'flow', 'knowledge', 'distillation', 'cifd', 'rate', 'distortion', 'module', 'rdm', 'layer', 'information', 'rate', 'teacher', 'assistant', 'model', 'train', 'operate', 'teacher', 'level', 'input', 'feature', 'information', 'rate', 'bottleneck', 'rdm', 'information', 'bottleneck', 'module', 'student', 'model', 'regularization', 'presence', 'number', 'rdm', 'state', 'art', 'imagenet', 'show', 'improvement', 'clip', 'image', 'text', 'dataset', 'distillation', 'zero', 'shot', 'classification', 'zero', 'shot', 'image', 'text', 'retrieval']], [['review', 'behavior'], ['change', 'detection', 'cd', 'change', 'image', 'pair', 'role', 'diverse', 'world', 'network', 'feature', 'difference', 'change', 'map', 'influence', 'quality', 'feature', 'difference', 'cd', 'perspective', 'optimize', 'feature', 'difference', 'highlight', 'module', 'difference', 'idet', 'range', 'information', 'transformer', 'feature', 'difference', 'contrast', 'feature', 'difference', 'refinement', 'multus', 'scale', 'idet', 'change', 'detection', 'feature', 'difference', 'fusion', 'strategy', 'combine', 'cd', 'method', 'state', 'art', 'application', 'feature', 'difference', 'idet']], [['crack', 'tip', 'zone'], ['article', 'time', 'network', 'structure', 'question', 'quantum', 'property']], [['model', 'history', 'damage', 'ma', 'diffusion'], ['question', 'vqa', 'image', 'adaptation', 'choice', 'question', 'mcq', 'refine', 'accuracy', 'applicability', 'question', 'stem', 'set', 'mcq', 'model', 'context', 'correct', 'performance', 'multiclas', 'classification', 'task', 'hyperparameter', 'performance', 'vqa', 'analysi', 'reasoning', 'world', 'vqa', 'application']], [['delamination'], ['progress', 'question', 'image', 'disease', 'diagnosi', 'accuracy', 'expense', 'pathway', 'decision', 'text', 'chain', 'novel', 'preference', 'region', 'level', 'attention', 'knowledge', 'vision', 'cot', 'vision', 'language', 'model', 'r', 'dataset', 'vt', 'cot', 'rationale', 'generation', 'precise', 'vqa', 'state', 'art', 'performance', 'performance', 'interpretability']], [['impact', 'rock', 'matrix', 'seepage', 'surface', 'restoration', 'layer', 'leshan', 'giant', 'buddha'], ['particle', 'model', 'field', 'potential', 'chapter', 'overview', 'particle', 'motion', 'realization', 'framework', 'shell', 'model', 'density', 'particle', 'motion', 'particle', 'shell', 'structure', 'structure', 'landscape', 'existence', 'superdeformation', 'spin', 'briefly', 'latter', 'particle']], [['peak', 'tensile', 'stres', 'concrete', 'size', 'hybrid', 'driven'], ['wave', 'background', 'sgwb', 'merger', 'neutron', 'collapse', 'merger', 'remnant', 'hole', 'remnant', 'amount', 'energy', 'account', 'contribution', 'sgwb', 'model', 'postmerger', 'emission', 'show', 'time', 'state', 'power', 'rm', 'khz', 'range', 'distinct', 'dimensionles', 'gw', 'energy', 'density', 'omegarm', 'gw', 'simeq', 'discus', 'detectability', 'sgwb', 'generation', 'explorer', 'show', 'noise', 'ratio', 'foreground', 'lifetime', 'detection', 'frequency', 'part', 'sgwb', 'offering', 'postmerger', 'matter']], [['solution', 'material', 'pinn'], ['band', 'attention', 'present', 'connection', 'topology', 'analysi', 'band', 'design', 'eigenmode', 'band', 'frequency', 'plane', 'effect', 'skin', 'effect', 'overview', 'band', 'treatment', 'band']], [['inversion', 'extract', 'traction', 'separation', 'material'], ['approximation', 'method', 'clas', 'random', 'clas', 'random', 'laplace', 'beltrami', 'operator', 'approximation', 'approximation', 'series', 'chebyshev', 'approximation', 'scheme', 'random', 'convergence', 'galerkin', 'approximation', 'convergence', 'chebyshev', 'approximation']], [['determination', 'traction', 'separation', 'analysi', 'zone', 'model', 'peeling', 'analysi'], ['structure', 'perturbation', 'theory', 'flavor', 'sector', 'branching', 'dalitz', 'ma', 'spectrum', 'transition', 'form', 'factor', 'vector', 'meson', 'dominance', 'model', 'dsast', 'dastpm', 'dastpm', 'dsastpm', 'dsastpm', 'dsastpm']], [['microscopic', 'model', 'spin', 'flip', 'flop', 'earth', 'ion'], ['work', 'gradient', 'regularity', 'theory', 'clas', 'fokker', 'planck', 'pointwise', 'spirit', 'theory', 'regularity', 'fokker', 'planck', 'divergence', 'form']], [['dalitz'], ['development', 'energy', 'complexity', 'distribution', 'voltage', 'distribution', 'observability', 'load', 'network', 'time', 'voltage', 'control', 'lvdn', 'challenge', 'awarenes', 'sac', 'voltage', 'awarenes', 'control', 'network', 'perception', 'regulation', 'actor', 'sac', 'algorithm', 'voltage', 'control', 'time', 'responsivenes', 'accuracy', 'simulation', 'method', 'robustnes', 'convergence', 'lvdn', 'voltage', 'violation']], [['vector', 'boson', 'pee'], ['vision', 'language', 'technique', 'vision', 'language', 'web', 'scale', 'shot', 'performance', 'domain', 'generalization', 'body', 'knowledge', 'downstream', 'survey', 'generalization', 'vlm', 'prompt', 'parameter', 'feature', 'category', 'transfer', 'era', 'vlm', 'generalization', 'performance', 'survey', 'date', 'language', 'example', 'deepseek', 'vl', 'vision', 'language', 'generalization', 'survey', 'landscape', 'future', 'multimodal']], [['state', 'quantum', 'eigensolver', 'spin'], ['lensing', 'analysi', 'galaxy', 'cluster', 'z', 'moment', 'shape', 'broadband', 'r', 'shape', 'measurement', 'moment', 'measurement', 'moment', 'algorithm', 'noise', 'ratio', 'error', 'use', 'phosim', 'pipeline', 'ma', 'agreement', 'mode', 'x', 'ray', 'feasibility', 'scale', 'structure', 'universe', 'portion', 'cluster', 'bimodal', 'ma', 'distribution', 'orientation', 'ray', 'discus', 'cluster', 'show', 'stage', 'merger']], [['spin', 'ground', 'state', 'preparation', 'quantum', 'algorithm'], ['generalize', 'notion', 'periodicity', 'kind', 'pseudoperiodicity', 'manner', 'answer', 'exponent', 'problem', 'word', 'pseudoperiodic', 'size', 'show']], [['qubit', 'chemistry', 'quantum', 'downfolding'], ['time', 'series', 'method', 'idea', 'time', 'series', 'image', 'space', 'term', 'autoregression', 'term', 'time', 'work', 'image', 'time', 'series', 'attention', 'scheme', 'frequency', 'mse', 'model', 'min', 'value', 'pattern', 'model', 'convergence', 'rate', 'volatility', 'accuracy', 'level', 'image', 'representation', 'time', 'series', 'information', 'efficient', 'time', 'series']], [['determination', 'symmetry', 'quantum', 'eigensolver', 'framework'], ['purpose', 'program', 'rnn', 'matrix', 'learn', 'rnn', 'analysi', 'functionalist', 'functionality', 'output', 'permutation', 'weight', 'space', 'layer', 'rnn', 'functionalist', 'information', 'rnn', 'rnn', 'framework', 'generate', 'behavior', 'release', 'model', 'zoo', 'representation', 'clas', 'mnist', 'emulation', 'self', 'learning', 'technique', 'rnn', 'downstream', 'task', 'rnn', 'superiority']], [['parameter', 'problem'], ['date', 'galaxy', 'image', 'profile', 'influence', 'galaxy', 'characterization', 'approximation', 'shear', 'calibration', 'quality', 'survey', 'demand', 'consideration', 'galaxy', 'deep', 'learning', 'method', 'create', 'network', 'wavelet', 'transform', 'learn', 'point', 'spread', 'function', 'hst', 'galaxy', 'instrument', 'vi', 'noise', 'convolution', 'generation', 'galaxy', 'model', 'quantify', 'bia', 'galaxy', 'measurement', 'fit', 'shape', 'measurement', 'algorithm', 'bia', 'difference', 'order', 'index', 'distribution', 'detection', 'bia', 'image', 'difference', 'shape', 'measurement', 'method', 'stage']], [['quantum', 'estimation', 'spectrum'], ['detection', 'patch', 'perturbation', 'detection', 'evasion', 'patch', 'generation', 'imagery', 'patch', 'generation', 'attack', 'detection', 'camera', 'perspective', 'distance', 'brightnes', 'accuracy', 'detector', 'visdrone', 'dataset', 'feasibility', 'succes', 'rate', 'box', 'addition', 'patch', 'dnn', 'attack', 'succes', 'box']], [['application', 'quantum', 'eigensolver', 'ground', 'state', 'calculation', 'hydrogen', 'helium'], ['attention', 'polarize', 'response', 'information', 'quality', 'disagreement', 'range', 'someone', 'backfire', 'decision', 'maker', 'world', 'information', 'expectation', 'quality', 'chamber', 'credibility']], [['simulation', 'system', 'transition', 'quantum'], ['energy', 'location', 'group', 'welfare', 'energy', 'regulate', 'number', 'number', 'energy', 'energy', 'community', 'community', 'energy', 'photovoltaic', 'household', 'way', 'information', 'need', 'share', 'community', 'server', 'number', 'community', 'time', 'step', 'intent', 'efficacy', 'number', 'value', 'time', 'community', 'value']], [['quantum', 'quantum', 'body', 'tumor', 'vaccine', 'metalloprotein', 'term', 'quantum', 'hardware'], ['policy', 'control', 'pool', 'part', 'policy', 'domain', 'expertise', 'unit', 'intervention', 'period', 'estimation', 'component', 'analysi', 'control', 'selection', 'control', 'method', 'select', 'proces', 'policy', 'case', 'reunification', 'hotel', 'moratorium', 'barcelona', 'sugar', 'beverage', 'tax', 'san', 'francisco', 'policy', 'work']], [['quantum'], ['bsde', 'pricing', 'deltum', 'gamma', 'bermudan', 'portfolio', 'risk', 'management', 'mixture', 'asset', 'bermudan', 'framework', 'system', 'step', 'et', 'al', 'proces', 'order', 'option', 'system', 'network', 'regression', 'monte', 'carlo', 'method', 'number', 'option', 'dimensional', 'basket', 'multiple', 'exercise', 'moneynes', 'volatility', 'robustnes', 'accuracy', 'method', 'risk', 'benchmark', 'case', 'deltum', 'deltum', 'gamma', 'hedging']], [['review', 'quantum', 'engineering'], ['work', 'solution', 'navigation', 'system', 'navigation', 'ability', 'perform', 'initialization', 'relocalization', 'air', 'motion', 'cause', 'scale', 'initialization', 'algorithm', 'issue', 'fuse', 'information', 'initialization', 'proces', 'feature', 'information', 'estimation', 'accuracy', 'initialization', 'initialization', 'laser', 'range', 'finder', 'lrf', 'method', 'cost', 'satellite', 'imagery', 'elevation', 'information', 'evaluate', 'scale', 'dataset', 'compare', 'effectivenes', 'method']], [['simulation', 'computer'], ['hendel', 'resistance', 'distance', 'grid', 'graph', 'behavior', 'behavior', 'circuit', 'graph', 'row', 'time', 'conjecture', 'number', 'grid', 'edge', 'edge', 'resistance', 'case', 'conjecture', 'theorem', 'edge', 'grid', 'notation']], [['subspace', 'search', 'quantum', 'time', 'evolution', 'state'], ['detection', 'quantum', 'k', 'n', 'quantum', 'k', 'point', 'k']], [['post', 'selection', 'noisy', 'boson', 'part', 'whole'], ['fcnr', 'representation', 'visualization', 'solution', 'compression', 'ratio', 'image', 'compression', 'fcnr', 'context', 'transfer', 'image', 'solution', 'speed', 'reconstruction', 'quality', 'compression', 'ratio', 'demonstrate', 'effectivenes', 'compare', 'state', 'art', 'compression', 'e', 'hnerv', 'nervus', 'source', 'code']], [['coherence', 'rail', 'erasure', 'qubit'], ['array', 'image', 'mode', 'collapse', 'lack', 'straightforward', 'representation', 'image', 'encounter', 'article', 'realism', 'overestimate', 'dimensionality', 'image', 'manifold', 'issue', 'framework', 'manner', 'auto', 'model', 'quality', 'ass', 'methodology', 'image', 'learning', 'system', 'convolutional', 'gan', 'network', 'autoencoder', 'network', 'technique', 'issue', 'scenario', 'integration', 'va', 'option']], [['quantum', 'error', 'cancellation', 'photon'], ['distance', 'chemo', 'capture', 'transient', 'diffusion', 'damage', 'evolution', 'framework', 'reliance', 'constitutive', 'tangent', 'database', 'potential', 'space', 'distance', 'norm', 'traction', 'separation', 'pair', 'concentration', 'pair', 'jump', 'flux', 'pair', 'momentum', 'conservation', 'law', 'conservation', 'law', 'concentration', 'lagrange', 'history', 'state', 'interface', 'damage', 'variable', 'integrity', 'condition', 'database', 'manage', 'evolution', 'efficiency', 'capability', 'framework', 'test', 'convergence', 'number', 'reference', 'history', 'interface', 'damage', 'evolution', 'interface', 'degradation', 'diffusion', 'stres', 'diffusion', 'work', 'tool']], [['linearisation', 'control'], ['interest', 'advent', 'scale', 'quantum', 'ground', 'quantum', 'attention', 'absence', 'work', 'introduce', 'subspace', 'search', 'quantum', 'time', 'evolution', 'method', 'quantum', 'eigensolver', 'quantum', 'time', 'evolution', 'method', 'effectivenes', 'model', 'toy', 'hamiltonian', 'robustnes', 'minimum', 'state', 'algorithm', 'robustnes', 'minimum', 'ssqite', 'quantum', 'range']], [['modlisation', 'commande', 'paramtr'], ['time', 'equilibrium', 'phase', 'matter', 'neighbor', 'range', 'prethermalization', 'spin', 'pdtc', 'emergence', 'disorder', 'pdtc', 'floquet', 'spin', 'time', 'frequency', 'energy', 'density', 'state', 'key', 'pdtc', 'order', 'spin', 'flip', 'pdtc', 'spin', 'chain', 'quantum', 'spin', 'half', 'system', 'range', 'exploration', 'quantum', 'quantum', 'time', 'crystalline', 'order']], [['reinforcement', 'framework', 'level', 'abstraction', 'expression', 'search'], ['detection', 'possibility', 'pfimp', 'matter', 'dm', 'presence', 'dm', 'context', 'pfimp', 'phenomenology', 'partner', 'dm', 'pfimp', 'model', 'sm', 'partner', 'lepton', 'interaction', 'lepton', 'sector', 'detection', 'observation', 'lepton', 'flavor', 'probe', 'energy', 'article', 'space', 'lepton', 'flavor', 'violation', 'lfv', 'tau', 'energy', 'lhc', 'model', 'lepton', 'collider', 'concern', 'space', 'connection', 'density', 'detection']], [['memory', 'decision', 'synthesi', 'task'], ['processing', 'memory', 'pim', 'memory', 'wall', 'problem', 'bitwise', 'memory', 'accelerating', 'gap', 'design', 'pim', 'memory', 'array', 'addres', 'gap', 'end', 'integration', 'pim', 'level', 'python', 'tensor', 'level', 'design', 'begin', 'microarchitecture', 'instruction', 'architecture', 'isa', 'bridge', 'gap', 'level', 'control', 'periphery', 'abstraction', 'pim', 'parallelism', 'development', 'library', 'level', 'python', 'driver', 'pypim', 'cycle', 'accurate', 'simulator', 'variety', 'versatility', 'performance', 'pim', 'pypim', 'development', 'pim', 'conversion', 'tensor', 'ease']], [['regression', 'earth', 'science', 'focu', 'evapotranspiration'], ['emergence', 'synchronization', 'phenomenon', 'context', 'equilibrium', 'phase', 'body', 'lattice', 'blume', 'capel', 'pott', 'order', 'control', 'response', 'theory', 'field', 'body', 'equilibrium', 'phase', 'self', 'feedback', 'landau', 'theory', 'case', 'model', 'bifurcation', 'point', 'evidence', 'value', 'law', 'feedback', 'illustrate', 'multistability', 'case', 'model', 'point', 'bifurcation', 'pott', 'model', 'mirror', 'limit', 'line', 'characterize', 'temperature', 'cascade', 'period', 'shilnikov', 'scenario', 'toru', 'destruction', 'entropy', 'production', 'temperature', 'correspond', 'change', 'spectrum', 'lyapunov', 'field', 'behavior', 'bifurcation', 'theory', 'way', 'definition', 'universality']], [['feasibility', 'optimality', 'generalizability'], ['model', 'anishchenkoastakhov', 'generator', 'regime', 'self', 'sequence', 'force', 'synchronization', 'picture', 'structure', 'synchronization', 'picture', 'system', 'action', 'excitation', 'spectrum', 'lyapunov', 'appearance', 'hyperchao', 'close', 'zero', 'lyapunov', 'development', 'chao', 'destruction', 'frequency', 'hyperchao', 'shilnikov', 'result', 'sequence', 'neimark', 'sacker', 'close', 'zero', 'lyapunov', 'impact', 'torus', 'sequence', 'toru']], [['compression', 'performance', 'pde'], ['pattern', 'antipersistency', 'sign', 'decomposition', 'range', 'antus', 'measure', 'antipersistent', 'sign', 'decomposition', 'noise', 'fluctuation', 'analysi', 'applicability', 'world']], [['feasibility', 'optimality', 'generalizability'], ['floquet', 'technique', 'engineering', 'quantum', 'equilibrium', 'challenge', 'energy', 'absorption', 'field', 'drive', 'energy', 'body', 'system', 'energy', 'absorption', 'existence', 'regime', 'presence', 'report', 'observation', 'prethermalization', 'spin', 'diamond', 'dependence', 'coupling', 'nature', 'interaction', 'observation', 'quasi', 'floquet', 'incommensurate', 'frequency', 'drive', 'find', 'existence', 'prethermalization', 'smoothnes', 'field', 'door', 'equilibrium', 'phenomenon', 'quasi']], [['sheaf', 'self', 'network', 'cost', 'air', 'quality', 'monitoring', 'causal'], ['model', 'trade', 'value', 'buyer', 'cost', 'seller', 'distribution', 'designer', 'value', 'cost', 'designer', 'designer', 'trading', 'mechanism', 'incentive', 'budget', 'mechanism', 'mechanism', 'equivalence', 'incentive', 'strategy', 'characterise', 'distribution', 'mechanism', 'use', 'characterisation', 'mechanism', 'show', 'mechanism', 'price', 'strategy', 'incentive', 'ex', 'post', 'explicit', 'expression', 'price', 'optimal', 'robust', 'mechanism', 'efficiency', 'mechanism', 'max', 'min', 'problem', 'efficiency', 'designer', 'mechanism', 'distribution', 'min', 'max', 'problem']], [['mltl', 'calibration', 'model', 'time', 'emission', 'brick', 'kiln', 'industry'], ['simulating', 'quantum', 'feasibility', 'transition', 'simulation', 'ground', 'state', 'preparation', 'tritium', 'nucleu', 'model', 'quantum', 'algorithm', 'aid', 'isospin', 'energy', 'estimation', 'probability', 'function', 'dipole', 'polarization', 'angle', 'transition', 'capture', 'dn', 'result', 'tritium', 'excitation']], [[], ['number', 'number', 'edge', 'neighbor', 'unit', 'band', 'number', 'continuation', 'vector', 'plane', 'riemann', 'surface', 'band', 'structure', 'correspond', 'bulk', 'eigenvector', 'number', 'similarity', 'phase', 'symmetry', 'classification', 'model', 'non', 'energy', 'edge', 'gap', 'condition', 'non', 'symmetry']], [[], ['collaboration', 'existence', 'vector', 'boson', 'ma', 'mev', 'boson', 'particle', 'dalitz', 'collaboration', 'decay', 'dee', 'time', 'prediction', 'vector', 'meson', 'dominance', 'vmd', 'model', 'exces', 'signal', 'x', 'investigate', 'bsee', 'j', 'cee', 'form', 'framework', 'covariant', 'model', 'quark', 'theory', 'vmd', 'model', 'peev', 'p']], [['conjugacy', 'clas', 'exponent'], ['type', 'ia', 'supernova', 'sne', 'ia', 'explosion', 'dwarf', 'result', 'interaction', 'nature', 'interaction', 'object', 'uncertain', 'model', 'degenerate', 'detonation', 'model', 'explanation', 'realization', 'scenario', 'companion', 'explosion', 'l', 'l', 'dwarf', 'survey', 'sn', 'dark', 'energy', 'camera', 'star', 'precision', 'motion', 'survey', 'population', 'remnant', 'rule', 'motion', 'object', 'realization', 'scenario', 'vtransverse', 'km', 'mr', 'luminosity', 'l', 'l', 'star', 'exist', 'detection', 'dust', 'possibility', 'ejection', 'binary', 'system', 'line', 'sight']], [['group'], ['exemplar', 'image', 'image', 'translation', 'source', 'image', 'target', 'image', 'domain', 'style', 'target', 'image', 'ground', 'truth', 'input', 'translation', 'style', 'image', 'level', 'feature', 'vector', 'vector', 'object', 'instanceclas', 'knowledge', 'scene', 'style', 'dense', 'feature', 'map', 'finer', 'transfer', 'source', 'image', 'information', 'style', 'content', 'cro', 'domain', 'style', 'source', 'content', 'demonstrate', 'effectivenes', 'method', 'style', 'measuring', 'style', 'similarity', 'clas', 'wise', 'manner', 'evidence', 'closer', 'state', 'art', 'source', 'content']], [['mechanism', 'trading'], ['scheme', 'determine', 'self', 'energy', 'ward', 'identity', 'momentum', 'conservation', 'law', 'calculation', 'electron', 'ga', 'particle', 'function', 'conservation', 'f', 'fermi', 'energy', 'f', 'surface', 'space', 'f', 'fermi', 'momentum', 'function', 'energy', 'peak', 'addition', 'quasiparticle', 'qp', 'plasmon', 'energy', 'function', 'im', 'bf', 'metal', 'density', 'region', 'dimensionles', 'density', 'peak', 'effect', 'attraction', 'electron', 'hole', 'polarization', 'function', 'f', 'f', 'peak', 'hundredth', 'qp', 'excitation', 'energy', 'half', 'contradiction', 'hypothesi', 'correspondence', 'energy', 'fermi', 'ga', 'liquid', 'qp', 'ma', 'renormalization', 'factor', 'agreement', 'quantum', 'monte', 'carlo']], [['trade'], ['analysi', 'deformation', 'design', 'repair', 'time', 'demand', 'accurate', 'surrogate', 'model', 'conduct', 'analysi', 'model', 'distribution', 'fibre', 'frp', 'lamina', 'stres', 'model', 'element', 'method', 'dem', 'simulation', 'volume', 'volume', 'fraction', 'volume', 'fraction', 'volume', 'fraction', 'comparison', 'model', 'accuracy', 'stres', 'fibre', 'volume', 'training', 'dataset']], [['phase', 'fermion', 'pair', 'exciton'], ['task', 'reinforcement', 'rl', 'performance', 'deploy', 'rl', 'level', 'domain', 'handle', 'policy', 'planning', 'scalability', 'addres', 'expression', 'search', 'optimization', 'level', 'pixel', 'level', 'leverage', 'simplicity', 'scalability', 'optimization', 'state', 'art', 'rl', 'amount', 'knowledge']], [['spin', 'quantum'], ['distribution', 'sentence', 'pre', 'language', 'degradation', 'performance', 'task', 'isotropy', 'sentence', 'word', 'sentence', 'quality', 'sentence', 'cl', 'token', 'pre', 'language', 'feed', 'model', 'downstream', 'task', 'los', 'function', 'isotropy', 'downstream', 'task', 'downstream', 'task', 'show', 'method', 'par', 'state', 'art', 'performance', 'downstream', 'baseline']], [['simulation', 'valence', 'bond', 'template', 'spin', 'liquid', 'ground', 'state'], ['electron', 'density', 'matrix', 'rdm', 'exchange', 'correlation', 'density', 'theory', 'rdmft', 'accuracy', 'density', 'theory', 'group', 'thermochemistry', 'density', 'screen', 'range', 'portion', 'rdm', 'correlation', 'treatment', 'correlation', 'equilibrium', 'performance', 'model', 'group', 'thermochemistry', 'atomization', 'reaction', 'model', 'density', 'prediction', 'reaction', 'singlet', 'power', 'rdmft', 'equilibrium', 'development', 'refine', 'model', 'order', 'description', 'equilibrium']], [['exploration', 'quantum'], ['quantum', 'einstein', 'condensate', 'fermion', 'pair', 'exciton', 'system', 'phase', 'fermion', 'pair', 'exciton', 'analysi', 'convex', 'ground', 'state', 'particle', 'density', 'set', 'representation', 'infinite', 'parameter', 'space', 'pair', 'phase', 'exciton', 'condensate', 'order', 'phase', 'number', 'system', 'fermion', 'exciton', 'condensate', 'fec', 'order', 'phase', 'transition', 'exciton', 'fermion', 'pair', 'condensate', 'information', 'exciton', 'fermion', 'pair', 'phase', 'insight', 'formation', 'fec', 'condensate', 'anticipate', 'prove', 'realization']], [['fermion'], ['survey', 'motion', 'poisson', 'structure', 'use', 'method', 'orbit', 'configuration', 'space', 'velocity', 'phase', 'space', 'jacobi', 'identity', 'velocity', 'phase', 'space', 'review', 'commutativity', 'velocity', 'clas', 'form', 'feynman', 'form', 'volume']], [['electro', 'thermo', 'flow', 'gold', 'nanoparticle', 'velocity', 'dependence', 'concentration'], ['influence', 'structure', 'micrometer', 'length', 'deformation', 'polycrystalline', 'plasticity', 'element', 'nonlinearity', 'deformation', 'power', 'application', 'addres', 'challenge', 'order', 'representation', 'complex', 'order', 'order', 'expense', 'cpfem', 'work', 'rom', 'framework', 'cpfem', 'decomposition', 'pod', 'proces', 'svgp', 'regression', 'crystal', 'protocol', 'compres', 'field', 'space', 'analysi', 'pca', 'value', 'decomposition', 'svd', 'result', 'dimensional', 'amount', 'proces', 'gp', 'regression', 'scalability', 'datain', 'manner', 'latent', 'pod', 'pod', 'pod', 'field', 'agreement', 'cpfem', 'framework', 'void', 'crystal', 'aluminum', 'alloy', 'framework', 'work', 'crystal', 'load', 'case', 'example', 'tensile', 'geometry']], [['inverse', 'problem', 'clas'], ['strategy', 'sketch', 'person', 'identification', 'method', 'self', 'person', 'identification', 'regularization', 'proces', 'problem', 'person', 'identification', 'proces', 'simple', 'jigsaw', 'pre', 'task', 'self', 'image', 'self', 'perform', 'learning', 'swin', 'transformer', 'v', 'sketch', 'reid', 'market', 'sketch', 'sketch', 'person', 'identification', 'performance', 'rank', 'map', 'pku', 'sketch', 'reid', 'rank', 'map', 'maskk', 'dataset', 'gradcam', 'analysi']], [['dirac', 'inverse'], ['skin', 'effect', 'number', 'lattice', 'existence', 'non', 'skin', 'effect', 'model', 'group', 'experiment', 'skin', 'effect', 'variation', 'effect', 'system', 'origin', 'non', 'skin', 'effect', 'work', 'way', 'skin', 'effect', 'quantum']], [['kernel', 'hilbert'], ['succes', 'image', 'work', 'image', 'compression', 'image', 'distribution', 'image', 'quality', 'complexity', 'codec', 'perception', 'distribution', 'trade', 'quality', 'bit', 'rate', 'compression', 'accumulate', 'decompression', 'c', 'image', 'codec', 'distortion', 'wd', 'image', 'rater', 'optimization', 'objective', 'predictor', 'pearson', 'correlation', 'elo']], [[], ['consensu', 'control', 'vehicle', 'platoon', 'account', 'psychological', 'comfort', 'end', 'state', 'velocity', 'platoon', 'controller', 'comfort', 'consensu', 'function', 'blf', 'stability', 'controller', 'stability', 'analysi', 'performance', 'control', 'control', 'state']], [['logic', 'change', 'memory'], ['sequence', 'model', 'computation', 'problem', 'prediction', 'los', 'indicator', 'los', 'stem', 'los', 'information', 'model', 'ability', 'hidden', 'contrast', 'prediction', 'los', 'interestingnes', 'task', 'measure', 'predictability', 'architecture', 'prediction', 'information', 'bottleneck', 'pathway', 'network', 'example', 'stream', 'information', 'computation', 'step', 'show', 'description', 'length', 'complexity', 'reasoning', 'reasoning']], [['spectrum', 'memory'], ['question', 'language', 'rge', 'language', 'character', 'recognition', 'technology', 'answer', 'performance', 'information', 'framework', 'language', 'generation', 'extraction', 'generate', 'accurate', 'effectivenes', 'method', 'accuracy', 'increase', 'bleu', 'increase', 'cider', 'score', 'state', 'art', 'vqa']], [['phase', 'change', 'memory', 'memory'], ['level', 'fidelity', 'offering', 'promise', 'privacy', 'imaging', 'aspect', 'largley', 'matching', 'performance', 'downstream', 'image', 'generation', 'image', 'diversity', 'fidelity', 'mode', 'coverage', 'performance', 'work', 'shift', 'highlight', 'diversity', 'secure', 'framework', 'training', 'diffusion', 'performance', 'percentage', 'point', 'state', 'art', 'privacy']], [['validation', 'memristor', 'rram', 'crossbar', 'array'], ['quality', 'today', 'dimensionality', 'quality', 'phase', 'analysi', 'number', 'time', 'procedure', 'parameter', 'estimation', 'phase', 'procedure', 'parameter', 'estimation', 'presence', 'estimator', 'parameter', 'estimation', 'correction', 'coefficient', 'simulation', 'performance', 'phase', 'criterion', 'assessment', 'absence', 'presence', 'control', 'chart', 'scheme', 'proces', 'mean', 'world', 'applicability', 'method']], [['power', 'memory', 'grade', 'imply', 'architecture'], ['origin', 'host', 'hole', 'mbh', 'mechanism', 'encounter', 'star', 'subsequent', 'fly', 'binary', 'fate', 'evolution', 'pericentre', 'population', 'body', 'formalism', 'strength', 'ability', 'parameter', 'space', 'inclination', 'encounter', 'mbh', 'tidal', 'eccentricity', 'fate', 'fraction', 'example', 'system', 'effect', 'time']], [['role', 'phase', 'change', 'memory', 'edge', 'memory'], ['aperture', 'array', 'field', 'regime', 'multiple', 'share', 'direction', 'capability', 'field', 'question', 'degree', 'freedom', 'dof', 'multiplexing', 'distance', 'domain', 'addres', 'problem', 'dof', 'line', 'transmit', 'aperture', 'array', 'direction', 'aperture', 'aperture', 'aperture', 'cap', 'number', 'case', 'case', 'transmit', 'array', 'piece', 'array', 'side', 'transmit', 'array', 'operator', 'convolution', 'form', 'expression', 'dof', 'transform', 'analysi', 'dof', 'distance', 'domain', 'structure', 'framework', 'projection', 'method', 'dof', 'broadside', 'case', 'framework', 'array', 'dof', 'gain', 'piece', 'array', 'constraint', 'length', 'array']], [['pypim', 'processing', 'memory', 'design', 'python'], ['pathwise', 'mckean', 'vlasov', 'equation', 'regularity', 'diffusion', 'diffusion', 'measure', 'solution', 'pathwise', 'drift', 'state', 'diffusion', 'time', 'mckean', 'vlasov', 'equation', 'proces']], [['bitwise', 'logic', 'change', 'memory', 'architecture'], ['multilayer', 'failure', 'device', 'reliability', 'zone', 'traction', 'separation', 'traction', 'separation', 'mode', 'complexity', 'problem', 'network', 'set', 'fracture', 'network', 'tcnn', 'behavior', 'training', 'consistency', 'ius', 'energy', 'dissipation', 'path', 'control', 'conservation', 'los', 'function', 'feasibility', 'optimization', 'algorithm', 'order', 'convergence', 'implementation', 'mode', 'traction', 'separation', 'fidelity', 'input', 'point', 'point', 'modeling', 'concept', 'interface']], [['simulation', 'phase', 'change', 'memory', 'implementation'], ['energy', 'transition', 'energy', 'source', 'generation', 'electricity', 'mode', 'electricity', 'generation', 'energy', 'requirement', 'power', 'globe', 'remote', 'power', 'maintenance', 'persist', 'faulty', 'pv', 'deep', 'learning', 'image', 'segmentation', 'detection', 'ground', 'truth', 'power', 'model', 'require', 'training', 'image', 'image', 'use', 'panel', 'input', 'network', 'cluster', 'pixel', 'model', 'backpropagation', 'gradient', 'descent', 'compute', 'similarity', 'los', 'continuity', 'los', 'assign', 'label', 'pixel', 'continuity', 'image', 'segmentation', 'proces', 'effectivenes', 'online', 'dataset', 'recognition', 'snail', 'spot']], [['stability', 'model', 'ralpha', 'r', 'theory', 'gravity'], ['industry', 'era', 'proces', 'monitoring', 'improvement', 'expository', 'perspective', 'practice', 'proces', 'monitoring', 'bring', 'level', 'view', 'practice', 'industry', 'era', 'introduction', 'growth', 'paradigm', 'spm', 'methodology', 'perspective', 'comparison', 'monitoring', 'area']], [['inflation', 'palatini', 'formalism'], ['sound', 'microcontroller', 'microcontroller', 'ideal', 'choice', 'architecture', 'versatility', 'cost', 'focu', 'application', 'microcontroller', 'ability', 'generate', 'buzzer', 'button', 'interface', 'implementation', 'project', 'hardware', 'software', 'performance', 'microcontroller', 'ability', 'application']], [['inflation'], ['segmentation', 'task', 'scale', 'pre', 'image', 'generation', 'boost', 'result', 'quality', 'ease', 'use', 'novel', 'method', 'generation', 'foreground', 'segmentation', 'segmentation', 'leverage', 'pre', 'diffusion', 'segmentation', 'tune', 'diffusion', 'model', 'task', 'removal', 'time', 'foreground', 'background', 'dataset', 'demonstrate', 'method', 'performance', 'training']], [['hamilton', 'jacobi', 'formulation', 'reduction'], ['lattice', 'quasi', 'monte', 'carlo', 'multivariate', 'rule', 'vector', 'boldsymbolz', 'mathbbz', 'number', 'rank', 'lattice', 'computer', 'search', 'ebert', 'journal', 'complexity', 'component', 'digit', 'digit', 'cbc', 'dbd', 'construction', 'generating', 'lattice', 'korobov', 'product', 'result', 'question', 'et', 'al', 'section', 'case', 'pod', 'construction', 'cbc', 'construction']], [['weyl', 'formulation', 'tegr', 'quantization'], ['significance', 'building', 'change', 'detection', 'cd', 'contribution', 'development', 'cd', 'extraction', 'detection', 'accuracy', 'state', 'art', 'sotum', 'domain', 'dml', 'unet', 'building', 'cd', 'imagery', 'efficientnet', 'b', 'backbone', 'module', 'extraction', 'parameter', 'reduction', 'performance', 'domain', 'attention', 'block', 'dmab', 'spatialfrequency', 'cro', 'feature', 'boost', 'capacity', 'pixel', 'classifier', 'change', 'identification', 'cd', 'cd', 'dstamnet', 'superiority', 'cd']], [['quantum', 'teleparallel', 'gravity'], ['quench', 'su', 'schrieffer', 'heeger', 'lattice', 'edge', 'state', 'transport', 'acros', 'chain', 'model', 'non', 'lattice', 'transport', 'result', 'quench', 'sense', 'imbalance', 'reflection', 'transport', 'imbalance', 'reflection', 'reflection', 'configuration', 'system', 'space', 'discus', 'emergence', 'phenomenon', 'reorganization', 'bulk', 'energy', 'configuration', 'system']], [['quantum', 'space', 'time', 'acceleration', 'quantum', 'gravity'], ['jsumkn', 'sinakpin', 'cosjakpin', 'bmnasumjm', 'j', 'jsumkn', 'sinakpin', 'cosjakpin', 'mgeq', 'ngeq', 'number', 'proof', 'n', 'amna', 'sinma', 'ius', 'notequiv', 'mboxmod', 'amna', 'iius', 'equiv', 'mboxmod', 'bmna', 'fracn', 'sinma', 'iv', 'mboxmod', 'n', 'bmna']], [['relation', 'hamilton', 'jacobi', 'equation', 'hamilton', 'jacobi', 'equation'], ['volt', 'var', 'volt', 'functionality', 'photovoltaic', 'system', 'voltage', 'power', 'system', 'cyberattack', 'event', 'volt', 'var', 'control', 'portion', 'distribution', 'grid', 'adaptation', 'scheme', 'energy', 'effect', 'instability', 'adaptation', 'mechanism', 'model', 'communication', 'configuration', 'derivation', 'control', 'validate', 'algorithm', 'test']], [['body', 'geometry'], ['challenge', 'drug', 'design', 'mpr', 'information', 'capture', 'space', 'perspective', 'simple', 'observation', 'performance', 'light', 'framework', 'space', 'framework', 'architecture', 'space', 'discretization', 'grid', 'mpr', 'downstream', 'benefit', 'space']], [['motion'], ['game', 'concurrent', 'graph', 'core', 'b', 'game', 'b', 'game', 'shapley', 'shubik', 'citeshapleyassignment', 'core', 'game', 'relaxation', 'game', 'deng', 'al', 'framework', 'framework', 'turn', 'show', 'core', 'question', 'understanding', 'game', 'reason', 'characterization', 'polytope']], [['vibration', 'teller', 'strength', 'decay', 'skyrme', 'proton', 'amplitude', 'method'], ['b', 'case', 'bound', 'value', 'core', 'solution', 'bipartite', 'b', 'bound', 'constraint', 'allocation', 'group', 'allocation', 'converge', 'core', 'bipartite', 'b', 'method', 'converge', 'time', 'converge', 'probability', 'state', 'aspiration', 'track', 'history', 'environment', 'state', 'stage', 'match', 'succes', 'failure', 'proposal', 'stage', 'match', 'calculate', 'feasibility', 'match', 'environment', 'structure', 'proposal', 'state', 'core', 'b', 'matching']], [['quasiparticle', 'random', 'phase', 'approximation', 'point'], ['discipline', 'science', 'knowledge', 'help', 'cut', 'complexity', 'chapter', 'science', 'world', 'science', 'aid', 'progress', 'space']], [['decay'], ['control', 'problem', 'prep', 'vaccine', 'model', 'spread', 'hiv', 'use', 'model', 'field', 'solution', 'system', 'model', 'control', 'problem', 'percentage', 'population', 'prep', 'principle', 'expression', 'control', 'lagrange', 'combination', 'principle', 'budget', 'control', 'case', 'control', 'case']], [['photoabsorption', 'cro', 'quasiparticle', 'amplitude', 'framework'], ['label', 'lnl', 'problem', 'image', 'literature', 'straightforward', 'migration', 'cost', 'information', 'sound', 'choice', 'analysi', 'noisy', 'selection', 'method', 'truncation', 'feature', 'noise', 'detection', 'method', 'noisy', 'category', 'strategy', 'relationship', 'noisy', 'model', 'training', 'benchmark', 'classification', 'show', 'e', 'split', 'contrbf', 'asbf', 'neat', 'dimension', 'method', 'detection', 'f', 'score', 'classification', 'accuracy', 'improvement', 'mini', 'noise', 'classification', 'accuracy', 'improvement', 'mini', 'v']], [['motion', 'body', 'problem'], ['gdm', 'scheme', 'action', 'ad', 'analyze', 'scheme', 'action', 'show', 'r', 'locu', 'r', 'law', 'decomposition', 'incidence', 'characterization', 'incidence', 'incidence']], [['model', 'particle', 'motion'], ['work', 'derivation', 'theory', 'hcoft', 'framework', 'rev', 'lett', 'key', 'representation', 'complexity', 'density', 'energy', 'exclusion', 'principle', 'clifford', 'algebra', 'los', 'meaning', 'work', 'determinant', 'framework', 'multireference']], [['microscopic', 'analysi', 'structure', 'region'], ['time', 'vlasovmaxwelllandau', 'system', 'domain', 'reflection', 'condition', 'result', 'case', 'domain', 'example', 'toru', 'knowledge', 'result', 'model', 'effect', 'dimensional', 'domain']], [['model', 'vibration'], ['intelligence', 'language', 'paradigm', 'pharmacy', 'language', 'succes', 'modeling', 'modeling', 'challenge', 'absence', 'gap', 'introduce', 'confseq', 'novel', 'conformation', 'description', 'language', 'bond', 'chirality', 'design', 'invariance', 'readability', 'concisenes', 'reformulation', 'range', 'modeling', 'conformation', 'prediction', 'generation', 'representation', 'sequence', 'transformer', 'architecture', 'state', 'art', 'performance', 'diffusion', 'confseq', 'method', 'inference', 'efficiency', 'generation', 'controllability', 'confseq', 'tool', 'development', 'sequence', 'modeling']], [['bit', 'time'], ['type', 'ia', 'supernova', 'sne', 'wd', 'ejection', 'example', 'iax', 'sn', 'companion', 'wd', 'characterisation', 'hyper', 'runawayhypervelocity', 'hv', 'wd', 'light', 'analyse', 'textitgaium', 'dr', 'search', 'hv', 'wd', 'sequence', 'sub', 'hvs', 'wd', 'sub', 'm', 'runaway', 'sub', 'm', 'sub', 'm', 'velocity', 'fraction', 'type', 'ia', 'sne', 'contribution', 'scenario', 'origin', 'sne', 'rate', 'reverse', 'detonation', 'channel', 'velocity', 'hv', 'wd', 'iax', 'sne', 'origin', 'contribution', 'candidate']], [['diversity'], ['entanglement', 'role', 'quantum', 'computation', 'quantum', 'information', 'processing', 'significance', 'separability', 'entanglement', 'matrix', 'criterion', 'density', 'entanglement', 'criterion', 'matrix', 'entanglement', 'bound', 'concurrence', 'entanglement', 'fine']], [['search', 'life', 'foundation'], ['generation', 'legality', 'flex', 'novel', 'generate', 'reliable', 'layout', 'method', 'diffusion', 'model', 'compute', 'efficient', 'representation', 'pattern', 'generation', 'optimization', 'box', 'assessment', 'proces', 'design', 'legalization', 'generation', 'proces', 'layout']], [['network'], ['group', 'element', 'eigenvalue', 'theory', 'field', 'question', 'existence', 'question', 'question', 'structure', 'linear']], [['computation', 'complexity', 'state', 'prediction'], ['function', 'generalize', 'level', 'box', 'decision', 'proces', 'addres', 'issue', 'rule', 'extraction', 'rule', 'representation', 'thesi', 'method', 'rule', 'rule', 'extraction', 'generate', 'rule', 'input', 'clas', 'label', 'reason', 'rule', 'extraction', 'technique', 'rule', 'production', 'method', 'range', 'rule', 'example', 'dataset', 'increase', 'size', 'extraction', 'method', 'rule', 'variety', 'rule', 'ripper']], [['reinforcement'], ['diffusion', 'model', 'performance', 'attention', 'diffusion', 'model', 'gadiff', 'conformation', 'generation', 'task', 'chain', 'gadiff', 'graph', 'isomorphism', 'network', 'information', 'subgraph', 'edge', 'bond', 'torsion', 'range', 'head', 'self', 'attention', 'noise', 'attention', 'mechanism', 'capture', 'information', 'addition', 'msa', 'calculate', 'conformation', 'noise', 'prediction', 'performance', 'state', 'art', 'generation', 'diversitycov', 'r', 'cov', 'p', 'accuracy', 'mat', 'r', 'mat', 'p', 'property', 'prediction', 'geom', 'qm', 'geom', 'geom', 'r', 'baseline', 'model', 'model', 'gadiff', 'gadiff', 'interaction', 'geom', 'qm', 'dataset', 'pre', 'model', 'encoder', 'level', 'evaluation', 'conformation', 'property', 'model', 'value', 'multus']], [['reinforcement', 'language'], ['galaxy', 'galaxy', 'cluster', 'lensing', 'waveform', 'morphology', 'frequency', 'domain', 'analysi', 'need', 'complex', 'matter', 'signal', 'test', 'fact', 'inference', 'hypothesi', 'correlation', 'hypothesi', 'fraction', 'show', 'detector', 'mismatch', 'population', 'sensitivity']], [['field', 'array'], ['management', 'integrity', 'maintenance', 'query', 'optimization', 'database', 'design', 'integrity', 'support', 'database', 'need', 'level', 'use', 'support', 'notion', 'cover', 'comprising', 'fd', 'set', 'algorithm', 'complement', 'performance', 'number', 'size', 'cover', 'latter', 'integrity', 'maintenance', 'performance', 'query', 'refresh', 'benchmark', 'constraint', 'growth', 'performance', 'improvement', 'minimal', 'time']], [['multiplexing', 'distance', 'domain', 'aperture', 'array', 'field', 'region'], ['number', 'time', 'series', 'pattern', 'time', 'series', 'time', 'series', 'work', 'normality', 'frequency', 'time', 'series', 'distribution', 'time', 'series']], [['field', 'versu', 'field', 'propagation', 'xl', 'mimo', 'performance', 'evaluation'], ['vx', 'environment', 'target', 'vehicle', 'motion', 'information', 'information', 'role', 'target', 'understand', 'car', 'behavior', 'target', 'vehicle', 'car', 'model', 'distance', 'field', 'influence', 'vehicle', 'stability', 'stability', 'analysi', 'equation', 'evolution', 'traffic', 'density', 'analysi', 'multus', 'vehicle', 'effect', 'vehicle', 'influence', 'distance', 'field', 'number', 'form', 'kink', 'multus', 'vehicle', 'effect', 'coefficient', 'value', 'vehicle', 'influence', 'field', 'model', 'distance', 'model', 'moreover', 'number', 'stability', 'traffic', 'flow', 'model', 'movement', 'efficiency', 'congestion', 'road', 'safety', 'collision', 'model', 'safety', 'technology']], [['antenna', 'field', 'communication'], ['post', 'panel', 'number', 'number', 'time', 'addition', 'post', 'estimator', 'sqrtnt', 'zero', 'assumption', 'post', 'estimator', 'effect', 'estimator', 'manresa', 'contrast', 'effect', 'estimator', 'estimator']], [['design', 'field', 'mimo'], ['video', 'task', 'computer', 'vision', 'surveillance', 'content', 'retrieval', 'video', 'video', 'context', 'relationship', 'interference', 'redundancy', 'tackle', 'video', 'story', 'generation', 'fine', 'content', 'bottom', 'video', 'interpretation', 'mechanism', 'interference', 'information', 'video', 'introduce', 'redundancy', 'reduction', 'mechanism', 'granularity', 'information', 'video', 'evaluate', 'method', 'performance', 'versatility', 'method']], [['impact', 'array', 'field', 'isac'], ['power', 'state', 'eeg', 'peak', 'hz', 'background', 'proces', 'peak', 'none', 'channel', 'xi', 'alpha', 'model', 'marqui', 'et', 'parametric', 'description', 'cortex', 'model', 'activity', 'connectivity', 'alpha', 'model', 'cro', 'density', 'spectrum', 'covariance', 'matrix', 'separation', 'repertoire', 'cortex', 'connectivity', 'model', 'estimation', 'acces', 'state', 'test', 'validate', 'model', 'dimension', 'cro', 'spectrum', 'matrix', 'factorization', 'population', 'power', 'spectrum', 'alpha', 'variance', 'value', 'xi', 'alpha', 'model', 'proces', 'cortical', 'interdistance', 'laminar', 'alpha']], [['field', 'scale', 'mimo'], ['increase', 'foreseen', 'level', 'result', 'population', 'growth', 'motor', 'sensory', 'extremity', 'possibility', 'balance', 'control', 'result', 'deterioration', 'integration', 'information', 'novel', 'rehabilitation', 'framework', 'balance', 'rehabilitation', 'bar', 'effectivenes', 'rehabilitation', 'assessment', 'therapy', 'convenience', 'disability', 'assist', 'paradigm', 'rehabilitation', 'proces', 'foot', 'preparation', 'balance', 'balance', 'rehabilitation', 'balance', 'ability', 'feedback', 'utilization', 'reality', 'platform', 'feedback']], [['deviation', 'design', 'ri', 'field'], ['policy', 'electricity', 'consumption', 'measure', 'electricity', 'information', 'identify', 'effect', 'consumption', 'grid', 'aggregation', 'problem', 'effect', 'electricity', 'consumption', 'unit', 'generator', 'addres', 'problem', 'electricity', 'supply', 'assumption', 'monotonicity', 'show', 'estimator', 'penalization', 'assumption', 'sparsity', 'estimator', 'aggregation', 'problem', 'regression', 'estimator', 'method', 'inference', 'estimator', 'electricity', 'consumption', 'generation', 'fuel', 'location', 'region', 'level', 'account', 'fuel']], [['form', 'model', 'analysi', 'terahertz', 'field', 'communication', 'division'], ['distance', 'redshift', 'information', 'order', 'operate', 'information', 'association', 'sky', 'development', 'framework', 'chimera', 'pipeline', 'galaxy', 'catalog', 'glade', 'pipeline', 'luminosity', 'selection', 'catalog', 'h', 'sample', 'hole', 'markov', 'chain', 'monte', 'carlo', 'simulation', 'estimation', 'catalog', 'siren', 'chimera', 'pipeline', 'gw', 'lvk', 'detector', 'network']], [['range', 'resolution', 'field', 'mimo'], ['quantum', 'demarcation', 'line', 'information', 'technology', 'work', 'decomposition', 'introduce', 'formulate', 'criterion', 'separability', 'correlation', 'tensor', 'criterion', 'separability', 'analysi', 'availability', 'feasibility', 'detection', 'family', 'entanglement', 'criterion', 'linearity', 'density', 'operator', 'space']], [['field', 'codebook', 'design', 'scale', 'mimo'], ['science', 'time', 'scientist', 'analysi', 'generation', 'investigate', 'self', 'environment', 'show', 'exploration', 'setting', 'pure', 'generator', 'time']], [['performance', 'analysi', 'field', 'mimo'], ['version', 'light', 'dirac', 'dark', 'matter', 'symmetry', 'completion', 'anomaly', 'cancellation', 'combination', 'form', 'sub', 'ev', 'dirac', 'symmetry', 'particle', 'content', 'gauge', 'way', 'matter', 'gauge', 'singlet', 'dirac', 'fermion', 'consider', 'production', 'matter', 'correlate', 'space', 'reach', 'microwave', 'background', 'cmb', 'interplay', 'matter', 'cmb', 'structure', 'formation', 'scenario', 'parameter', 'space']], [['domain', 'field', 'channel', 'estimation', 'beam', 'training', 'analysi', 'case'], ['density', 'theory', 'manner', 'occupation', 'optimization', 'method', 'ebi', 'method', 'ebi', 'method', 'optimization', 'ebi', 'performance', 'optimization', 'convergence', 'require', 'occupation', 'issue', 'work', 'optimization', 'method', 'convergence', 'optimization', 'order', 'algorithm', 'preconditioner', 'line', 'search', 'method', 'basi', 'optimization', 'speed', 'convergence', 'stability', 'system', 'optimization', 'method', 'facilitate', 'wider', 'application', 'development']], [['layer', 'security', 'optimization', 'field', 'mimo'], ['graph', 'represent', 'life', 'example', 'information', 'system', 'existence', 'machine', 'perform', 'prediction', 'classification', 'network', 'gnn', 'graph', 'machine', 'utilize']], [['hybrid', 'field', 'system', 'beamfocusing', 'design'], ['generalization', 'dg', 'algorithm', 'perform', 'distribution', 'state', 'art', 'dg', 'algorithm', 'world', 'distribution', 'hence', 'introduce', 'attribute', 'distribution', 'shift', 'dg', 'algorithm', 'characterization', 'generalization', 'causal', 'relationship', 'classification', 'label', 'causal', 'graph', 'characterize', 'distribution', 'independence', 'constraint', 'work', 'evidence', 'constraint', 'minimization', 'cacm', 'proces', 'apply', 'independence', 'regularization', 'mnist', 'multus', 'dataset', 'accuracy', 'importance', 'proces']], [['learning', 'field', 'iot', 'localization', 'monitoring', 'healthcare'], ['busines', 'intelligence', 'bi', 'crucial', 'decision', 'edge', 'growth', 'need', 'analysi', 'language', 'processing', 'analyzing', 'chapter', 'nlp', 'analysi', 'role', 'text', 'analysi', 'bi', 'area', 'world', 'demonstrate', 'text', 'analysi', 'gain', 'customer', 'experience', 'anticipate', 'market', 'ai', 'knowledge', 'graph', 'integration', 'scalability', 'interpretability', 'privacy', 'bi', 'innovation', 'busines']], [['profile', 'wideband', 'dipole'], ['information', 'reasoning', 'pre', 'vision', 'language', 'model', 'vlm', 'network', 'reasoning', 'interpretability', 'question', 'text', 'fine', 'knowledge', 'reasoning', 'knowledge', 'framework', 'knowledge', 'language', 'knowledge', 'assistance', 'relationship', 'detection', 'fine', 'knowledge', 'paraphrase', 'question', 'underspecification', 'method', 'chain', 'evidence', 'coe', 'power', 'evidence', 'integration', 'self', 'reflection', 'technology', 'ability', 'vikser', 'state', 'art', 'sotum']], [['field', 'localization', 'antenna'], ['video', 'content', 'content', 'video', 'audio', 'inr', 'audio', 'representation', 'nera', 'represent', 'audio', 'network', 'representation', 'network', 'multimedium', 'network', 'timestamp', 'input', 'image', 'frame', 'network', 'architecture', 'combination', 'perceptron', 'mlp', 'convolutional', 'representation', 'multimedium', 'content', 'performance', 'improvement', 'db', 'psnr', 'video', 'fad', 'audio']], [['field', 'structure', 'design', 'planar', 'array'], ['time', 'promise', 'equilibrium', 'body', 'heating', 'frequency', 'regime', 'extent', 'quantum', 'non', 'quantum', 'processor', 'chuang', 'report', 'observation', 'body', 'particle', 'imbalance', 'subsystem', 'entropy', 'monitor', 'heating', 'proces', 'existence', 'plateau', 'lifetime', 'way', 'frequency', 'order', 'n', 'state', 'tomography', 'entanglement', 'distribution', 'area', 'law', 'volume', 'law', 'entanglement', 'equilibrium', 'reach', 'simulation', 'tensor', 'network', 'equilibrium', 'simulation']], [['field', 'localization', 'communication'], ['detection', 'cornerstone', 'uav', 'detection', 'method', 'implement', 'object', 'detection', 'scarcity', 'environment', 'image', 'acquisition', 'development', 'altitude', 'reconnaissance', 'patch', 'generation', 'framework', 'image', 'collection', 'photography', 'patch', 'optimization', 'method', 'enhance', 'continuity', 'method', 'exhibit', 'robustnes', 'transferability']], [['detection', 'possibility', 'presence', 'wimp'], ['canonicalweyl', 'moyal', 'type', 'nc', 'formalism', 'harmonic', 'oscillator', 'problem', 'quantum', 'phase', 'space', 'type', 'space', 'length', 'latter', 'case', 'case', 'conclusion', 'length', 'area', 'space', 'area', 'analysi', 'case', 'ladder', 'operator', 'quantization', 'length', 'space', 'quantization', 'spacetime', 'length', 'minkowski', 'time', 'space', 'time', 'noncommutativity', 'quantization', 'length']], [['dirac', 'neutrino', 'matter', 'symmetry'], ['scheme', 'order', 'clas', 'runge', 'kuttum', 'semi', 'hure', 'pham', 'warin', 'euler', 'scheme', 'time', 'error', 'convergence', 'regularity', 'efficiency', 'order', 'compromise', 'cost', 'implementation']], [['influence', 'lepton', 'portal', 'wimp', 'pfimp', 'framework'], ['user', 'web', 'acces', 'control', 'acces', 'ad', 'hoc', 'error', 'prone', 'misplace', 'policy', 'acces', 'control', 'enforcement', 'policy', 'application', 'code', 'application', 'acces', 'issue', 'development', 'policy', 'extraction', 'task', 'acces', 'control', 'policy', 'application', 'policy', 'specification', 'acces', 'compliance', 'code', 'time', 'ote', 'policy', 'extractor', 'ruby', 'execution', 'execution', 'application', 'policy', 'world']], [['multiparticle', 'matter', 'zn', 'symmetry'], ['delivery', 'agriculture', 'surveillance', 'search', 'rescue', 'cost', 'navigation', 'performance', 'vision', 'navigation', 'method', 'estimation', 'vision', 'language', 'model', 'obstacle', 'avoidance', 'path', 'planning', 'system', 'depth', 'zero', 'shot', 'depth', 'estimator', 'depth', 'flash', 'gpt', 'model', 'vlm', 'network', 'output', 'heading', 'angle', 'course', 'action', 'target', 'environment', 'destination', 'task', 'completion', 'rate', 'pre', 'solution', 'cost', 'efficient', 'time', 'navigation']], [['disorder', 'limit', 'graph', 'vertex', 'disorder'], ['hartree', 'fock', 'method', 'correlation', 'calculation', 'density', 'theory', 'method', 'correlation', 'energy', 'occupation', 'equation', 'occupation', 'distribution', 'efficient', 'ground', 'state']], [['heat', 'flow'], ['star', 'merger', 'neutrino', 'flavor', 'conversion', 'dense', 'e', 'e', 'neutrino', 'cancel', 'matter', 'potential', 'rise', 'matter', 'neutrino', 'flavor', 'conversion', 'assumption', 'antineutrino', 'homogeneity', 'neutrino', 'quantum', 'occurrence', 'matter', 'neutrino', 'resonance', 'angle', 'framework', 'ma', 'simulation', 'neutron', 'star', 'merger', 'hole', 'accretion', 'toru', 'flavor', 'conversion', 'matter', 'neutrino', 'resonance', 'matter', 'neutrino', 'neutrino', 'flavor', 'conversion', 'shape', 'modeling', 'neutrino', 'flavor', 'conversion', 'merger', 'iron']], [['surface', 'chao', 'spin', 'glas'], ['energy', 'priority', 'choice', 'utility', 'carbon', 'emission', 'footprint', 'cut', 'energy', 'utility', 'electricity', 'operation', 'usage', 'pv', 'organization', 'manage', 'panel', 'maintenance', 'example', 'vehicle', 'image', 'processing', 'technique', 'condition', 'efficiency', 'safety', 'maintenance', 'program', 'panel', 'maintenance', 'time', 'case', 'panel', 'maintenance', 'proces', 'technology', 'organization', 'panel', 'maintenance']], [['phase', 'component', 'spin', 'spin', 'glas', 'liquid', 'phase', 'dirty', 'magnet'], ['type', 'ia', 'supernova', 'sne', 'wd', 'ejection', 'example', 'iax', 'sn', 'companion', 'wd', 'characterization', 'hyper', 'runawayhypervelocity', 'hv', 'wd', 'light', 'analyse', 'gaium', 'dr', 'search', 'hv', 'wd', 'sequence', 'sub', 'hvs', 'wd', 'sub', 'm', 'runaway', 'sub', 'm', 'sub', 'm', 'velocity', 'fraction', 'type', 'ia', 'sne', 'contribution', 'scenario', 'origin', 'sne', 'rate', 'reverse', 'detonation', 'channel', 'velocity', 'hv', 'wd', 'iax', 'sne', 'origin', 'andor', 'contribution', 'candidate']], [['planar', 'body', 'spin', 'spin', 'glas', 'plethora'], ['safety', 'power', 'cause', 'safety', 'damage', 'system', 'resiliency', 'cyber', 'article', 'resiliency', 'cyber', 'resiliency', 'cp', 'combination', 'diversification', 'redundancy', 'inertium', 'system']], [['ashkinteller', 'phase', 'bifurcation', 'versu', 'tricriticalityendpoint'], ['advent', 'antenna', 'meeting', 'performance', 'generation', 'g', 'wireles', 'field', 'communication', 'wavefront', 'propagation', 'planar', 'field', 'risk', 'layer', 'security', 'challenge', 'communication', 'article', 'input', 'multiple', 'output', 'mimo', 'system', 'field', 'regime', 'performance', 'ffm', 'domain', 'distance', 'pl', 'direction', 'user', 'reinforcement', 'solution', 'optimize', 'power', 'allocation', 'selection', 'antenna', 'use', 'resource', 'wastage', 'security', 'rate']], [['equilibrium', 'phase', 'diagram', 'clock', 'model', 'order', 'equilibrium', 'order', 'spinodal', 'renormalization', 'group', 'theory'], ['architecture', 'performance', 'architecture', 'meet', 'time', 'aspect', 'architecture', 'los', 'function', 'role', 'time', 'series', 'analysi', 'error', 'mse', 'los', 'function', 'aim', 'los', 'challenge', 'los', 'function', 'conduct', 'time', 'series', 'los', 'model', 'performance', 'los', 'function', 'los', 'time', 'series', 'analysi', 'custom', 'los', 'work']], [['field', 'heisenberg', 'model', 'renormalization', 'group', 'theory'], ['video', 'novel', 'video', 'compression', 'problem', 'consist', 'multiple', 'video', 'sequence', 'video', 'contrast', 'coding', 'codec', 'complexity', 'compression', 'performance', 'nvr', 'codec', 'codec', 'design', 'parameter', 'model', 'model', 'compression', 'quantization', 'minimization', 'overview', 'work', 'field', 'work', 'deployment', 'video', 'introduction', 'video', 'codec', 'video', 'compression']], [['pott', 'clock', 'model'], ['vision', 'language', 'commonsense', 'vlm', 'cola', 'framework', 'language', 'model', 'language', 'communication', 'claim', 'dataset', 'coordination', 'building', 'methodology', 'surveillance', 'action', 'recognition', 'knowledge', 'base', 'vlm', 'information', 'enhance', 'solution', 'signal']], [['teller', 'phase', 'diagram'], ['ground', 'state', 'intersection', 'cu', 'scale', 'quantum', 'strategy', 'chemistry', 'spin', 'state', 'calculation', 'method', 'quantum', 'state', 'calculation', 'method', 'quantum', 'deflation', 'vqeac', 'determination', 'constraint', 'describe', 'energy', 'strategy', 'state', 'space', 'self', 'field', 'casscf', 'level', 'theory', 'energy', 'device']], [['teller', 'phase', 'diagram'], ['generation', 'wave', 'gw', 'concurrent', 'adaptability', 'attention', 'architecture', 'number', 'coalescence', 'gw', 'architecture', 'range', 'path', 'manner', 'feature', 'representation', 'analysi', 'hole', 'neutron', 'star', 'starblack', 'hole', 'time', 'series', 'noise', 'method', 'accuracy', 'overlap', 'generalization', 'ability', 'precession', 'eccentricity', 'advance', 'precision', 'versatility', 'gw', 'analysi']], [['phase', 'component', 'spin', 'spin', 'glas', 'liquid', 'phase', 'dirty', 'magnet'], ['slip', 'fault', 'event', 'north', 'subduction', 'zone', 'preparatory', 'phase', 'earthquake', 'use', 'template', 'gns', 'time', 'series', 'surface', 'motion', 'extract', 'noise', 'detect', 'moment', 'cube', 'duration', 'distribution', 'distribution', 'inference', 'gns', 'insar', 'megathrust', 'region', 'role', 'mechanism', 'area']], [['surface', 'chao', 'spin', 'glas'], ['zone', 'law', 'traction', 'separation', 'response', 'crack', 'tip', 'proces', 'material', 'fracture', 'proces', 'macroscopic', 'failure', 'behavior', 'form', 'zone', 'law', 'inverse', 'problem', 'field', 'form', 'traction', 'separation', 'relationship', 'fracture', 'proces', 'zone', 'field', 'network', 'pinn', 'betti', 'theorem', 'reciprocity', 'gap', 'account', 'crack', 'growth', 'scale', 'mode', 'show', 'pinn', 'traction', 'separation', 'range', 'zone', 'traction', 'separation', 'field', 'strain', 'strain', 'crack', 'zk', 'magnesium', 'alloy', 'ray', 'diffraction', 'traction', 'separation', 'relationship', 'damage']], [['measure', 'space'], ['advance', 'foundation', 'particle', 'density', 'theory', 'rdmft', 'refine', 'relate', 'concise', 'rdmft', 'identify', 'time', 'symmetry', 'notion', 'v', 'representability', 'scope', 'choice', 'hubbard', 'dimer', 'generalization', 'pair', 'space', 'comparison', 'representability', 'solution', 'pair', 'interaction', 'found', 'domain', 'sense', 'key', 'character', 'exchange', 'force', 'context', 'band', 'lattice']], [['runge', 'kuttum'], ['system', 'field', 'method', 'distribution', 'occupation', 'system', 'evidence', 'support', 'hypothesi', 'entropy', 'entropy', 'distribution', 'approximation', 'correlation', 'energy', 'evidence', 'correlation', 'energy', 'occupation', 'distribution', 'support', 'field', 'number', 'series', 'pilot', 'bond', 'chemical', 'footing', 'measure', 'correlation', 'energy', 'example', 'dmft', 'wang', 'rev', 'lett', 'tao', 'dft', 'j', 'chai', 'j', 'chem', 'phy', 'use', 'entropy', 'correlation']], [['machine', 'control'], ['ability', 'invent', 'novel', 'intelligence', 'science', 'method', 'proces', 'power', 'state', 'art', 'generative', 'diversity', 'python', 'literature', 'code', 'search', 'diversity', 'difficulty', 'space', 'example', 'manipulation', 'measure', 'difficulty', 'function', 'succes', 'rate', 'extitllama', 'b', 'state', 'art', 'llm', 'problem', 'solver', 'language', 'model', 'generate', 'diversity', 'target', 'goal', 'exploration', 'python', 'state', 'art', 'code', 'llm']], [['survey'], ['interface', 'projector', 'camera', 'system', 'interface', 'form', 'attempt', 'employ', 'network', 'hand', 'information', 'network', 'mb', 'hand', 'existence', 'hand', 'segmentation', 'fingertip', 'network', 'state', 'art', 'hand', 'segmentation', 'fingertip', 'localization', 'precision', 'range', 'system', 'detection', 'precision', 'localization', 'error', 'time', 'interaction', 'execution', 'time', 'm']], [['relu', 'activation', 'curse', 'dimensionality', 'sense'], ['array', 'aperture', 'scale', 'multiple', 'input', 'output', 'mimo', 'consideration', 'field', 'wavefront', 'beam', 'training', 'codebook', 'size', 'hence', 'nf', 'codebook', 'distance', 'elevation', 'angle', 'reveal', 'wavefront', 'channel', 'product', 'field', 'phase', 'term', 'codebook', 'beam', 'training', 'phase', 'beam', 'pattern', 'distance', 'elevation', 'angle', 'furthermore', 'codebook', 'beamforming', 'performance', 'dimension', 'codebook', 'size']], [['control', 'pre', 'exposure', 'prophylaxi', 'hiv', 'infection', 'jump', 'model'], ['density', 'theory', 'dft', 'chemistry', 'work', 'electron', 'density', 'matrix', 'theory', 'rdmft', 'inclusion', 'electron', 'density', 'matrix', 'rdm', 'correction', 'rdmft', 'dft', 'fock', 'elucidate', 'dependence', 'selection', 'information', 'density', 'theory', 'idmft', 'correction', 'hartree', 'fock', 'method', 'density', 'fock', 'relate', 'idmft']], [['bsde', 'pricing', 'deltum', 'gamma', 'multus', 'asset', 'bermudan'], ['localization', 'uav', 'accurate', 'operation', 'gnssgp', 'navigation', 'localization', 'technique', 'image', 'end', 'network', 'clip', 'model', 'correlate', 'geolocation', 'uav', 'satellite', 'map', 'image', 'orientation', 'feature', 'similarity', 'computation', 'flight', 'information', 'validate', 'model', 'performance', 'image', 'dataset', 'altitude', 'evaluation', 'region', 'location', 'feasibility', 'gns', 'localization', 'method']], [['detection', 'power', 'feature', 'segmentation', 'algorithm'], ['dark', 'sector', 'particle', 'symmetry', 'matter', 'dm', 'component', 'annihilation', 'heavier', 'dm', 'dm', 'sector', 'role', 'resultant', 'phenomenology', 'possibility', 'dm', 'symmetry', 'consider', 'particle', 'wimp', 'particle', 'pfimp', 'model', 'density', 'parameter', 'space', 'search', 'distinction', 'space', 'component', 'component', 'wimp', 'wimp', 'pfimp']], [['cerviformer', 'pap', 'cancer', 'classification', 'method', 'crossattention', 'latent', 'transformer'], ['challenge', 'density', 'theory', 'failure', 'treat', 'correlation', 'der', 'reaction', 'electron', 'density', 'matrix', 'rdm', 'generalization', 'dft', 'correlation', 'invariant', 'cumulant', 'rdm', 'generate', 'theory', 'convexity', 'capture', 'correlation', 'theory', 'dependence', 'strength', 'trace', 'electron', 'repulsion', 'barrier', 'rotation', 'ethylene', 'dissociation', 'benchmark', 'efficiency', 'dft', 'treatment', 'correlation', 'theory', 'prediction', 'interpretation', 'quantum']], [['detection', 'image', 'processing', 'case', 'utility', 'company'], ['management', 'water', 'distribution', 'conserving', 'water', 'problem', 'transformer', 'noise', 'alarm', 'prevention', 'framework', 'noise', 'frequency', 'selection', 'tnf', 'method', 'domain', 'knowledge', 'system', 'feature', 'dependence', 'wdn', 'addition', 'network', 'minority', 'smote', 'mode', 'collapse', 'issue', 'system', 'world', 'noise', 'importance', 'domain', 'knowledge', 'application', 'machine', 'sensor']], [['comparison', 'density', 'matrix', 'theory'], ['mapping', 'material', 'design', 'design', 'stres', 'strain', 'space', 'attention', 'learning', 'cut', 'random', 'analysi', 'cost', 'microstructure', 'space', 'autoencoder', 'va', 'connotation', 'time', 'consistency', 'task', 'stres', 'strain', 'prediction', 'problem', 'sequence', 'transformer', 'model', 'attention', 'mechanism', 'model', 'microstructure', 'sequence', 'weight', 'differential', 'los', 'function', 'capture', 'time', 'nature', 'stres', 'strain', 'proces', 'multus', 'optimization', 'target', 'search', 'domain', 'pixel', 'space', 'space', 'learning', 'prediction', 'inverse', 'design', 'design']], [['fallacy', 'conjecture'], ['panel', 'iv', 'estimator', 'sample', 'estimator', 'permutation', 'inference', 'procedure', 'demonstrate', 'effectivenes', 'simulation', 'exercise', 'shift', 'share', 'control', 'trial', 'application', 'impact', 'refugee', 'crisi', 'labor', 'estimator', 'capture', 'application', 'siv', 'estimator', 'iv']], [['generalization', 'density', 'theory', 'correlation'], ['intelligence', 'phenomenon', 'analysi', 'ass', 'publication', 'biology', 'reference', 'journal', 'period', 'rise', 'ai', 'trend', 'ai', 'fraction', 'output', 'science', 'agriculture', 'adoption']], [['field', 'method', 'theory'], ['cp', 'safety', 'application', 'manufacturing', 'power', 'cause', 'safety', 'damage', 'system', 'safety', 'cp', 'redundancy', 'operating', 'resilient', 'guarantee', 'safety', 'framework', 'compare', 'analysi', 'design', 'cp', 'architecture', 'article', 'framework', 'cp', 'methodology', 'safety', 'analysi', 'computation', 'control', 'cyber', 'subsystem', 'finite', 'number', 'system', 'model', 'system', 'formulate', 'problem', 'computation', 'control', 'safety', 'constraint', 'solution', 'compute', 'control', 'architecture', 'solution', 'clas', 'cp', 'incorporation', 'framework', 'case', 'cruise', 'control']], [['theory'], ['lyapunov', 'order', 'posse', 'property', 'attractor', 'invariant', 'point', 'describe', 'bifurcation', 'attractor', 'period', 'sacker', 'codimension', 'period', 'cascade', 'endomorphism', 'hnon', 'map']], [['tao', 'dft', 'continuum', 'model'], ['boson', 'show', 'advantage', 'quantum', 'boson', 'quantum', 'supremacy', 'boson', 'los', 'method', 'effect', 'los', 'hardware', 'post', 'selection', 'proces', 'quality', 'criterion', 'improve', 'performance', 'part', 'example', 'show', 'post', 'selection', 'method', 'experiment', 'test', 'pa', 'test', 'computation', 'los', 'mitigation', 'method', 'development', 'gb', 'quantum', 'algorithm']], [['approximation', 'correlation', 'energy'], ['separation', 'fb', 'method', 'novel', 'foreground', 'model', 'sparse', 'representation', 'csr', 'order', 'power', 'method', 'frame', 'foreground', 'background', 'capture', 'datum', 'specific', 'fb', 'proces', 'end', 'robust', 'fb', 'method', 'csr', 'model', 'model', 'formulate', 'fb', 'optimization', 'problem', 'characterization', 'frame', 'solution', 'optimization', 'problem', 'algorithm', 'convex', 'superiority', 'method', 'video', 'microscope', 'video']], [['field', 'method', 'correlation', 'calculation', 'density', 'theory'], ['field', 'power', 'law', 'random', 'matrix', 'plrbm', 'model', 'variation', 'power', 'law', 'exponent', 'delocalization', 'localization', 'phase', 'transition', 'examine', 'plrbm', 'model', 'help', 'floquet', 'operator', 'level', 'ratio', 'participation', 'ratio', 'floquet', 'reveal', 'drive', 'phase', 'transport', 'plrbm', 'model', 'time', 'model', 'level', 'transport', 'analysi', 'thue', 'morse', 'driven', 'system', 'range', 'model', 'counterpart', 'plrbm', 'model', 'localization', 'drive', 'time', 'system', 'transport', 'relaxation', 'infinite', 'temperature', 'state', 'side', 'plateau', 'subdiffusion', 'side', 'model', 'localization', 'delocalization', 'transition', 'model', 'plateau', 'subdiffusion', 'infinite', 'temperature', 'state', 'side']], [['progress', 'theory'], ['ability', 'counter', 'frequency', 'disturbance', 'rejection', 'lag', 'frequencydependent', 'time', 'shift', 'delay', 'introduction', 'clegg', 'integrator', 'phase', 'describing', 'function', 'delay', 'design', 'example', 'overshoot', 'addition', 'loop', 'frequency', 'disturbance', 'rejection', 'integrato', 'motion', 'control', 'benchmark', 'practice', 'wafer', 'computer']], [['density', 'theory', 'occupation'], ['clas', 'stochastic', 'transport', 'sot', 'endpoint', 'case', 'cost', 'function', 'growth', 'time', 'noise', 'explosion', 'rate', 'time', 'sot', 'value', 'function', 'zero', 'infinity', 'case', 'cost', 'function', 'growth', 'product', 'value', 'function', 'sot', 'mongekantorovich', 'problem', 'application', 'show', 'semimartingale', 'vector', 'rth', 'integrable', 'problem', 'problem', 'continuation', 'work']], [['density', 'theory', 'correlation'], ['generation', 'wave', 'strain', 'band', 'detect', 'neutron', 'star', 'bn', 'year', 'band', 'noise', 'gen', 'bn', 'rotation', 'earth', 'range', 'wave', 'complexity', 'gen', 'bn', 'minute', 'virgo', 'compression', 'speed', 'bn', 'order', 'quadrature', 'multus', 'binning', 'carry', 'order', 'inference', 'gen', 'signal', 'account', 'rotation', 'range', 'compression', 'problem', 'part', 'band', 'precise', 'sky', 'localisation', 'problem']], [['dispersion', 'method'], ['carbon', 'dioxide', 'energy', 'storage', 'system', 'energy', 'system', 'energy', 'utilization', 'carbon', 'performance', 'strategy', 'phase', 'change', 'generation', 'carbon', 'system', 'level', 'operation', 'carbon', 'capture', 'storage', 'cc', 'power', 'ga', 'pg', 'co', 'capture', 'utilization', 'level', 'model', 'phase', 'change', 'wind', 'solar', 'enhance', 'energy', 'absorption', 'life', 'cycle', 'cost', 'model', 'phase', 'change', 'carbon', 'carbon', 'trading', 'mechanism', 'policy', 'level', 'model', 'goal', 'optimization', 'carbon', 'method', 'system', 'carbon', 'energy', 'consumption', 'rate', 'cost', 'system', 'foundation']], [['energy', 'br', 'dmft', 'method'], ['scale', 'multiple', 'input', 'output', 'mimo', 'technology', 'generation', 'communication', 'field', 'nf', 'range', 'region', 'aim', 'answer', 'transciver', 'system', 'performance', 'region', 'end', 'channel', 'gpp', 'tr', 'channel', 'model', 'model', 'wavefront', 'stationarity', 'mimo', 'system', 'performance', 'gain', 'rate', 'simulation', 'field', 'ff', 'technique', 'channel', 'maximum', 'beam', 'gain', 'los', 'region', 'distance', 'rate', 'los', 'beam', 'training', 'necessity', 'transceiver', 'simulation']], [['exchangecorrelation', 'response', 'correlation', 'electron'], ['random', 'environment', 'dpre', 'polymer', 'diamond', 'graph', 'random', 'environment', 'limit', 'theorem', 'partition', 'function', 'regime', 'wherein', 'system', 'random', 'environment', 'sequence', 'diamond', 'graph', 'choice', 'number', 'number', 'case', 'model', 'b', 'work', 'case']], [['derivation', 'theory', 'role', 'hypercomplex'], ['phase', 'diagram', 'model', 'dimension', 'renormalization', 'group', 'theory', 'system', 'site', 'spin', 'orientation', 'pu', 'neighbor', 'spin', 'multiplicative', 'spin', 'phase', 'diagram', 'reverse', 'bifurcation', 'phase', 'renormalization', 'group', 'energy', 'neighbor']], [['energy', 'br', 'dmft', 'method'], ['generalization', 'su', 'schrieffer', 'heeger', 'model', 'interaction', 'los', 'gain', 'system', 'field', 'band', 'structure', 'edge', 'ssh', 'model', 'condition', 'gbc', 'point', 'band', 'gap', 'strength', 'interaction', 'value', 'line', 'gap', 'loop', 'interaction', 'condition', 'pbc', 'zak', 'phase', 'contribution', 'interaction', 'pbc', 'show', 'interaction', 'effect', 'half', 'limit', 'case', 'respect', 'system', 'case', 'spectrum', 'show', 'magnitude', 'strength', 'blg', 'show', 'model', 'interaction', 'clas', 'gbc', 'pbc', 'condition', 'apbc', 'antus', 'condition', 'ahbc', 'case', 'condition', 'interaction', 'show', 'edge', 'phase', 'interaction', 'strength', 'los', 'gain', 'term', 'difference', 'intercell', 'phase', 'edge', 'value', 'strength', 'value', 'bulk', 'correspondence', 'bbc', 'phase', 'ssh', 'model', 'skin', 'effect', 'nhse', 'phase']], [['range', 'density', 'matrix', 'singlet'], ['role', 'state', 'art', 'license', 'plate', 'recognition', 'dataset', 'bia', 'problem', 'computer', 'vision', 'community', 'literature', 'lpr', 'scenario', 'dataset', 'performance', 'bia', 'problem', 'lpr', 'context', 'mainland', 'china', 'signature', 'classification', 'model', 'source', 'dataset', 'license', 'plate', 'image', 'accuracy', 'discussion', 'attention', 'fact', 'cost', 'generalization', 'capability', 'importance', 'indication', 'generalization', 'world', 'performance']], [['conjecture'], ['ground', 'state', 'ga', 'phase', 'reference', 'character', 'occupation', 'tao', 'density', 'theory', 'dft', 'outperform', 'kohnsham', 'exchange', 'correlation', 'energy', 'explore', 'solvation', 'ground', 'state', 'reference', 'character', 'cost', 'dft', 'pcm', 'continuum', 'model', 'order', 'show', 'tao', 'dft', 'pcm', 'tao', 'pcm', 'water', 'pcm', 'presence', 'character', 'character', 'ga', 'phase']], [['jacobi'], ['thesi', 'regularity', 'fact', 'order', 'part', 'presence', 'order', 'operator', 'part', 'thesi', 'consider', 'clas', 'backward', 'kolmogorov', 'time', 'space', 'regularity', 'solution', 'schauder', 'problem', 'part', 'regularity', 'fokker', 'planck', 'equation', 'inequality', 'sobolev']], [['modulus'], ['occurrence', 'km', 'portion', 'hikurangi', 'subduction', 'zone', 'catalog', 'length', 'occurrence', 'renewal', 'proces', 'inference', 'distribution', 'model', 'recurrence', 'margin', 'part', 'margin', 'periodicity', 'strike', 'part', 'margin', 'part', 'evidence', 'w', 'earthquake', 'effect', 'sse', 'occurrence']], [['case'], ['delivery', 'viewpoint', 'video', 'fvv', 'popularity', 'ability', 'delivery', 'challenge', 'traffic', 'latency', 'traffic', 'decoding', 'transmission', 'novel', 'representation', 'format', 'viewpoint', 'representation', 'video', 'addres', 'dilemma', 'delivery', 'fv', 'nerv', 'traffic', 'delay', 'number', 'model', 'show', 'traffic', 'reduction', 'speed', 'fvv', 'codec', 'nerv']], [['picard', 'stack'], ['dml', 'embedding', 'input', 'decade', 'succes', 'dml', 'los', 'function', 'los', 'function', 'similarity', 'generalizability', 'dml', 'stage', 'matter', 'los', 'feature', 'extractor', 'model', 'improvement', 'los', 'generalize', 'los', 'los', 'function', 'end', 'paradigm', 'need', 'parameter', 'evaluate', 'machine', 'vision', 'shot', 'show', 'baseline', 'margin']], [['detection', 'slip', 'wavelet', 'analysi', 'gns'], ['spin', 'glas', 'system', 'outer', 'surface', 'renormalization', 'group', 'theory', 'bulk', 'dimension', 'surface', 'bulk', 'interaction', 'surface', 'spin', 'glas', 'absence', 'bulk', 'spin', 'glas', 'glas', 'spin', 'glas', 'sponge', 'surface', 'spin', 'glas', 'absence', 'bulk', 'spin', 'glas', 'phase', 'diagram', 'surface', 'spin', 'glas', 'phase', 'bulk', 'surface', 'spin', 'glas', 'phase', 'point', 'glas', 'renormalization', 'group', 'runaway']], [['idea', 'gns'], ['intelligence', 'certification', 'level', 'safety', 'safety', 'mind', 'map', 'ai', 'certification', 'ai', 'development', 'example', 'need', 'qualification', 'performance']], [['multivariate', 'drought', 'severity', 'index', 'term', 'case', 'river', 'basin'], ['succes', 'field', 'language', 'processing', 'interest', 'potential', 'mod', 'range', 'speech', 'prominence', 'speech', 'speech', 'recognition', 'speech', 'synthesi', 'speech', 'translation', 'speech', 'para', 'dialogue', 'integration', 'complexity', 'speech', 'variability', 'scarcity', 'speech', 'survey', 'bridge', 'speech', 'technology', 'speech', 'technology', 'landscape', 'resource', 'power', 'field', 'identify', 'speech', 'processing']], [['slip', 'activity', 'hikurangi', 'subduction', 'zealand'], ['merger', 'rate', 'density', 'history', 'neutron', 'history', 'element', 'formation', 'generation', 'wave', 'gw', 'merger', 'rate', 'density', 'history', 'gamma', 'ray', 'bn', 'merger', 'originate', 'bn', 'bn', 'merger', 'gw', 'laser', 'interferometer', 'wave', 'observatory', 'ligo', 'design', 'sgrb', 'gamma', 'ray', 'burst', 'monitor', 'constrain', 'merger', 'rate', 'density', 'history', 'z', 'sgrb', 'bn', 'merger', 'rate', 'density', 'accuracy', 'cent', 'ratio', 'jet', 'angle', 'event', 'rate', 'density', 'merger', 'rate', 'density', 'uncertainty', 'cent', 'gw', 'merger', 'rate', 'density', 'cent', 'cent', 'uncertainty', 'cent', 'simulation', 'constrain', 'delay', 'time', 'formation', 'rate', 'model', 'error', 'cent', 'redshift']], [['impact', 'gp', 'earth', 'deformation'], ['article', 'membership', 'control', 'method', 'frame', 'methodology', 'choice', 'donor', 'pool', 'judge', 'appropriatenes', 'design', 'performance', 'benchmark', 'case', 'country', 'basket', 'donor', 'pool', 'precision', 'robustnes', 'effect', 'eu', 'membership', 'integration', 'proces', 'divergence', 'heterogeneity', 'growth', 'member']], [['occurrence', 'slip', 'renewal'], ['control', 'range', 'finance', 'energy', 'management', 'world', 'development', 'machine', 'control', 'possibility', 'structure', 'time', 'space', 'network', 'reinforcement', 'decision', 'state', 'art', 'crossroad', 'machine', 'control']], [['detection', 'slip', 'peru', 'subduction', 'zone'], ['literature', 'graph', 'edge', 'variety', 'resistance', 'tn', 'compute', 'method', 'application', 'circuit', 'series', 'method', 'turn', 'number', 'grid', 'example', 'appearance', 'e', 'base', 'logarithm', 'graph', 'method']], [['evolution', 'term', 'slip', 'subduction', 'activity'], ['disease', 'firing', 'brain', 'processing', 'order', 'examine', 'regulate', 'synchronization', 'motor', 'brain', 'machine', 'investigation', 'suppression', 'power', 'pose', 'db', 'reinforcement', 'framework', 'activity', 'power', 'consumption', 'rl', 'algorithm', 'representation', 'td', 'policy', 'gradient', 'algorithm', 'stability', 'framework', 'noise', 'bursting', 'eliminate', 'evaluation', 'energy', 'point', 'convergence', 'actor', 'ac', 'actor', 'kronecker', 'region', 'policy', 'optimization', 'ppo']], [['detection', 'slip', 'peru', 'subduction', 'zone'], ['damage', 'behavior', 'focu', 'element', 'fe', 'simulation', 'issue', 'time', 'prediction', 'damage', 'morphology', 'angle', 'interlock', 'impact', 'simulation', 'damage', 'morphology', 'predictor', 'decoder', 'learning', 'model', 'attention', 'mechanism', 'model', 'time', 'damage', 'damage', 'development', 'model', 'feasibility', 'learning', 'damage', 'prediction', 'solution', 'challenge', 'damage', 'prediction', 'textile', 'time', 'monitoring', 'design', 'optimization']], [['patch', 'wise', 'modeling'], ['nobel', 'prize', 'foundation', 'life', 'alife', 'fm', 'opportunity', 'field', 'burden', 'design', 'trial', 'error', 'discover', 'time', 'realization', 'opportunity', 'vision', 'language', 'fm', 'search', 'life', 'asal', 'target', 'phenomenon', 'novelty', 'space', 'generality', 'asal', 'range', 'alife', 'particle', 'life', 'game', 'life', 'automatum', 'result', 'technique', 'discovery', 'lenium', 'game', 'life', 'quantification', 'way', 'paradigm', 'ingenuity']], [['video', 'representation', 'structure', 'patch', 'decoding'], ['field', 'video', 'compression', 'pursuit', 'quality', 'bit', 'goal', 'representation', 'inr', 'transform', 'frame', 'wise', 'pixel', 'wise', 'structure', 'network', 'parallelization', 'frame', 'wise', 'performance', 'introduce', 'novel', 'pixel', 'wise', 'inr', 'video', 'compression', 'state', 'art', 'wise', 'inr', 'par', 'performance', 'frame', 'wise', 'separation', 'information', 'network', 'motion', 'byproduct', 'segmentation', 'video', 'sequence', 'motion', 'compensate', 'method', 'video', 'stabilization']], [['survey', 'compression'], ['heat', 'equation', 'field', 'method', 'space', 'euler', 'maruyama', 'time', 'analogy', 'wiener', 'case', 'regularity', 'heat', 'equation', 'approximation', 'truncation', 'series', 'expansion', 'field', 'optimal', 'convergence', 'condition', 'regularity', 'noise', 'convergence', 'convergence', 'expectation', 'moment', 'approximation']], [['range', 'image', 'compression', 'lidar', 'point'], ['space', 'telescope', 'shear', 'level', 'error', 'control', 'shape', 'measurement', 'image', 'resolution', 'space', 'telescope', 'hst', 'principle', 'emulate', 'environment', 'investigate', 'point', 'spread', 'function', 'psf', 'model', 'calibration', 'galaxy', 'moment', 'shape', 'measurement', 'algorithm', 'galaxy', 'model', 'procedure', 'multiplicative', 'percent', 'achievement', 'pixel', 'interpolation', 'noise', 'noise', 'simulation', 'scale', 'hst', 'procedure', 'impact', 'estimate', 'calibration', 'bia', 'post', 'deconvolution', 'isotropisation', 'euclidisation', 'depth', 'analysi', 'accuracy', 'tinytim', 'hst', 'psf', 'star', 'fw', 'scatter', 'focu', 'filter', 'focu', 'value', 'density']], [['lnerv', 'representation', 'video', 'codec'], ['integration', 'power', 'injection', 'defense', 'detection', 'multistage', 'design', 'cp', 'co', 'design', 'secure', 'detection', 'edge', 'intelligence', 'recovery', 'mechanism', 'defense', 'reinforcement', 'future', 'resilience', 'grid', 'cro', 'sector', 'policy', 'coordination', 'secure', 'power']], [['nvc', 'framework', 'memory', 'video', 'compression'], ['weyl', 'dw', 'theory', 'space', 'time', 'footing', 'quantization', 'quantization', 'generalization', 'quantum', 'formalism', 'field', 'theory', 'quantization', 'poisson', 'work', 'quantization', 'relativity', 'relativity', 'tegr', 'tetrad', 'palatini', 'formulation', 'schrdinger', 'equation', 'quantum', 'tegr', 'relevant', 'quantization', 'analysi', 'theory', 'analysi', 'equation', 'contribution', 'quantum', 'tegr', 'argue', 'consistency', 'value', 'error', 'estimation', 'scale', 'varkappa', 'quantization', 'ma', 'gap', 'pure', 'gauge', 'sector', 'qcd']], [['canerv', 'content', 'representation', 'video', 'compression'], ['phase', 'diagram', 'model', 'dimension', 'renormalization', 'group', 'theory', 'system', 'site', 'spin', 'orientation', 'neighbor', 'spin', 'multiplicative', 'spin', 'phase', 'diagram', 'pair', 'bifurcation', 'reverse', 'bifurcation', 'phase', 'renormalization', 'group', 'energy', 'neighbor']], [['lottery', 'ticket', 'hypothesi', 'video'], ['stewart', 'platform', 'sinusoidal', 'direction', 'ankle', 'instability', 'concurrent', 'ankle', 'pain', 'stance', 'support', 'surface', 'analgesium', 'center', 'pressure', 'electromyography', 'tibiali', 'gastrocnemiu', 'analysi', 'post', 'analgesium', 'test']], [['coordinate', 'flow', 'pixel', 'video', 'representation'], ['information', 'extraction', 'layout', 'segmentation', 'behavior', 'pre', 'vision', 'work', 'method', 'analysi', 'activation', 'state', 'leveraging', 'need', 'part', 'model', 'information', 'analysi', 'affinity', 'layer', 'optimization', 'problem', 'descent', 'technique', 'scale', 'analysi', 'inter', 'image', 'pre', 'transformer', 'strategy', 'affinity', 'query', 'similarity', 'attention', 'scene', 'layout', 'affinity', 'value', 'vector', 'similarity', 'identity', 'result', 'query', 'information', 'flow', 'proximity', 'pathway', 'value', 'category', 'representation', 'pathway']], [['compression', 'point'], ['equilibrium', 'interest', 'skin', 'effect', 'particle', 'number', 'non', 'quench', 'particle', 'number', 'tendency', 'half', 'density', 'particle', 'number', 'distribution', 'charge', 'inflow', 'decrease', 'particle', 'number', 'hermiticity', 'growth', 'time', 'regime', 'skin', 'effect', 'accumulation', 'side', 'reduction', 'entanglement', 'entropy', 'moreover', 'presence', 'quantum', 'mpemba', 'effect', 'restoration', 'symmetry', 'body', 'symmetry', 'hermiticity']], [['pet', 'video', 'codec', 'content', 'representation'], ['date', 'galaxy', 'image', 'profile', 'influence', 'galaxy', 'characterisation', 'approximation', 'shear', 'calibration', 'quality', 'survey', 'demand', 'consideration', 'galaxy', 'deep', 'learning', 'method', 'create', 'space', 'telescope', 'hst', 'network', 'wavelet', 'transform', 'learn', 'point', 'spread', 'function', 'psf', 'hst', 'galaxy', 'instrument', 'vi', 'noise', 'convolution', 'generation', 'galaxy', 'model', 'case', 'tune', 'interpolation', 'space', 'index', 'half', 'distribution', 'distribution', 'model', 'distribution', 'input', 'capability', 'model', 'bia', 'galaxy', 'measurement', 'fit', 'complexity', 'kaiser', 'shape', 'measurement', 'algorithm', 'bia', 'difference', 'order', 'magnitude', 'index', 'distribution', 'detection', 'bia', 'image', 'difference', 'shape', 'measurement', 'method', 'morphology', 'stage', 'error', 'budget', 'survey']], [['image', 'compression', 'distortion'], ['generation', 'g', 'wireles', 'millimeter', 'terahertz', 'thz', 'spectrum', 'communication', 'transformation', 'integration', 'multus', 'multus', 'mimo', 'capacity', 'field', 'communication', 'planar', 'field', 'communication', 'beamforming', 'channel', 'estimation', 'wavefront', 'phenomenon', 'channel', 'estimation', 'beam', 'article', 'development', 'domain', 'field', 'field', 'communication', 'design', 'sparsity', 'analysi', 'efficacy', 'channel', 'estimation', 'beam', 'training', 'range', 'information', 'dimensionality', 'solution', 'pilot', 'case', 'channel', 'estimation', 'beam', 'training', 'domain', 'enhance', 'system', 'performance', 'efficiency', 'field', 'wireles']], [['fv', 'compression', 'viewpoint'], ['coalescence', 'phenomenon', 'space', 'point', 'coalescence', 'macroscopic', 'point', 'letter', 'band', 'theory', 'formulation', 'presence', 'dimensional', 'boundary', 'non', 'addition', 'explanation', 'localization', 'mechanism', 'coalescence', 'theory', 'non', 'way']], [['shot', 'view', 'synthesi', 'depth', 'splatting'], ['calculate', 'model', 'presence', 'qubit', 'interaction', 'whereasthe', 'analysi', 'information', 'majority', 'correlation', 'calculation', 'invariance', 'model', 'particle', 'permutation', 'quantify', 'subpart', 'system', 'percentage', 'contribution', 'gmc', 'order', 'body', 'signal', 'order', 'quantum', 'phase', 'model', 'quantum', 'quantum', 'fisher', 'information', 'qfi', 'detect', 'entanglement', 'dicke', 'model', 'field', 'realization', 'model']], [['snerv', 'spectrum', 'representation', 'video'], ['weconsider', 'task', 'distribution', 'ood', 'generalization', 'distribution', 'shift', 'confounder', 'z', 'shift', 'heterogeneity', 'predictor', 'generalization', 'domain', 'adaptation', 'acces', 'covariate', 'distribution', 'test', 'scenario', 'ood', 'robustnes', 'ztr', 'confounder', 'training', 'b', 'ptez', 'ptrz', 'c', 'training', 'distribution', 'accurate', 'scenario', 'literature', 'identifiability', 'identifiability', 'predictor', 'simplicity']], [['video', 'representation', 'modulation'], ['construct', 'obstruction', 'theory', 'dimension', 'scheme', 'sheaf', 'fold', 'clas', 'degree', 'therefore', 'define', 'compute', 'conjecture', 'ricolfi', 'computation', 'case', 'cobordism', 'theory', 'degeneration', 'argument', 'case', 'computation', 'scheme', 'toru', 'localization', 'toru', 'formula', 'obstruction', 'jouanolou', 'trick']], [['fcnr', 'representation', 'visualization'], ['focu', 'security', 'surge', 'security', 'attack', 'overview', 'sg', 'generation', 'transmission', 'distribution', 'consumption', 'survey', 'literature', 'review', 'security', 'machine', 'analysi', 'classification', 'control', 'monitoring', 'protection', 'component', 'stage', 'cyberattack', 'literature', 'conclusion', 'security', 'need', 'exploration', 'innovation', 'domain', 'roadmap', 'future', 'state', 'field', 'security']], [['joint'], ['generation', 'sequence', 'structure', 'datum', 'example', 'task', 'sequence', 'diffusion', 'phi', 'succes', 'language', 'generation', 'example', 'image', 'video', 'audio', 'vq', 'represent', 'application', 'precision', 'nature', 'hand', 'diffusion', 'datum', 'protein', 'molecule', 'material', 'accuracy', 'inability', 'purpose', 'multimodal', 'foundation', 'framework', 'token', 'prediction', 'diffusion', 'integration', 'diffusion', 'diffusion', 'precision', 'material', 'molecule', 'generation', 'state', 'art', 'performance', 'material', 'crystal', 'structure', 'prediction', 'state', 'art', 'structure', 'prediction', 'design', 'generation', 'efficacy', 'tool', 'datum', 'generation']], [['foreground', 'background', 'separation', 'concept', 'distillation', 'image', 'foundation'], ['point', 'interaction', 'body', 'body', 'interaction', 'point', 'dyson', 'form', 'approximation', 'interaction', 'time', 'energy', 'map', 'energy', 'energy', 'energy', 'range', 'feedback', 'range', 'fermion', 'fermion', 'coupling', 'regime', 'response', 'energy', 'quadrupole', 'response', 'sn']], [['diffusion', 'intelligence'], ['positioning', 'system', 'position', 'time', 'series', 'standard', 'precision', 'position', 'series', 'observation', 'earth', 'deformation', 'show', 'configuration', 'gp', 'constellation', 'navigation', 'satellite', 'correlation', 'analysi', 'gp', 'galileo', 'glonas', 'beidou', 'gp', 'sensitivity', 'resonance', 'geometry', 'time', 'station', 'correlation', 'gp', 'position', 'time', 'series', 'effect', 'geometry', 'absent', 'gns']], [['gd', 'dense', 'radiography', 'representation', 'vision', 'language', 'pre', 'training'], ['sensitivity', 'parameter', 'skin', 'effect', 'particle', 'disorder', 'hopping', 'body', 'system', 'work', 'examine', 'sensitivity', 'non', 'system', 'presence', 'random', 'nonzero', 'parameter', 'hopping', 'disorder', 'body', 'localization', 'disorder', 'stability', 'spectrum', 'show', 'chain', 'level', 'sensitivity', 'participation', 'behavior', 'quench', 'particle', 'density', 'population', 'imbalance', 'entanglement', 'entropy', 'charge', 'density', 'state', 'corroborate', 'localization', 'understanding', 'body']], [['layer'], ['splatting', 'radiance', 'field', 'view', 'synthesi', 'computational', 'time', 'quality', 'quality', 'lot', 'performance', 'work', 'addres', 'depth', 'splatting', 'method', 'shot', 'view', 'synthesi', 'use', 'depth', 'prediction', 'depth', 'los', 'constrain', 'shape', 'input', 'color', 'order', 'opacity', 'work', 'point', 'cloud', 'hence', 'quality', 'mitigate', 'retain', 'reconstruction', 'view', 'noise', 'ratio', 'similarity', 'index', 'similarity', 'effectivenes']], [['trade', 'diffusion', 'interpretability'], ['energy', 'storage', 'technology', 'stability', 'system', 'economy', 'proportion', 'energy', 'energy', 'structure', 'strategy', 'air', 'energy', 'storage', 'cae', 'power', 'cchp', 'model', 'cae', 'system', 'interference', 'control', 'efficiency', 'energy', 'management', 'reinforcement', 'algorithmtd', 'ac', 'algorithm', 'attention', 'basi', 'twin', 'policy', 'gradient', 'td', 'stability', 'robustnes', 'energy', 'dispatch', 'dispatch', 'accuracy', 'achievement', 'stability', 'economy', 'pathway', 'management', 'scale', 'energy', 'storage']], [['depth', 'image', 'pig', 'detection', 'time'], ['galaxy', 'push', 'measure', 'galaxy', 'result', 'source', 'configuration', 'galaxy', 'galaxy', 'situation', 'source', 'galaxy', 'galaxy', 'source', 'sample', 'survey', 'telescope', 'dark', 'energy', 'science', 'collaboration', 'iggl', 'way', 'ggl', 'magnification', 'galaxy', 'bia', 'way', 'combination', 'galaxy', 'probe', 'redshift', 'bia', 'find', 'improve', 'shear']], [['generate', 'ground', 'vision', 'language'], ['memory', 'cim', 'bottleneck', 'throughput', 'energy', 'efficiency', 'cim', 'logic', 'input', 'output', 'operation', 'cim', 'memory', 'computation', 'proces', 'complexity', 'understanding', 'cim', 'spectrum', 'classification', 'cim', 'memory', 'computation', 'output', 'elucidate', 'cim', 'spectrum', 'platform', 'comparing', 'taxonomy', 'memory']], [['foreground', 'separation', 'sparse', 'representation'], ['supply', 'electricity', 'accessibility', 'issue', 'design', 'analysi', 'energy', 'demand', 'area', 'kanur', 'indium', 'wt', 'photovoltaic', 'pv', 'bioga', 'generator', 'bg', 'battery', 'energy', 'storage', 'system', 'homer', 'software', 'present', 'cost', 'npc', 'cost', 'energy', 'coe', 'cost', 'design', 'system', 'reliability', 'capacity', 'shortage', 'pv', 'wt', 'bg', 'capacity', 'configuration', 'kwh', 'kwh', 'energy', 'generation', 'generation', 'diesel', 'generator', 'dg', 'supply', 'sensitivity', 'analysi', 'impact', 'system', 'npc', 'coe', 'cost', 'design', 'selection']], [['secure', 'diversity', 'diffusion'], ['quantum', 'superposition', 'entanglement', 'force', 'technology', 'speed', 'efficiency', 'engineering', 'superiority', 'quantum', 'engineering', 'quantum', 'outperform', 'scalability', 'coherence', 'reliance', 'depth', 'quantum', 'curve', 'adoption', 'complex', 'problem', 'advancement', 'quantum', 'hardware']], [['sketchseg', 'sketch', 'image', 'segmentation', 'pre', 'diffusion', 'model'], ['machinery', 'infrastructure', 'fault', 'diagnosi', 'efficiency', 'downtime', 'review', 'impact', 'learning', 'dl', 'fault', 'diagnosi', 'domain', 'accuracy', 'versatility', 'diverse', 'role', 'quality', 'diversity', 'representativenes', 'building', 'dl', 'roadmap', 'collaborative', 'development', 'application', 'game', 'review', 'dl', 'fault', 'diagnosi', 'machinery', 'reliability', 'efficiency']], [['image', 'segmentation', 'diffusion'], ['speed', 'day', 'scale', 'quantum', 'era', 'algorithm', 'work', 'method', 'rodeo', 'eigensolver', 'chip', 'qubit', 'exciton', 'transfer', 'chemical', 'accuracy', 'ground', 'hydrogen', 'molecule', 'scalability', 'vre', 'qubit', 'hydrogenhelium', 'ion', 'work', 'estimation', 'spectrum']], [[], ['dense', 'whereupon', 'hypervelocity', 'potential', 'speed', 'ejectum', 'gc', 'body', 'binarysingle', 'model', 'way', 'gc', 'mwgc', 'day', 'population', 'ejectum', 'star', 'center', 'population', 'stellar', 'dwarf', 'evidence', 'gc']], [['music', 'table', 'instrument'], ['panel', 'iv', 'estimator', 'sample', 'estimator', 'permutation', 'inference', 'procedure', 'demonstrate', 'effectivenes', 'simulation', 'exercise', 'shift', 'share', 'control', 'trial', 'application', 'impact', 'refugee', 'crisi', 'labor', 'estimator', 'capture', 'application', 'siv', 'estimator', 'iv']], [['hapticsound', 'learning', 'experience', 'instrument'], ['area', 'adopt', 'control', 'tackle', 'problem', 'model', 'control', 'architecture', 'system', 'identification', 'methodology', 'performance', 'robustnes', 'imperfect', 'extrapolation', 'oscillator', 'prototype', 'precision', 'motion', 'system']], [['interface', 'light'], ['integration', 'vehicle', 'vg', 'power', 'solution', 'enhance', 'stability', 'energy', 'energy', 'utilization', 'challenge', 'reliability', 'optimization', 'algorithm', 'goa', 'rule', 'energy', 'management', 'scheme', 'addres', 'problem', 'vg', 'optimize', 'system', 'configuration', 'rule', 'energy', 'management', 'scheme', 'energy', 'distribution', 'utilization', 'methodology', 'case', 'effectivenes', 'balance', 'cost', 'reliability', 'performance']], [['microcontroller', 'sound'], ['construct', 'schrdinger', 'equation', 'quantum', 'gravity', 'correspond', 'plane', 'connection', 'bundle', 'reproduce', 'space', 'time', 'emergence', 'acceleration', 'range', 'yukawa', 'connection', 'bundle', 'acceleration', 'square', 'root', 'constant', 'operator', 'schrdinger', 'equation', 'connection', 'acceleration', 'constant', 'effect', 'quantum', 'gravity', 'parameter', 'quantization', 'agreement', 'connection', 'scale', 'ma', 'gap', 'quantum', 'su', 'yang', 'theory']], [['echo'], ['neuron', 'interaction', 'chemical', 'coupling', 'function', 'model', 'behavior', 'quasi', 'scenario', 'formation', 'hyperchao', 'appearance', 'shilnikov', 'attractor', 'formation', 'appearance', 'phase', 'bursting']], [['characterization'], ['perspective', 'nfa', 'canonization', 'problem', 'minimization', 'exploration', 'space', 'equivalence', 'information', 'optimization', 'convexity', 'simulation', 'boost', 'performance', 'generality', 'subset', 'construction', 'brzozowski', 'evaluate', 'world', 'case', 'source', 'library']], [['dof', 'platform', 'rehabilitation', 'assessment', 'reaction', 'time', 'balance'], ['consistency', 'interpolation', 'result', 'generalization', 'error', 'kernel', 'interpolation', 'scale', 'hypothesi', 'space', 'interpolation', 'smoothnes', 'index', 'norm', 'index', 'hypothesi', 'space', 'decay', 'rate']], [['balance', 'rehabilitation', 'classification', 'review', 'end', 'effector'], ['service', 'vehicle', 'task', 'variety', 'number', 'introduction', 'vehicle', 'market', 'verus', 'car', 'information', 'retrieval', 'help', 'task', 'type', 'model', 'year', 'color', 'license', 'plate', 'challenge', 'world', 'car', 'combination', 'pre', 'similarity', 'los', 'verus', 'car', 'performance', 'precision', 'accuracy', 'license', 'plate', 'detection', 'model', 'plate', 'accuracy']], [['bar', 'balance', 'rehabilitation', 'framework'], ['complexity', 'multiplication', 'field', 'extension', 'basi', 'show', 'control', 'complexity', 'geometry', 'algebraic']], [['analysi', 'cro', 'talk', 'machine', 'rehabilitation'], ['asenkron', 'endstride', 'gcnn', 'salanma', 'asndan', 'birok', 'kullanlmaktadr', 'asenkron', 'motorlarda', 'mil', 'stator', 'rotor', 'bileenlerus', 'ile', 'ilgilidir', 'bu', 'bileenlerden', 'mil', 'yatum', 'karlalan', 'biridir', 'bu', 'tehisi', 'iin', 'genellikle', 'titreim', 'sinyallerus', 'kullanlmaktadr', 'endstriyel', 'ortamda', 'alan', 'motor', 'ayn', 'zelliklerde', 'bir', 'motor', 'bulmak', 'zor', 'olduundan', 'karlatrma', 'yaplarak', 'arzalarn', 'tespitus', 'yaplamamaktadr', 'bu', 'almada', 'titreim', 'sinyallerinin', 'zaman', 'mil', 'iin', 'toplanarak', 'transfer', 'renme', 'tabanl', 'bir', 'model', 'eitilmitir', 'daha', 'sonra', 'endstriyel', 'mil', 'arza', 'olan', 'motordan', 'ayn', 'benzer', 'bir', 'konumda', 'sinyaller', 'kullanlarak', 'endstrideki', 'byk', 'gl', 'motordaki', 'arza', 'belirlenmitir', 'yaplan', 'testler', 'sonucunda', 'endstrideki', 'motorda', 'kusurlarn', 'zerinde', 'doru', 'bir', 'ekilde', 'tespit', 'edildius', 'ispatlanmtr']], [['gait', 'pattern', 'generation', 'verification', 'analysi', 'model'], ['ga', 'model', 'system', 'force', 'instance', 'contrast', 'visualization', 'application', 'hence', 'dependence', 'control', 'variety', 'model', 'control', 'space', 'focu', 'lyapunov', 'lyapunov', 'zero', 'lyapunov', 'exponent', 'example', 'attractor', 'zero', 'lyapunov', 'exponent', 'onset', 'space', 'parametric', 'appearance', 'lyapunov', 'inclusion', 'orbit', 'manifold', 'exponent', 'synchronization', 'bifurcation', 'emergence', 'bifurcation']], [['design', 'evaluation', 'ankle', 'preparation', 'phase'], ['construct', 'th', 'root', 'line', 'picard', 'stack', 'genu', 'g', 'line', 'number', 'formula', 'formula', 'mumford', 'author', 'pagani', 'ricolfi', 'van', 'zelm', 'conjecture', 'chiodo', 'ramification', 'cycle', 'formula', 'r', 'spin', 'ramification', 'cycle']], [['pain', 'alleviation', 'balance', 'control', 'coordination', 'instability', 'sinusoidal'], ['graph', 'v', 'dominating', 'g', 'vertex', 'v', 'setminu', 'vertex', 'degxleq', 'degy', 'domination', 'number', 'gammastg', 'cardinality', 'dominating', 'domination', 'number', 'haj', 'vertex', 'sum', 'graph']], [['device', 'therapy', 'multiple', 'sclerosi'], ['language', 'image', 'recognition', 'image', 'text', 'pre', 'training', 'clip', 'inference', 'classification', 'image', 'diagnosi', 'inadequacy', 'image', 'category', 'gap', 'text', 'clip', 'disease', 'language', 'clas', 'knowledge', 'performance', 'addition', 'evidence', 'proxy', 'image', 'classification', 'image', 'instability', 'knowledge', 'proxy', 'mine', 'knowledge', 'clip', 'kpl', 'image', 'classification', 'optimization', 'multimodal', 'proxy', 'image', 'knowledge', 'knowledge', 'base', 'enrich', 'text', 'input', 'clip', 'classification', 'performance', 'image', 'zero', 'shot', 'image', 'classification', 'paradigm', 'mining', 'knowledge', 'clip', 'image', 'classification']], [['impedance', 'control', 'preparation', 'phase', 'platform'], ['sample', 'velocity', 'velocity', 'vgsr', 'km', 'sd', 'dr', 'lamost', 'dr', 'apogee', 'dr', 'galah', 'dr', 'gaium', 'sample', 'star', 'hv', 'escape', 'confidence', 'time', 'type', 'halo', 'hvs', 'type', 'velocity', 'hv', 'population', 'investigate', 'velocity', 'reconstruct', 'analysi', 'center', 'gc', 'metal', 'velocity', 'distance', 'gc', 'velocity', 'hv', 'suggesting', 'hypothesi', 'analysi', 'fefeh', 'diagram', 'analysi', 'velocity', 'picturestar', 'ejection', 'velocity', 'type', 'halo', 'population']], [[], ['microscale', 'technology', 'combination', 'field', 'temperature', 'gradient', 'electro', 'thermal', 'flow', 'analysi', 'performance', 'electro', 'flow', 'gradient', 'suspension', 'resonance', 'laser', 'fluid', 'flow', 'velocity', 'tracer', 'suspension', 'function', 'field', 'laser', 'power', 'concentration', 'relationship', 'velocity', 'fluid', 'particle', 'concentration', 'absorption', 'absorption', 'concentration', 'description', 'phenomenon', 'way', 'estimate', 'absorption', 'cro', 'information', 'structure', 'behavior', 'etp', 'aggregation']], [['efficiency', 'vaccination', 'efficacy', 'hpv'], ['genome', 'element', 'fe', 'simulation', 'enhance', 'efficiency', 'element', 'genome', 'element', 'method', 'simulation', 'efficiency', 'efficiency', 'accuracy', 'database', 'element', 'genome', 'simulation', 'machine', 'technology', 'combination', 'element', 'simulation', 'modulus', 'particle', 'fiber', 'random', 'pixel', 'particle', 'cost', 'accuracy', 'refinement', 'accuracy', 'stres', 'simulation', 'stres', 'refinement', 'stres']], [['control', 'outcome', 'review'], ['distribution', 'network', 'adn', 'voltage', 'integration', 'intermittent', 'energy', 'stage', 'multus', 'voltage', 'control', 'strategy', 'reinforcement', 'algorithm', 'voltage', 'network', 'power', 'los', 'stage', 'drl', 'actor', 'critic', 'sac', 'load', 'tap', 'security', 'day', 'stage', 'mode', 'voltage', 'regulation', 'strategy', 'time', 'dispatch', 'pv', 'energy', 'enforce', 'voltage', 'time', 'voltage', 'regulation', 'problem', 'decision', 'proces', 'multus', 'agent', 'sac', 'attention', 'mechanism', 'offline', 'training', 'learn', 'voltage', 'control', 'strategy', 'online', 'information', 'effectivenes', 'testing', 'ieee', 'bu', 'distribution', 'system', 'simulation', 'ability', 'addres', 'voltage', 'violation']], [['papillomaviru', 'vaccine', 'efficacy', 'arm', 'trial', 'proof', 'principle', 'costum', 'rica', 'vaccine', 'trial'], ['phase', 'change', 'memory', 'pcm', 'memory', 'technology', 'analog', 'memory', 'health', 'monitoring', 'network', 'acceleration', 'pattern', 'future', 'state', 'art', 'overview', 'pcm', 'technology', 'edge', 'body', 'monitoring']], [['control', 'adjustment', 'earlyphase', 'vaccine'], ['surveillance', 'work', 'detection', 'methodology', 'medium', 'detection', 'model', 'enhance', 'performance', 'scale', 'input', 'image', 'prediction', 'aggregation', 'copy', 'paste', 'augmentation', 'technique', 'training', 'dataset', 'diverse', 'drone', 'bird', 'post', 'processing', 'technique', 'consistency', 'mitigate', 'ranking', 'th', 'drone', 'vsbird', 'detection', 'challenge', 'conference', 'capability']], [['control', 'energy', 'distribution', 'voltage', 'stability'], ['water', 'energy', 'food', 'desalination', 'refrigeration', 'cogeneration', 'development', 'cogeneration', 'development', 'freshwater', 'production', 'storage', 'refrigeration', 'desalination', 'refrigeration', 'food', 'storage', 'refrigeration', 'desalination', 'development', 'capacity', 'desalination', 'refrigeration', 'source', 'water', 'potential', 'system', 'design', 'energy', 'integration', 'energy', 'synergy', 'temperature', 'evaporation', 'water', 'fluid', 'waste', 'heat', 'refrigeration', 'desalination', 'performance', 'water', 'recovery', 'desalination', 'effect', 'distillation', 'deeper', 'heat', 'integration', 'system', 'efficiency', 'dehumidification', 'water', 'production']], [['control', 'power', 'filter', 'power', 'quality', 'improvement'], ['language', 'image', 'clip', 'performance', 'range', 'corpu', 'pre', 'training', 'consumption', 'knowledge', 'distillation', 'modality', 'knowledge', 'distillation', 'vision', 'language', 'foundation', 'datum', 'introduce', 'clip', 'cid', 'distillation', 'mechanism', 'vision', 'language', 'foundation', 'model', 'image', 'balance', 'method', 'transfer', 'distillation', 'efficiency', 'method', 'image', 'text', 'performance', 'leverage', 'cluster', 'instance', 'discrimination', 'facilitate', 'knowledge', 'transfer', 'teacher', 'model', 'student', 'model', 'student', 'model', 'comprehension', 'cid', 'state', 'art', 'performance', 'downstream', 'probe', 'shot', 'classification']], [['reinforcement', 'perception', 'control', 'voltage', 'distribution'], ['sequenceability', 'sequenceability', 'show', 'group', 'g', 'involution', 'imathg', 'permutation', 'g', 'permutation', 'backslash', 'imathg', 'group', 'order', 'sequence', 'identity', 'element', 'g', 'identity', 'element', 'g']], [['voltage', 'control', 'distribution', 'integration'], ['method', 'construct', 'chain', 'order', 'system', 'function', 'solution', 'inverse', 'problem', 'structure', 'space']], [['volt', 'var', 'optimization', 'impala', 'framework', 'reinforcement'], ['machine', 'science', 'credit', 'assignment', 'performance', 'credit', 'assignment', 'world', 'life', 'light', 'history', 'intelligence', 'ai', 'field', 'ai', 'example', 'expert', 'history', 'ai', 'ai', 'text', 'chain', 'rule', 'regression', 'circa', 'hindsight', 'history', 'learning', 'computer', 'science', 'field', 'text', 'overview', 'blog', 'learning', 'survey', 'context', 'spanning', 'time', 'bang']], [['security'], ['revisit', 'topic', 'power', 'clas', 'letter', 'alphabet', 'map', 'prefix', 'thuemorse', 'word', 'morphism', 'hence', 'number', 'state', 'automaton']], [['impact', 'volt', 'var', 'volt', 'watt', 'regulation', 'accommodation', 'pv', 'distribution'], ['observation', 'robust', 'phase', 'neighbor', 'nnn', 'electron', 'density', 'matrix', 'renormalization', 'group', 'dmrg', 'diagram', 'leg', 'ladder', 'spin', 'interaction', 'region', 'level', 'half', 'emery', 'liquid', 'phase', 'charge', 'density', 'regime', 'parameter', 'system', 'density', 'regime', 'tomonaga', 'luttinger', 'tll', 'phase', 'region', 'correlation', 'quarter', 'level', 'dimer', 'bond', 'energy', 'system', 'symmetry', 'phase', 'leg', 'ladder', 'role', 'wider', 'cylinder', 'system', 'emergence', 'wave', 'phase', 'wider', 'system']], [['voltage', 'control', 'strategy', 'multus', 'mode', 'distribution'], ['aim', 'work', 'model', 'spde', 'clas', 'advection', 'diffusion', 'dimension', 'discretization', 'show', 'simulation', 'prediction', 'random', 'spde']], [['clip', 'td', 'clip', 'distillation', 'vision', 'language'], ['geolocation', 'navigation', 'satellite', 'range', 'localization', 'solution', 'gns', 'localization', 'system', 'day', 'night', 'image', 'odometry', 'vo', 'terrain', 'constraint', 'optimization', 'map', 'management', 'strategy', 'image', 'time', 'dd', 'geo', 'registration', 'method', 'search', 'control', 'localization', 'position', 'estimation', 'optimization', 'method', 'window', 'terrain', 'control', 'position', 'error', 'accumulation', 'position', 'drift', 'twenty', 'resilience', 'altitude', 'terrain', 'system', 'viewpoint', 'robust', 'stability', 'closure', 'localization', 'thermal', 'performance', 'night', 'time', 'error', 'gns', 'event', 'gns']], [['vt', 'cot', 'vision', 'text', 'chain', 'reasoning', 'diagnosi'], ['shapley', 'shubik', 'core', 'assignment', 'game', 'coalition', 'player', 'set', 'bipartition', 'make', 'zero', 'profit', 'therefore', 'profit', 'core', 'imputation', 'amount', 'core', 'imputation', 'guarantee', 'level', 'deficiency', 'core', 'imputation', 'solution', 'concept', 'core', 'imputation', 'comparison', 'solution', 'leximax', 'core', 'core', 'algorithm', 'adaptation', 'paradigm', 'engine', 'complementarity', 'work', 'technique', 'work', 'leximax', 'core', 'addition', 'work', 'ggsv']], [['vision', 'language', 'survey'], ['image', 'generation', 'area', 'disentanglement', 'representation', 'control', 'output', 'level', 'disentanglement', 'latent', 'representation', 'background', 'disentanglement', 'information', 'cholec', 'dataset', 'tool', 'background', 'disentanglement', 'opportunity', 'generate', 'custom', 'method', 'level', 'disentanglement']], [['future'], ['cette', 'thse', 'sinscrit', 'croisement', 'entre', 'lapprentissage', 'proposant', 'base', 'modlisation', 'contrle', 'sur', 'la', 'reprsentation', 'gnrale', 'sont', 'cadre', 'thorique', 'la', 'paramtrisation', 'avec', 'gradient', 'et', 'diffrentiation', 'automatique', 'linarisation', 'par', 'bouclage', 'lapprentissage', 'seule', 'tape', 'approximativement', 'linarisant', 'et', 'dun', 'rfrence', 'prsente', 'dattnuation', 'la', 'utilisation', 'systmatique', 'conception', 'commande']], [['crossmodal', 'knowledge', 'distillation', 'wordnet', 'image', 'classification'], ['variance', 'reduction', 'convergence', 'optimization', 'sequence', 'function', 'acces', 'iteration', 'application', 'family', 'optimization', 'figimathbfw', 'gi', 'oracle', 'issue', 'track', 'estimate', 'sequence', 'mathbf', 'gmathbfw', 'probe', 'mathcalo', 'complexity', 'method', 'multus', 'block', 'probe', 'variance', 'estimator', 'track', 'sequence', 'mathbf', 'gmathbfw', 'storm', 'error', 'correction', 'term', 'noise', 'help', 'msvr', 'estimator', 'lojasiewicz', 'pl', 'order', 'sample', 'dependence', 'convexity', 'parameter', 'auc', 'maximization', 'demonstrate', 'performance', 'estimator']], [['knowledge', 'mining', 'vision', 'language'], ['geolocalization', 'crucial', 'uav', 'navigation', 'satellite', 'precision', 'navigation', 'geolocalization', 'use', 'system', 'georeference', 'map', 'system', 'measurement', 'unit', 'camera', 'odometry', 'navigation', 'position', 'world', 'frame', 'geolocation', 'odometry', 'image', 'level', 'image', 'registration', 'frame', 'portion', 'vehicle', 'frame', 'geolocation', 'image', 'registration', 'navigation', 'result', 'odometry', 'vio', 'drift', 'geolocalization', 'performance', 'method', 'body', 'method', 'position', 'error', 'flight', 'position', 'error', 'flight']], [['tripartite', 'alignment', 'network', 'image', 'retrieval', 'momentum', 'distillation'], ['prove', 'abel', 'jacobi', 'section', 'ring', 'space', 'conjecture', 'pagani', 'ricolfi', 'van', 'part', 'broader', 'program', 'intersection', 'theory', 'mgn']], [['bridgeclip', 'bridge', 'inspection', 'vision', 'language', 'model'], ['tremor', 'relation', 'slip', 'slip', 'magnitude', 'surface', 'deformation', 'navigation', 'satellite', 'system', 'relationship', 'tremor', 'slip', 'occurrence', 'quantify', 'slip', 'wavelet', 'transform', 'dwt', 'wavelet', 'transform', 'time', 'series', 'time', 'frequency', 'domain', 'time', 'series', 'period', 'use', 'wavelet', 'time', 'series', 'slip', 'use', 'gns', 'transform', 'stack', 'wavelet', 'slip', 'number', 'tremor', 'vicinity', 'gns', 'apply', 'transform', 'time', 'series', 'slip', 'slip', 'event', 'peak', 'wavelet', 'verify', 'agreement', 'slip', 'slip', 'tremor', 'wavelet', 'detection', 'method', 'magnitude', 'event', 'demonstration', 'analysi', 'region', 'tremor', 'detect', 'slip']], [['cifd', 'information', 'flow', 'enhance', 'knowledge', 'distillation'], ['schrodinger', 'system', 'interaction', 'ma', 'resonance', 'case', 'system', 'symmetry', 'interest', 'construct', 'ma', 'resonance', 'case', 'ma', 'case', 'existence', 'result', 'application', 'invariance', 'system']], [['vision', 'language', 'navigation', 'history', 'cro', 'modal', 'feature', 'fusion', 'indoor', 'environment'], ['proces', 'vehicle', 'lane', 'decision', 'making', 'system', 'safety', 'comfort', 'decision', 'term', 'time', 'inference', 'system', 'comfort', 'safety', 'lane', 'change', 'safety', 'comfort', 'term', 'trajectory', 'prediction', 'future', 'term', 'information', 'compensate', 'term', 'variability', 'decision', 'decision', 'term', 'trajectory', 'prediction', 'lane', 'term', 'trajectory', 'prediction', 'model', 'predict', 'lane', 'change', 'decision', 'relationship', 'car', 'establishment', 'fuzzy', 'rule', 'library', 'vehicle', 'speed', 'acceleration', 'system', 'delay', 'time', 'delay', 'time', 'distance', 'dataset', 'prediction', 'model', 'simulation', 'road', 'road', 'decision', 'model', 'safety', 'comfort']], [['cognition', 'text', 'segmentation'], ['example', 'cut', 'ratio', 'min', 'cut', 'cost', 'function', 'cluster', 'factor', 'example', 'size', 'degree', 'order', 'yield', 'cost', 'function', 'case', 'regularization', 'term', 'sum', 'size', 'regularization', 'pairwise', 'connection', 'method', 'correlation', 'search', 'optimization', 'convergence', 'rate', 'problem', 'shift', 'pairwise', 'performance', 'method']], [['cascade', 'prompt', 'vision', 'language', 'model', 'adaptation'], ['hase', 'change', 'memory', 'pcm', 'space', 'utilization', 'bit', 'crystalline', 'state', 'information', 'non', 'volatility', 'period', 'memory', 'article', 'adaptability', 'decision', 'module', 'padm', 'module', 'information', 'non', 'volatility', 'memory', 'classification', 'influence', 'adaptability', 'volatility', 'memory', 'utilization', 'memory', 'proces', 'mark', 'combination', 'state', 'module', 'rate', 'time', 'complexity']], [['vision', 'language'], ['language', 'ability', 'perform', 'planning', 'evaluate', 'planning', 'variety', 'benchmark', 'feasibility', 'optimality', 'generalizability', 'constraint', 'decision', 'management', 'preview', 'model', 'pilot', 'memory', 'management', 'decision', 'generalization', 'planning']], [['clip', 'cid', 'clip', 'distillation', 'cluster', 'instance', 'discrimination'], ['criterion', 'reduction', 'transpose', 'map', 'basi', 'power', 'reduction', 'map', 'family', 'bound', 'reduction', 'detect', 'map', 'detect', 'range', 'entanglement', 'family', 'quantum', 'criterion', 'range', 'system', 'reduction', 'qubit', 'operation', 'state', 'w', 'state', 'noise', 'reduction', 'map']], [['alignment', 'fusion', 'image', 'retrieval'], ['degradation', 'stone', 'heritage', 'weathering', 'preservation', 'role', 'seepage', 'rock', 'interface', 'rock', 'matrix', 'restoration', 'layer', 'stone', 'coupling', 'model', 'rock', 'restoration', 'layer', 'interface', 'leshan', 'giant', 'buddha', 'stres', 'distribution', 'seepage', 'influence', 'seepage', 'interface', 'stres', 'restoration', 'layer', 'interface', 'rock', 'matrix', 'restoration', 'layer', 'protection', 'interface', 'rock', 'matrix', 'restoration', 'layer', 'cause', 'cracking', 'distribution', 'strength', 'bedrock', 'rock', 'matrix', 'interface', 'deformation', 'seepage', 'impact', 'protection', 'leshan', 'giant', 'heritage', 'seepage', 'conservation', 'preservation']], [['note', 'cbc', 'dbd', 'construction', 'lattice'], ['work', 'system', 'schrdinger', 'power', 'type', 'energy', 'setting', 'aim', 'demonstrate', 'versu', 'blow', 'dichotomy', 'case', 'existence', 'ground', 'state', 'concentration', 'compactnes', 'method', 'time', 'blow', 'convexity', 'argument', 'concentration', 'compactnes', 'rigidity', 'method']], [['component', 'digit', 'construction', 'lattice', 'point'], ['search', 'velocity', 'region', 'bulge', 'sample', 'clump', 'hypervelocity', 'ejection', 'hole', 'smbh', 'centre', 'galaxy', 'hvs', 'region', 'galaxy', 'detection', 'hvs', 'ejection', 'mechanism', 'centre', 'interaction', 'smbh', 'methodology', 'group', 'version', 'vistum', 'lactea', 'vvv', 'catalogue', 'virac', 'gaium', 'dr', 'sample', 'escape', 'velocity', 'candidate', 'hvs', 'centre', 'sample', 'dr', 'counterpart', 'escape', 'velocity', 'centre', 'candidate', 'hvs', 'candidate', 'hvs', 'centre', 'transverse', 'escape', 'velocity']], [['question', 'shevelev'], ['field', 'cover', 'galoi', 'group', 'let', 'divisor', 'space', 'kg', 'module']], [[], ['energy', 'landscape', 'shift', 'adoption', 'energy', 'power', 'system', 'modernisation', 'generation', 'dg', 'mg', 'energy', 'storage', 'energy', 'future', 'review', 'analysi', 'change', 'power', 'growth', 'power', 'integration', 'generation', 'voltage', 'hvdc', 'transmission', 'power', 'system', 'protection', 'control', 'transmission', 'distribution', 'infrastructure', 'ami', 'development', 'emphasi', 'intelligence', 'ai', 'operation', 'voltage', 'control', 'stability', 'system', 'integration', 'lifetime', 'energy', 'identification', 'efficient', 'power', 'system', 'infrastructure', 'future', 'machine', 'ml', 'energy', 'resilience', 'sustainability']], [['power', 'binary'], ['cooper', 'instability', 'jellium', 'model', 'parameter', 'r', 'leq', 'superconductivity', 'overhauser', 'vertex', 'function', 'renormalization', 'mechanism', 'instability', 'coulomb', 'interaction', 'phase', 'approximation', 'kohn', 'luttinger', 'contribution']], [['construction'], ['language', 'shot', 'inability', 'experience', 'robustnes', 'world', 'minecraft', 'introduce', 'experience', 'planning', 'framework', 'leverage', 'interaction', 'environment', 'inspiration', 'mental', 'llm', 'database', 'innovation', 'language', 'state', 'task', 'plan', 'llm', 'planner', 'generate', 'plan', 'environment', 'simulation', 'environment', 'level', 'memory', 'flexibility', 'generalization', 'shot', 'step', 'ai', 'experience']], [['verification', 'quantum', 'nature', 'network'], ['vacancy', 'center', 'promising', 'state', 'quantum', 'combination', 'time', 'concentration', 'sensitivity', 'measurement', 'electron', 'spin', 'center', 'time', 'field', 'electron', 'series', 'performance', 'diamond', 'concentration', 'sensitivity', 'field']], [['creation'], ['stabilization', 'force', 'infinity', 'rssler', 'system', 'bifurcation', 'birth', 'equilibrium', 'action', 'range', 'signal', 'spectrum', 'lyapunov', 'multus', 'hyperchao', 'chao', 'zero', 'lyapunov', 'development', 'chao', 'universality', 'direction', 'force', 'force', 'behavior', 'direction', 'force', 'plane', 'universality', 'picture', 'change', 'action', 'picture', 'model', 'stabilization', 'increase', 'period', 'force', 'model']], [['resonant', 'toru', 'bifurcation', 'map'], ['language', 'image', 'vision', 'language', 'space', 'vision', 'language', 'vl', 'concurrent', 'subset', 'clip', 'vl', 'benefit', 'shot', 'domain', 'inference', 'complexity', 'work', 'seek', 'answer', 'evaluation', 'protocol', 'commonsense', 'entailment', 'snli', 'question', 'vqa', 'variety', 'availability', 'second', 'clip', 'distillation', 'clip', 'td', 'clip', 'instance', 'clip', 'td', 'shot', 'domain', 'performance', 'standard', 'state', 'art', 'performance', 'vcr', 'image', 'text', 'snli', 'clip', 'td', 'shot', 'vqa', 'clip', 'td', 'improvement', 'shot', 'td', 'clip', 'distillation', 'code']], [['map'], ['interest', 'probability', 'example', 'pearson', 'johnson', 'non', 'family', 'tractability', 'flexibility', 'function', 'probability', 'number', 'location', 'feasibility', 'define', 'metalog', 'degeneracy', 'number', 'location', 'explicit', 'formula', 'precision', 'challenge', 'metalog', 'function', 'provide', 'feasibility', 'test', 'introduce', 'algorithm', 'metalog', 'precision']], [['stabilization', 'force', 'rssler', 'system', 'node', 'bifurcation'], ['phase', 'space', 'field', 'roll', 'inflation', 'orbit', 'type', 'point', 'point', 'point', 'field', 'view', 'phase', 'portrait', 'task', 'literature', 'state', 'picture', 'work', 'construct', 'set', 'depiction', 'manner', 'method', 'apply', 'field', 'inflation', 'inflation', 'pole', 'inflation', 'palatini', 'model']], [['emergence', 'self', 'lattice'], ['model', 'clock', 'dimension', 'renormalization', 'group', 'theory', 'renormalization', 'group', 'phase', 'diagram', 'axial', 'phase', 'order', 'phase', 'phase', 'diagram', 'cro', 'phase', 'diagram', 'phase', 'order', 'phase', 'phase', 'diagram', 'cro', 'spinodality', 'phase', 'diagram', 'reentrance', 'renormalization', 'group', 'transformation', 'model', 'kadanoff', 'approximate', 'lattice']], [['chao', 'radio', 'generator'], ['phase', 'heisenberg', 'spin', 'glas', 'system', 'component', 'spin', 'spin', 'glas', 'system', 'temperature', 'spin', 'glas', 'phase', 'temperature', 'number', 'dimension', 'phase', 'dirty', 'magnet', 'result', 'renormalization', 'group', 'lattice', 'lattice', 'phase', 'spin', 'glas', 'phase', 'phase', 'lyapunov', 'glas', 'chao', 'show']], [['zero', 'lyapunov'], ['explicit', 'role', 'computer', 'theatre', 'analysi', 'scene', 'work', 'represent', 'phase', 'recognition', 'step', 'recognition', 'action', 'instrument', 'detection', 'level', 'scene', 'target', 'context', 'transformer', 'hct', 'network', 'explore', 'level', 'relation', 'aggregation', 'module', 'hram', 'level', 'interaction', 'information', 'augment', 'task', 'representation', 'task', 'learning', 'icl', 'model', 'learn', 'task', 'wise', 'information', 'adapter', 'acces', 'performance', 'endoscopic', 'psi', 'ava', 'performance', 'method', 'state', 'art', 'margin', 'code']], [['creation', 'lyapunov'], ['article', 'heat', 'equation', 'mollification', 'parameter', 'case', 'geq', 'problem', 'date', 'article', 'question', 'prove', 'result', 'theorem', 'operator', 'divergence', 'system', 'regime', 'phenomenon', 'counterpart', 'differentiate', 'nature', 'case', 'case', 'result', 'sub', 'criticality', 'sub', 'moment', 'limit', 'moment', 'criticality', 'application', 'order', 'byproduct', 'estimate', 'exponent', 'polymer', 'l', 'regime']], [['appearance', 'contrast'], ['integration', 'extension', 'architecture', 'representation', 'formula', 'training', 'complexity', 'applicability', 'mainstream', 'classification', 'look', 'regularization', 'los', 'los', 'information', 'finite', 'order', 'logic', 'formula', 'network', 'work', 'citepsemanticlossxu', 'los', 'function', 'knowledge', 'los', 'probability', 'distribution', 'formula', 'satisfaction', 'probability', 'distribution', 'formula', 'domain', 'los', 'accommodate', 'order', 'language', 'finite', 'constraint', 'distribution', 'knowledge', 'logic', 'los', 'function', 'combination', 'learning', 'task', 'los', 'los', 'fisher', 'rao', 'distance', 'kullback', 'leibler', 'divergence', 'constraint', 'distribution']], [['analysi', 'drop', 'robot'], ['graph', 'structure', 'task', 'graph', 'machine', 'capture', 'relationship', 'structure', 'world', 'graph', 'gap', 'graph', 'structure', 'end', 'model', 'proces', 'graph', 'markov', 'estimation', 'problem', 'optimization', 'method', 'solution', 'justification', 'optimization', 'world', 'method', 'structure', 'graph', 'identification', 'edge', 'recovery']], [['chao', 'hyperchao', 'hindmarshrose'], ['result', 'circuit', 'array', 'array', 'graph', 'plane', 'form', 'circuit', 'array', 'conjecture', 'circuit', 'sub', 'case', 'proven']], [['look', 'dataset', 'bia', 'license', 'plate', 'recognition'], ['slip', 'fault', 'event', 'north', 'subduction', 'zone', 'preparatory', 'phase', 'iquique', 'earthquakewe', 'use', 'template', 'gns', 'time', 'series', 'surface', 'motion', 'peru', 'extract', 'noise', 'detect', 'moment', 'duration', 'reveal', 'subduction', 'distribution', 'distribution', 'inference', 'gns', 'insar', 'megathrust', 'region', 'role', 'mechanism', 'area']], [['drone', 'detection', 'scale', 'processing', 'augmentation'], ['date', 'galaxy', 'image', 'profile', 'influence', 'galaxy', 'characterisation', 'approximation', 'shear', 'calibration', 'quality', 'survey', 'demand', 'consideration', 'galaxy', 'deep', 'learning', 'method', 'create', 'space', 'telescope', 'hst', 'network', 'wavelet', 'transform', 'learn', 'point', 'spread', 'function', 'psf', 'hst', 'galaxy', 'instrument', 'vi', 'noise', 'convolution', 'generation', 'galaxy', 'model', 'case', 'tune', 'interpolation', 'space', 'index', 'half', 'distribution', 'distribution', 'model', 'distribution', 'input', 'capability', 'model', 'bia', 'galaxy', 'measurement', 'fit', 'complexity', 'kaiser', 'shape', 'measurement', 'algorithm', 'bia', 'difference', 'order', 'magnitude', 'index', 'distribution', 'detection', 'bia', 'image', 'difference', 'shape', 'measurement', 'method', 'morphology', 'stage', 'error', 'budget', 'survey']], [['verus', 'car', 'world', 'vehicle', 'information', 'retrieval'], ['wave', 'gw', 'year', 'reason', 'fast', 'tool', 'detector', 'estimation', 'information', 'matrix', 'fim', 'tool', 'problem', 'source', 'code', 'gwjulium', 'perform', 'fim', 'analysi', 'cbc', 'hole', 'star', 'star', 'hole', 'code', 'level', 'accuracy', 'case', 'telescope', 'et', 'configuration', 'km', 'l', 'cosmology', 'population', 'detection', 'guide', 'gw', 'monte', 'carlo', 'hmc', 'sampler']], [['number', 'plate', 'detection', 'recognition', 'world'], ['reinforcement', 'intelligence', 'environment', 'aspect', 'rl', 'input', 'evaluate', 'value', 'function', 'policy', 'value', 'track', 'policy', 'forget', 'information', 'problem', 'generalization', 'parameter', 'value', 'clas', 'value', 'policy', 'model', 'performance', 'policy', 'state', 'state', 'action', 'pair', 'distribution', 'rl', 'policy', 'actor', 'input', 'policy', 'value', 'function', 'employ', 'technique', 'policy', 'policy', 'pbvf', 'policy', 'architecture', 'policy', 'abstract', 'knowledge', 'environment', 'number', 'behavior', 'policy', 'gradient', 'value', 'method', 'search', 'policy', 'space', 'performance', 'control', 'network', 'goal', 'network', 'nn', 'return', 'training']], [['license', 'plate', 'resolution', 'layout', 'character', 'driven'], ['quasi', 'ma', 'transfer', 'roche', 'lobe', 'ma', 'sequence', 'star', 'e', 'orbit', 'qpe', 'emission', 'circularization', 'hole', 'bh', 'accretion', 'model', 'presence', 'time', 'accretion', 'disc', 'time', 'luminosity', 'quiescent', 'ray', 'emission', 'qpe', 'gsn', 'accretion', 'l', 'spectrum', 'lifetime', 'qpe', 'phase', 'yr', 'ma', 'los', 'pressure', 'interaction', 'star', 'accretion', 'disc', 'star', 'show', 'breakup', 'orbit', 'breakup', 'growth', 'mode', 'amplitude', 'ius', 'wave', 'emission', 'momentum', 'diffusion', 'case', 'ma', 'bh', 'mbh', 'conclude', 'velocity', 'ma', 'ratio']], [['predictor', 'selection'], ['sequence', 'number', 'order', 'subset', 'implement', 'noise', 'entropy', 'complexity', 'information', 'signal', 'timestamp', 'way', 'permutation', 'entropy', 'hnon', 'noise', 'wake', 'permutation', 'variability', 'signal', 'wake', 'feature', 'engineering', 'machine', 'signal', 'classification', 'accuracy']], [['integration', 'algorithmic'], ['overview', 'kolmogorov', 'list', 'space', 'theory', 'sobolev', 'regularity', 'theory', 'discus', 'life', 'analysi', 'kinetic']], [['integration', 'algorithmic'], ['optimization', 'function', 'composition', 'problem', 'suffer', 'sub', 'sample', 'batch', 'multus', 'level', 'variance', 'reduction', 'smvr', 'method', 'expectation', 'case', 'method', 'complexity', 'point', 'non', 'convex', 'convexity', 'condition', 'stage', 'wise', 'smvr', 'variant', 'complexity', 'convex', 'condition', 'convexity', 'batch', 'iteration', 'sum', 'case', 'f', 'algorithm', 'complexity', 'non', 'convex', 'condition', 'n', 'number', 'learning', 'method', 'convergence', 'practice']], [['splash', 'policy'], ['neutron', 'star', 'coalescence', 'neutron', 'temperature', 'mev', 'ray', 'calet', 'cgbm', 'konu', 'wind', 'axion', 'particle']], [['iv', 'estimation'], []], [[], ['intelligence', 'activity', 'age', 'datum', 'group', 'province', 'turkey', 'techniqueselectron', 'microprobe', 'analysi', 'ablation', 'ma', 'spectrometry', 'la', 'msin', 'quality', 'learning', 'm', 'range', 'trace', 'classification', 'accuracy', 'feasibility', 'rock', 'age', 'estimation', 'autoencoder', 'dimensionality', 'group', 'composition', 'detail', 'form', 'm', 'age', 'sensitivity', 'trace', 'network', 'dnn', 'rock', 'model', 'classification', 'accuracy', 'model', 'importance', 'quality', 'technique', 'selection', 'ai', 'geochronology', 'quality', 'element', 'model', 'performance', 'rock', 'age', 'estimation']], [['greed', 'difference'], ['diffusion', 'category', 'image', 'synthesi', 'video', 'generation', 'molecule', 'design', 'survey', 'analysi', 'body', 'investigate', 'architecture', 'intelligence', 'ai', 'methodology', 'design', 'generation', 'cro', 'domain', 'generation', 'dm', 'diverse', 'computer', 'vision', 'language', 'processing', 'image', 'synthesi', 'generation', 'vision', 'video', 'image', 'diagnosi', 'time', 'series', 'analysi', 'generation', 'molecule', 'generation', 'ai', 'downstream', 'order', 'progress', 'area']], [['multiagent', 'framework', 'extension', 'multitask', 'ml'], ['stres', 'analysi', 'step', 'design', 'method', 'standard', 'analysi', 'material', 'way', 'stres', 'analysi', 'machine', 'stres', 'analysi', 'fiber', 'material', 'system', 'learning', 'stres', 'field', 'prediction', 'field', 'number', 'arrangement', 'material', 'von', 'field', 'network', 'cnn', 'architecture', 'stres', 'number', 'encoder', 'decoder', 'network', 'material', 'image', 'input', 'field', 'image', 'size', 'image', 'perform', 'robustnes', 'analysi', 'sensitivity', 'prediction', 'accuracy', 'number', 'training', 'number', 'system', 'volume', 'fraction', 'finer', 'element', 'discretization', 'geometry', 'cost', 'goal', 'predict', 'field', 'number', 'information', 'stres', 'number']], [['multipath', 'multitask', 'ml'], ['remote', 'image', 'change', 'rsicc', 'interest', 'remote', 'language', 'rsicc', 'deficiency', 'precise', 'change', 'change', 'cc', 'method', 'knowledge', 'guidance', 'term', 'cc', 'cc', 'generalization', 'latent', 'knowledge', 'foundation', 'accurate', 'change', 'level', 'detection', 'cd', 'image', 'feature', 'extraction', 'multitask', 'aggregation', 'neck', 'information', 'interaction', 'cd', 'decoder', 'level', 'guidance', 'change', 'caption', 'decoder', 'language', 'model', 'generate', 'change', 'description', 'stability', 'training', 'cd', 'stage', 'strategy', 'method', 'levir', 'cc', 'cd', 'cd', 'cc', 'cc', 'generate', 'accurate', 'change', 'performance']], [['production', 'light', 'merger'], ['energy', 'use', 'energy', 'interval', 'method', 'energy', 'system', 'power', 'uncertainty', 'uncertainty', 'wind', 'power', 'output', 'system', 'operation', 'cost', 'wind', 'curtailment', 'cost', 'optimization', 'optimization', 'energy', 'system', 'optimization', 'uncertainty', 'transformation', 'quantum', 'algorithm', 'optimization', 'accuracy', 'distribution', 'k', 'scenario', 'combination', 'source', 'load', 'simulation', 'optimization', 'method', 'operation', 'cost', 'energy', 'system', 'utilization', 'energy']], [['nucleosynthesi'], ['light', 'deficit', 'electron', 'antineutrino', 'neutrino', 'oscillation', 'order', 'investigate', 'neutrino', 'radiation', 'core', 'collapse', 'oscillation', 'mikheyevsmirnovwolfenstein', 'effect', 'condition', 'model', 'progenitor', 'compare', 'event', 'oscillation', 'explosion', 'energy', 'ma', 'difference', 'star', 'explodability', 'need', 'addition', 'predict', 'neutrino', 'event', 'event', 'number', 'dune', 'search', 'signature', 'effect', 'flux']], [['multimessenger', 'gw'], ['convergence', 'power', 'security', 'datum', 'injection', 'attack', 'fdium', 'stage', 'market', 'mission', 'centric', 'defense', 'paradigm', 'power', 'power', 'cp', 'resilience', 'redundancy', 'diversity', 'time', 'loop', 'defense', 'mechanism', 'role', 'multiagent', 'coordination', 'edge', 'cloud', 'collaboration', 'operator', 'awarenes', 'response', 'mission', 'continuity', 'post', 'attack', 'recovery', 'reconstruction', 'reconfiguration', 'resilience', 'integration', 'cro', 'sector', 'collaboration', 'resilience', 'secure', 'energy', 'system']], [['symmetry', 'matter', 'neutrino', 'resonance', 'neutron', 'star', 'merger'], ['development', 'generation', 'wireles', 'efficiency', 'order', 'support', 'quality', 'transmission', 'technology', 'field', 'addres', 'issue', 'wave', 'propagation', 'article', 'input', 'output', 'field', 'shape', 'structure', 'planar', 'array', 'system', 'performance', 'array', 'reveal', 'deterioration', 'noise', 'ratio', 'snr', 'projection', 'aperture', 'field', 'crown', 'antenna', 'design', 'crown', 'array', 'design', 'order', 'addres', 'issue', 'role', 'projection', 'aperture', 'detail', 'shape', 'exact', 'form', 'probability', 'op', 'control', 'angle', 'user', 'way', 'projection', 'aperture', 'simulation', 'analysi', 'stability', 'angle']], [['core', 'collapse', 'ma', 'sterile'], ['spin', 'glas', 'system', 'outer', 'surface', 'renormalization', 'group', 'theory', 'bulk', 'dimension', 'surface', 'bulk', 'interaction', 'surface', 'spin', 'glas', 'absence', 'bulk', 'spin', 'glas', 'glas', 'spin', 'glas', 'sponge', 'surface', 'spin', 'glas', 'absence', 'bulk', 'spin', 'glas', 'phase', 'diagram', 'surface', 'spin', 'glas', 'phase', 'bulk', 'surface', 'spin', 'glas', 'phase', 'point', 'glas', 'renormalization', 'group', 'runaway']], [['b'], ['holder', 'continuity', 'fokker', 'planck', 'equation', 'condition', 'result', 'fokker', 'planck', 'order', 'part', 'equation', 'source', 'term', 'solution', 'order', 'part', 'boundary']], [['core', 'adaptation', 'framework'], ['pattern', 'analysi', 'spectrum', 'field', 'track', 'parameter', 'dependence', 'article', 'overview', 'reader', 'literature', 'knowledge']], [['core', 'b'], ['offer', 'framework', 'predict', 'uncertainty', 'use', 'distribution', 'ppd', 'step', 'diffusion', 'ppd', 'gp', 'dgm', 'surrogate', 'leverage', 'guidance', 'algorithm', 'dgm', 'sample', 'distribution', 'apply', 'gp', 'validate', 'counterpart', 'tune', 'target', 'gp', 'inverse', 'state', 'art']], [['investment', 'management', 'game', 'notion', 'core'], ['k', 'let', 'representation', 'function', 'rakn', 'number', 'integer', 'n', 'sum', 'k', 'function', 'bell', 'conjecture', 'number', 'theory', 'math', 'hung', 'conjecture', 'dombi', 'rnakn', 'result', 'anonkk', 'example', 'show']], [['los', 'generalizability', 'learning'], ['lensing', 'probability', 'self', 'depth', 'detectability', 'effect', 'imprint', 'star', 'ma', 'account', 'imprint', 'ma', 'diffraction', 'interference', 'ligo', 'virgo', 'kagra', 'telescope', 'bh', 'probability', 'von', 'kozai', 'bh', 'bbh', 'wolf', 'cusp', 'cluster', 'self', 'bh', 'bbh', 'migration', 'trap', 'nucleu', 'disk', 'imprint', 'disk', 'merger', 'h', 'polarization', 'probability', 'detectability', 'impact', 'parameter', 'ymax', 'increase', 'future', 'environment', 'bbh', 'self', 'eccentricity', 'polarization']], [['aviation', 'landscape'], ['novel', 'length', 'noncommutativity', 'method', 'ladder', 'length', 'plane', 'direction', 'parameter', 'combination', 'canonicalweylmoyal', 'type', 'lie', 'type', 'quantization', 'length', 'type', 'space', 'place', 'plane', 'case', 'operator', 'algebra', 'length', 'determine', 'ladder', 'length', 'operator', 'ladder']], [['speech', 'synthesi', 'vision', 'los'], ['processing', 'memory', 'technique', 'memory', 'bottleneck', 'compatibility', 'von', 'memory', 'perform', 'memory', 'array', 'logic', 'memory', 'ram', 'rram', 'method', 'design', 'memory', 'phase', 'change', 'memory', 'pcm', 'gate', 'pcm', 'mechanism', 'functionality', 'pcm', 'rram', 'form', 'set', 'execution', 'logic', 'function', 'memory', 'way', 'processing', 'memory']], [['learning'], ['ai', 'progress', 'availability', 'computation', 'invention', 'paradigm', 'leverage', 'machine', 'reinforcement', 'scale', 'self', 'ai', 'curiosity', 'center', 'exploration', 'part', 'progress', 'thesi', 'use', 'framework', 'repertoire', 'language', 'support', 'imagination', 'way', 'acces', 'language', 'ground', 'stand', 'scratch', 'effect', 'scienceworld', 'text', 'environment', 'impact', 'difficulty', 'feedback', 'goal', 'language', 'program', 'synthesi', 'generate', 'diversity', 'player', 'game', 'end', 'manuscript', 'discussion', 'framework']], [['z', 'dml', 'shot', 'learning', 'plant', 'leaf', 'disease', 'classification'], ['los', 'control', 'separability', 'compactnes', 'space', 'clas', 'clas', 'dml', 'softmax', 'operation', 'probability', 'optimization', 'pushpull', 'clas', 'los', 'domain', 'advantage', 'space', 'formation', 'softmax', 'separability', 'function', 'work', 'example', 'function', 'use', 'state', 'art', 'learning']], [['los', 'time', 'series', 'analysi'], ['thesi', 'deep', 'learning', 'compression', 'scale', 'differential', 'science', 'engineering', 'interaction', 'order', 'behavimy', 'operator', 'macroscopic', 'target', 'interest', 'microscopic', 'homogenization', 'compres', 'task', 'network', 'offline', 'online', 'algorithm', 'model', 'homogenization', 'learning', 'phase', 'network', 'coefficient', 'surrogate', 'map', 'dataset', 'surrogate', 'homogenization', 'algorithm', 'advantage', 'online', 'phase', 'network', 'homogenization', 'algorithm', 'phase', 'query', 'efficiency', 'example', 'simulation', 'evolution', 'time', 'multus', 'scale', 'framework', 'homogenization', 'problem', 'connection', 'representative', 'homogenization', 'method', 'decomposition', 'justify', 'viewpoint', 'approximation', 'theory', 'prove', 'decomposition', 'accuracy', 'network', 'number', 'non', 'network', 'discus', 'discretization', 'level', 'error', 'network', 'surrogate', 'model', 'feasibility', 'method', 'clas', 'multus', 'scale', 'example', 'test', 'diffusion', 'contrast', 'random', 'performance', 'method', 'time', 'heat', 'time', 'multus', 'scale']], [['intermittent', 'strategy', 'self', 'sketch', 'person', 'identification'], ['work', 'combine', 'cluster', 'ducc', 'theory', 'problem', 'quantum', 'eigensolver', 'vqe', 'explore', 'accuracy', 'simulation', 'chemistry', 'benchmark', 'ability', 'correlation', 'energy', 'space', 'consider', 'correlation', 'commutator', 'truncation', 'body', 'ducc', 'convergence', 'ground', 'state', 'bare', 'space', 'ducc', 'accuracy', 'load', 'quantum', 'processor']], [['image', 'similarity', 'application', 'hyundai', 'motor', 'company', 'case'], ['intelligence', 'chatgpt', 'thinking', 'lack', 'gap', 'thinking', 'disposition', 'intelligence', 'pctd', 'scale', 'ai', 'gai', 'thinking', 'acces', 'justice', 'search', 'evidence', 'search', 'truth', 'mindednes', 'systematicity', 'instrument', 'ai', 'broader', 'ai', 'ai', 'reliance', 'ai', 'development', 'self', 'education', 'pctd', 'gai', 'scale', 'marmara', 'thinking', 'mctd', 'relevance', 'assessment', 'robustnes', 'cro', 'sectional', 'university', 'poland', 'factor', 'ass', 'validity', 'reliability', 'gai', 'thinking', 'rating', 'chatgpt', 'response', 'variability', 'consensu', 'truth', 'domain', 'systematicity', 'ai', 'education', 'pctd', 'scale', 'literacy', 'develop', 'ai', 'engagement', 'reliance', 'ai', 'field', 'basi', 'learning', 'tool', 'reasoning', 'scale', 'method', 'evidence', 'pedagogy', 'integration', 'education']], [['application', 'verification', 'proces', 'wheel', 'design', 'similarity', 'hyundai', 'motor', 'company', 'case'], ['tool', 'quality', 'video', 'compression', 'redundancy', 'time', 'group', 'patch', 'wise', 'prediction', 'design', 'computation', 'group', 'encoding', 'time', 'video', 'video', 'representation', 'group', 'efficiency', 'perform', 'quantization', 'network', 'post', 'hoc', 'quantization', 'dataset', 'nirvana', 'quality', 'speed', 'compression', 'rate', 'contrast', 'video', 'inr', 'resolution', 'show', 'patch', 'wise', 'compression', 'inter', 'frame', 'motion', 'speed', 'deployment']], [['performance', 'text', 'classification', 'los', 'function'], ['photon', 'information', 'system', 'absence', 'fault', 'tolerance', 'quantum', 'error', 'mitigation', 'help', 'manage', 'mitigation', 'protocol', 'error', 'cancellation', 'error', 'mitigation', 'technique', 'error', 'cancellation', 'protocol', 'photon', 'value', 'estimation', 'inverse', 'photon', 'los', 'channel', 'sum', 'expectation', 'value', 'estimator', 'cost', 'protocol', 'amplification', 'series', 'photon', 'state', 'avoid', 'burden', 'amplification', 'photon', 'monte', 'estimate', 'ideal', 'expectation', 'value', 'validate', 'mitigation', 'protocol', 'vacuum']], [['design', 'implementation', 'image', 'classification', 'method', 'learning'], ['schrdinger', 'system', 'interaction', 'math', 'ann', 'show', 'system', 'ground', 'state', 'ma', 'parameter']], [['alpha', 'model', 'state', 'activity'], ['diffusion', 'machine', 'strategy', 'pre', 'domain', 'image', 'image', 'synthesi', 'radiology', 'concern', 'lack', 'assurance', 'evolution', 'image', 'generation', 'localization', 'scrutiny', 'realm', 'role', 'interpretability', 'trade', 'image', 'fidelity', 'interpretability', 'diffusion', 'text', 'interpretability', 'depth', 'exploration', 'divergence', 'set', 'design', 'development']], [['model', 'power', 'spectrum', 'decomposition'], ['host', 'gaples', 'superconductivity', 'interplay', 'electronelectron', 'electronphonon', 'superconductivity', 'momentum', 'frequency', 'loop', 'theory', 'phononplasmon', 'accuracy', 'tune', 'strength', 'coulomb', 'interaction', 'screening', 'superconductor', 'superconductivity', 'state', 'electronphonon', 'superconductivity', 'coupling', 'manner', 'screening']], [['lifespan', 'source', 'net'], ['video', 'compression', 'compres', 'video', 'model', 'codec', 'compression', 'efficiency', 'work', 'side', 'model', 'video', 'content', 'parameter', 'group', 'compensate', 'cost', 'transmitting', 'challenge', 'tune', 'video', 'codec', 'video', 'content', 'parameter', 'manner', 'content', 'entropy', 'distribution', 'compression', 'efficiency', 'size', 'acces', 'generality', 'validity', 'dcvc', 'hem', 'transformer', 'content', 'representation', 'improvement', 'compression', 'efficiency']], [['shift', 'pairwise', 'clustering'], ['article', 'suschriefferheeger', 'model', 'non', 'model', 'respect', 'hermiticity', 'system', 'eigenspectra', 'insulating', 'phase', 'los', 'gain', 'strength', 'system', 'insulator', 'limit', 'increase', 'los', 'gain', 'strength', 'transition', 'phase', 'gaples', 'phase', 'phenomenon', 'case', 'system', 'insulator', 'situation', 'hermiticity', 'phase', 'phase', 'transition', 'phase', 'stabilization', 'semi', 'phase', 'transition', 'insulating', 'semi', 'phase', 'question', 'system', 'possibility', 'edge', 'insulating', 'difference', 'addition', 'nature', 'case', 'gaples', 'semi', 'region']], [['correlation', 'learning', 'pairwise'], ['sclerosi', 'm', 'disease', 'treatment', 'disease', 'treatment', 'plan', 'level', 'disease', 'scale', 'monitor', 'deterioration', 'extremity', 'physiotherapist', 'opinion', 'physiotherapist', 'person', 'person', 'addition', 'information', 'impairment', 'patient', 'evaluation', 'system', 'world', 'treatment', 'plan', 'disease', 'importance', 'assessment', 'addres', 'problem', 'design', 'evaluation', 'device', 'device', 'sensitivity', 'opportunity', 'assessment', 'place', 'treatment', 'phase']], [['correlation'], ['treating', 'intelligence', 'discovery', 'development', 'chemical', 'vice', 'design', 'improvement', 'web', 'discovery', 'proces', 'meanwhile', 'ai', 'identification', 'structure', 'elucidation', 'ma', 'spectrometry', 'resonance', 'article', 'product', 'discovery', 'drug', 'development']], [['information', 'correlation', 'clustering'], ['building', 'change', 'detection', 'cd', 'ground', 'building', 'cd', 'detection', 'accuracy', 'extraction', 'therefore', 'feature', 'enhancement', 'network', 'fenet', 'uevt', 'accuracy', 'detection', 'encoder', 'vision', 'transformer', 'structure', 'detect', 'building', 'ability', 'network', 'part', 'vision', 'transformer', 'structure', 'feature', 'extraction', 'ability', 'design', 'channel', 'attention', 'mechanism', 'module', 'scam', 'channel', 'detection', 'ability', 'scale', 'module', 'usrm', 'extraction', 'module', 'sfem', 'feature', 'extraction', 'capability', 'attention', 'feature', 'fusion', 'module', 'saffm', 'convergence', 'integration', 'feature', 'information', 'saffm', 'prevent', 'detection', 'detection', 'information', 'los', 'cro', 'channel', 'context', 'aggregation', 'module', 'ccsam', 'information', 'aggregation', 'channel', 'dimension', 'evaluate', 'performance', 'model', 'model', 'state', 'art', 'sotum', 'algorithm', 'f', 'score', 'accuracy', 'coefficient', 'cd', 'cd', 'cdd', 'dataset']], [['search', 'community', 'discovery'], ['energy', 'spectrum', 'fermi', 'attraction', 'interaction', 'result', 'convergence', 'range', 'stability', 'instability', 'transition', 'subsystem', 'strength', 'g', 'einstein', 'condensate', 'energy', 'particle', 'g', 'energy', 'particle', 'collapse', 'condensate']], [['hypervelocity', 'velocity', 'distribution', 'formation', 'history'], ['cancer', 'death', 'advice', 'pap', 'constructive', 'type', 'cancer', 'attention', 'transfomer', 'classification', 'cancer', 'pap', 'model', 'size', 'input', 'model', 'attention', 'technique', 'input', 'transformer', 'module', 'scale', 'pap', 'state', 'classification', 'model', 'state', 'classification', 'herlev', 'model', 'method', 'classification', 'model', 'cancer', 'pap', 'cancer', 'treatment', 'effectivenes', 'testing', 'proces']], [['quasi', 'ma', 'transfer', 'nucleus'], ['ml', 'development', 'methodology', 'number', 'extension', 'system', 'methodology', 'accelerate', 'rate', 'innovation', 'increase', 'ml', 'accessibility', 'emergence', 'methodology', 'ml', 'development', 'representation', 'ml', 'use', 'extension', 'framework', 'extension', 'scale', 'multitask']], [['runaway', 'hypervelocity', 'dwarf', 'release'], ['loop', 'method', 'design', 'performance', 'response', 'state', 'disturbance', 'rejection', 'noise', 'attenuation', 'robustnes', 'gain', 'phase', 'margin', 'relation', 'create', 'limitation', 'theory', 'order', 'transfer', 'function', 'break', 'phase', 'relation', 'transfer', 'function', 'approximate', 'order', 'controller', 'cloc', 'simulation', 'example', 'controller']], [['ejection', 'hypervelocity', 'search', 'method'], ['intelligence', 'ai', 'interest', 'part', 'machine', 'learning', 'ml', 'computer', 'vision', 'language', 'processing', 'learning', 'field', 'machine', 'network', 'growth', 'integration', 'vision', 'language', 'lot', 'attention', 'result', 'way', 'review', 'review', 'state', 'design', 'problem', 'formulation', 'evaluation', 'reasoning', 'vision', 'language', 'representation', 'future', 'field', 'hope']], [['hypervelocity'], ['minimax', 'function', 'regression', 'variate', 'function', 'regression', 'function', 'h', 'space', 'smoothnes', 'variation', 'space', 'network', 'network', 'width', 'byproduct', 'size', 'bound', 'rademacher', 'complexity', 'interest']], [['velocity'], ['vertex', 'graph', 'g', 'identity', 'number', 'number', 'thetag', 'number', 'colorsk', 'k', 'g', 'number', 'g', 'sum', 'product', 'corona', 'product', 'product', 'number', 'threshold', 'g']], [['hypervelocity', 'dwarf', 'sn', 'companion', 'motion', 'survey', 'sn'], ['hamilton', 'jacobi', 'formulation', 'order', 'palatini', 'analysi', 'dedonder', 'weyl', 'covariant', 'formalism', 'reduction']], [['candidate', 'hypervelocity', 'clump', 'bulge'], ['slip', 'subduction', 'activity', 'positioning', 'system', 'relationship', 'activity', 'investigate', 'activity', 'detection', 'inversion', 'period', 'activity', 'coordinate', 'time', 'series', 'gp', 'network', 'inversion', 'filter', 'method', 'surface', 'analysi', 'activity', 'distribution', 'frequency', 'sse', 'sse', 'surface', 'frequency', 'day', 'region', 'surface', 'lead', 'increase', 'frequency', 'slip', 'trend', 'frequency', 'island', 'frequency', 'msr', 'frequency', 'ecr', 'monitoring', 'identification', 'activity']], [['disruption'], ['integration', 'power', 'efficiency', 'flexibility', 'integration', 'power', 'injection', 'operation', 'power', 'cp', 'system', 'resilience', 'power', 'cp', 'impact', 'system', 'security', 'stability', 'nature', 'detection', 'machine', 'detection', 'reconstruction', 'attack', 'localization', 'need', 'power', 'cp', 'threat']], [['hole', 'center', 'hypervelocity'], ['time', 'behavior', 'replicator', 'field', 'ecology', 'propagation', 'chao', 'property', 'persistence', 'n', 'replicator', 'system', 'existence', 'clas', 'ecology', 'fitnes', 'equivalence', 'need', 'condition', 'persistence', 'system', 'neutrality', 'dirichlet', 'probability', 'measure', 'case', 'theory', 'ecology']], [['hole', 'survival', 'guide', 'center', 'endure', 'disruption'], ['adjustment', 'baseline', 'increase', 'efficiency', 'adjustment', 'phase', 'sample', 'phase', 'uncertainty', 'precision', 'los', 'type', 'error', 'rate', 'inflation', 'undercoverage', 'confidence', 'addres', 'problem', 'adjustment', 'control', 'outcome', 'post', 'randomization', 'outcome', 'treatment', 'baseline', 'nco', 'post', 'randomization', 'selection', 'bia', 'describe', 'adjustment', 'adjustment', 'baseline', 'performance', 'model', 'selection', 'sample', 'variance', 'reanalysi', 'phase', 'vaccine', 'heu', 'post', 'baseline', 'precision', 'vaccine', 'effect', 'standard', 'adjustment', 'baseline']], [['ma'], ['work', 'deviation', 'resolve', 'performance', 'degradation', 'elevation', 'field', 'surface', 'ri', 'scheme', 'field', 'phase', 'user', 'link', 'field', 'scenario', 'scheme', 'impact', 'account', 'point', 'distance', 'elevation', 'handicap', 'addition', 'elevation', 'difference', 'enlarge', 'difference', 'gain', 'simulation', 'scheme', 'ri', 'case', 'incidence', 'signal', 'elevation', 'construction', 'gain', 'frequency', 'rate']], [['runaway', 'hypervelocity', 'dwarf', 'gaium', 'release'], ['nh', 'ladder', 'variety', 'driving', 'system', 'symmetry', 'c', 'presence', 'characterization', 'bulk', 'correspondence', 'bbc', 'presence', 'non', 'skin', 'effect', 'formalism', 'construction', 'brillouin', 'zone', 'gbz', 'step', 'impact', 'nhse', 'drive', 'sake', 'completenes', 'framework', 'skin', 'effect', 'system', 'step', 'drive', 'skin', 'effect', 'space', 'devoid', 'skin', 'effect', 'act', 'boundary', 'moreover', 'computation', 'non', 'bloch', 'gbz', 'pair', 'time', 'step', 'frequency', 'expansion', 'deal', 'drive', 'phase', 'coexistence', 'energy', 'limit', 'time']], [['behavior', 'graph'], ['introduce', 'gain', 'k', 'bilevel', 'k', 'convex', 'iteration', 'complexity', 'point', 'inner', 'computation', 'approximation', 'stop', 'gradient', 'performance', 'complexity', 'meet', 'convex', 'optimization', 'addres', 'issue', 'incorporate', 'variance', 'reduction', 'level', 'speed', 'type', 'variance', 'minimization', 'variance', 'complexity', 'highlight', 'spectrum', 'precision', 'precision', 'map', 'k', 'algorithm', 'convergence', 'effectivenes']], [['resistance'], ['algorithm', 'point', 'quasi', 'monte', 'carlo', 'integration', 'korobov', 'component', 'component', 'digit', 'digit', 'cbc', 'dbd', 'algorithm', 'function', 'space', 'show', 'advantage', 'algorithm', 'effort', 'dimension', 'integration', 'problem', 'digit', 'construction', 'integration', 'algorithm', 'respect', 'number', 'problem', 'cbc', 'dbd', 'algorithm', 'work', 'construction', 'lattice', 'point', 'integration', 'lattice', 'treat', 'function', 'integration', 'satisfy', 'error', 'convergence', 'order', 'implementation', 'speed', 'cbc', 'component', 'component', 'lattice', 'smoothnes', 'kritzer', 'complexity', 'improvement']], [['circuit', 'array'], ['body', 'motion', 'system', 'dyson', 'type', 'basi', 'bogoliubov', 'method', 'quasiparticle', 'random', 'phase', 'approximation', 'qrpa', 'structure', 'notion', 'quasiparticle', 'phonon', 'vertex', 'variation', 'bogoliubov', 'show', 'amplitude', 'method', 'fam', 'compute', 'qrpa', 'illustrate', 'validity', 'method', 'density', 'point', 'nucleon', 'medium', 'ma', 'cf']], [['quasi', 'floquet', 'prethermalization', 'spin', 'diamond'], ['experience', 'involve', 'museum', 'experience', 'knowledge', 'way', 'system', 'hapticsound', 'information', 'entertainment', 'interaction', 'instrument', 'exact', 'instrument', 'capture', 'machine', 'gesture', 'recognition', 'museum', 'visitor', 'interact', 'replica', 'system', 'time', 'feedback', 'emphasi', 'interaction', 'subsystem', 'pilot', 'usability', 'subsystem', 'usability', 'satisfactory', 'sensorimotor', 'machine', 'time', 'gesture', 'recognition']], [['thermalization', 'becbc', 'crossover'], ['component', 'processing', 'deteriorate', 'performance', 'field', 'integrity', 'longevity', 'effort', 'field', 'characterization', 'machine', 'stres', 'generator', 'rsg', 'field', 'dataset', 'proces', 'parameter', 'ml', 'model', 'architecture', 'structure', 'hyperparameter', 'ability', 'characterization', 'validate', 'effectivenes', 'prediction', 'accuracy', 'generalization', 'latent', 'structure', 'stres', 'distribution', 'rsg', 'performance', 'feasibility', 'stres']], [['time', 'floquet', 'neighbor'], ['design', 'trial', 'error', 'optimisation', 'performance', 'manufacturability', 'optimisation', 'simulation', 'manufacturability', 'shape', 'parameterisation', 'flexibility', 'effectivenes', 'limitation', 'optimisation', 'framework', 'sheet', 'metal', 'case', 'shape', 'optimisation', 'hot', 'framework', 'auto', 'decoder', 'shape', 'generator', 'network', 'cnn', 'model', 'manufacturability', 'evaluation', 'optimiser', 'shape', 'optimisation', 'surrogate', 'model', 'distance', 'auto', 'decoder', 'latent', 'shape', 'manufacturability', 'framework', 'performance', 'distribution', 'prediction', 'fidelity', 'shape', 'generation', 'efficiency', 'shape', 'optimisation']], [['roadmap', 'quantum'], ['dense', 'nucleus', 'cluster', 'alter', 'star', 'smbh', 'radiu', 'star', 'cluster', 'proof', 'concept', 'model', 'speed', 'smbh', 'influence', 'radiu', 'disruption', 'collision', 'star', 'product', 'merger', 'speed', 'impact', 'star', 'speed', 'periapsi', 'orbit', 'dissipation', 'speed', 'number', 'disruption', 'frequency', 'star', 'cluster', 'work', 'addres']], [['prethermalization', 'random', 'qubit', 'superconducting', 'processor'], ['heat', 'flow', 'shf', 'limit', 'heat', 'equation', 'dimension', 'temperature', 'work', 'caravenna', 'sun', 'zygoura', 'limit', 'limit', 'shf', 'work', 'formulate', 'law', 'existence', 'showing', 'noise', 'formulation', 'set', 'axiom', 'time', 'interval']], [['time', 'time', 'field', 'ising'], ['penetration', 'fault', 'distribution', 'network', 'dn', 'overcurrent', 'location', 'result', 'fault', 'location', 'optimization', 'accuracy', 'fault', 'tolerance', 'area', 'fault', 'location', 'method', 'optimization', 'distribution', 'grid', 'expression', 'switch', 'statu', 'function', 'impact', 'dg', 'overcurrent', 'reverse', 'learning', 'strategy', 'optimization', 'algorithm', 'diversity', 'population', 'levy', 'flight', 'control', 'random', 'walk', 'increase', 'randomnes', 'optimization', 'emergence', 'overcurrent', 'statu', 'fault', 'location', 'method', 'simulation', 'model', 'dn', 'photovoltaic', 'dg', 'ieee', 'simulation', 'fault', 'location', 'method', 'point', 'multus', 'point', 'case', 'method', 'accuracy', 'fault', 'tolerance']], [['time', 'rondeau', 'body'], ['taiji', 'space', 'wave', 'detection', 'project', 'wave', 'universe', 'sensitivity', 'hole', 'ma', 'ratio', 'wave', 'analysi', 'ground', 'virgo', 'kagra', 'accuracy', 'waveform', 'noise', 'spectrum', 'round', 'taiji', 'challenge', 'collection', 'simulation', 'platform', 'analysi', 'platform', 'integration', 'attitude', 'control', 'simulation', 'noise', 'wave', 'generation', 'time', 'delay', 'interferometry', 'effect', 'time', 'source', 'toolkit', 'triangle', 'simulation', 'step', 'detection', 'taiji', 'challenge', 'ius', 'triangle', 'development', 'taiji', 'analysi', 'end', 'end', 'observation']], [['k', 'ground', 'state', 'dicke', 'model'], ['latent', 'group', 'panel', 'deal', 'heterogeneity', 'way', 'focu', 'structure', 'manresa', 'estimator', 'literature', 'create', 'selection', 'heterogeneity', 'level', 'section', 'literature', 'practice', 'gfe', 'bonhomme', 'et', 'al', 'detail']], [['localization'], ['hole', 'vacuum', 'environment', 'influence', 'deformability', 'waveform', 'interpretation', 'wave', 'analysi', 'work', 'focu', 'generation', 'vacuum', 'evolution', 'deformability', 'measurability']], [['floquet', 'gibb'], ['power', 'safety', 'presence', 'safety', 'dimensionality', 'number', 'network', 'resilience', 'index', 'safety', 'resilience', 'index', 'safety', 'property', 'subsystem', 'resilience', 'index', 'subsystem', 'safety', 'safety', 'constraint', 'leverage', 'optimization', 'program', 'compute', 'resilience', 'index', 'resilience', 'safety', 'system', 'system', 'resilience', 'index', 'case', 'chemical', 'series']], [['blueprint', 'magnetometer', 'diamond', 'sensor', 'material', 'characterization'], ['prompt', 'method', 'vision', 'language', 'downstream', 'dataset', 'example', 'imagenet', 'k', 'role', 'prompt', 'discrimination', 'generalization', 'addres', 'framework', 'generalization', 'ability', 'structure', 'supervision', 'prompt', 'structure', 'restriction', 'practice', 'query', 'value', 'query', 'value', 'capacity', 'parameter', 'diversity', 'supervision', 'probability', 'language', 'image', 'clip', 'teacher', 'model', 'inter', 'clas', 'proces', 'generalization', 'ability', 'rpp', 'initialization', 'transferability', 'recognition', 'state', 'art', 'sotum', 'performance']], [['entanglement', 'detection'], ['lyapunov', 'map', 'map', 'consideration', 'hyperchaoticity', 'sense', 'wider', 'range', 'parameter', 'space', 'system', 'lyapunov', 'regime', 'distance', 'periodic', 'route', 'point', 'period', 'role', 'route', 'bifurcation', 'presence', 'flow']], [['detection', 'bipartite', 'quantum'], ['detection', 'entanglement', 'knowledge', 'quantum', 'state', 'challenge', 'implement', 'criterion', 'quantum', 'density', 'matrix', 'detection', 'bound', 'framework', 'illustrate', 'significance', 'method', 'state', 'information', 'formalism', 'qubit', 'modification', 'separability', 'criterion']], [['entanglement', 'characterization', 'quantum'], ['period', 'bang', 'evolution', 'messenger', 'fusion', 'center', 'sun', 'composition', 'evolution', 'core', 'collapse', 'merger', 'neutron', 'supernova', 'neutron', 'star', 'role', 'interaction', 'element', 'nucleosynthesi', 'supernova', 'neutrino', 'opacity', 'field', 'level', 'account', 'effect', 'nucleonnucleon', 'correlation', 'nucleonnucleon', 'bremsstrahlung', 'framework', 'compute', 'date', 'yield', 'prediction', 'nucleosynthesi', 'envelope', 'supernova', 'progenitor', 'star', 'explosion', 'energy', 'nucleosynthesi', 'flavor', 'nucleosynthesi']], [['visualization', 'qubit'], ['optimization', 'traction', 'separation', 'zone', 'model', 'electrode', 'failure', 'lithium', 'ion', 'abaqu', 'software', 'sim', 'flow', 'optimization', 'tool', 'simulation', 'analysi', 'failure', 'behavior', 'lithium', 'ion', 'battery', 'electrode', 'interface', 'fracture', 'energy', 'electrode', 'interface', 'performance', 'electrode', 'force', 'displacement', 'traction', 'separation', 'czm', 'traction', 'separation', 'collector', 'increase', 'interface', 'strength', 'state', 'force', 'energy', 'influence', 'state', 'force', 'collector', 'force', 'effect', 'state', 'force', 'enhance', 'accuracy', 'failure', 'behavior', 'electrode', 'interface']], [['detection', 'entanglement'], ['represent', 'framework', 'polarization', 'trust', 'conflict', 'group', 'k', 'limitation', 'tendency', 'size', 'optimization', 'imbalance', 'addition', 'approximation', 'algorithm', 'search', 'clustering', 'idea', 'design', 'search', 'algorithm', 'block', 'coordinate', 'frank', 'optimization', 'convergence', 'rate', 'structure', 'world', 'state', 'art', 'quality', 'efficiency']], [[], ['article', 'convergence', 'artistry', 'technology', 'event', 'orchestration', 'concert', 'istanbul', 'harbiye', 'cemil', 'topuzlu', 'air', 'theater', 'july', 'orchestration', 'event', 'nature', 'experience', 'advancement', 'milestone', 'evolution', 'art', 'age']], [['detection', 'quantum', 'k'], ['analysi', 'response', 'structure', 'detection', 'method', 'representation', 'response', 'frequency', 'time', 'series', 'frequency', 'response', 'representation', 'frequency', 'response', 'learning', 'tsvec', 'distance', 'detection', 'k', 'neighbor', 'algorithm', 'semi', 'learning', 'excitation', 'dataset', 'method', 'detection', 'rate', 'result', 'validity', 'representation', 'response']], [['separability', 'criterion', 'correlation', 'tensor'], ['attention', 'driving', 'car', 'lane', 'model', 'control', 'car', 'vehicle', 'follower', 'vehicle', 'fv', 'car', 'lane', 'anticipation', 'perception', 'preparation', 'relaxation', 'perception', 'index', 'human', 'create', 'perception', 'behavior', 'guidance', 'account', 'opacity', 'efficacy', 'technique', 'comfort', 'safety', 'uniformity', 'traffic', 'flow', 'time', 'motion', 'sicknes']], [['projection', 'qubit'], ['modulus', 'stratum', 'connection', 'piecewise', 'calculation', 'piecewise', 'artin', 'fan', 'presentation', 'chow', 'show', 'structure', 'knowledge', 'modulus', 'conjecture', 'conjecture', 'modulus', 'theory', 'intersection', 'case', 'explicit', 'chow', 'ring', 'piecewise', 'stack']], [['entanglement', 'realignment'], ['manufacturing', 'condition', 'fault', 'diagnosi', 'machinery', 'classifier', 'machine', 'size', 'type', 'hence', 'purpose', 'problem', 'classification', 'task', 'similarity', 'measure', 'reference', 'sample', 'classification', 'task', 'similarity', 'amount', 'hence', 'meet', 'world', 'similarity', 'framework', 'maintenance', 'pdm', 'machinery', 'state', 'machine', 'reference', 'vibration', 'signal', 'condition', 'time', 'analysi', 'transform', 'fft', 'time', 'transform', 'stft', 'vibration', 'similarity', 'similarity', 'measure', 'similarity', 'distance', 'measure', 'similarity', 'test', 'reference', 'space', 'hence', 'type', 'similarity', 'measure', 'similarity', 'accuracy', 'computational', 'machine', 'fft', 'similarity', 'performance']], [['characterization', 'entanglement', 'bipartite', 'system', 'application'], ['skin', 'effect', 'affinity', 'hermiticity', 'flow', 'transient', 'accumulation', 'population', 'proces', 'pumping', 'system', 'state', 'dark', 'state', 'subspace', 'interplay', 'dissipation', 'drive', 'work', 'show', 'pumping', 'skin', 'effect', 'spectrum', 'proces', 'state', 'space', 'signature', 'skin', 'effect', 'connection', 'pumping', 'engineering', 'condition', 'sideband', 'scheme', 'state', 'preparation']], [['difference', 'quality', 'change', 'detection'], ['interest', 'balance', 'rehabilitation', 'edge', 'rehabilitation', 'balance', 'way', 'platform', 'platform', 'motorsport', 'analysi', 'presence', 'talk', 'device', 'step', 'analysi', 'machine', 'analysi', 'talk', 'response', 'platform', 'friction', 'contact', 'design', 'solution', 'spring', 'constraint', 'system', 'dominance', 'role', 'friction', 'response', 'system', 'predictability', 'evaluation', 'cro', 'talk', 'platform', 'rehabilitation', 'cro', 'value', 'modulate', 'difficulty', 'machine']], [['cebsnet', 'change', 'background', 'network', 'dependency', 'change', 'detection'], ['intelligence', 'energy', 'management', 'ai', 'control', 'consumption', 'energy', 'power', 'time', 'analysi', 'energy', 'efficiency', 'method', 'ai', 'energy', 'management', 'creation', 'aggregation', 'fuzzy', 'theory', 'decision', 'information', 'setting', 'solve', 'energy', 'management', 'decision', 'series', 'hbcf', 'hamacher', 'power', 'aggregation', 'precision', 'stability', 'decision', 'power', 'aggregation', 'decision', 'strength', 'superiority', 'aggregation', 'energy', 'management', 'method', 'reliability', 'application', 'energy', 'distribution', 'usage', 'optimization']], [['change', 'detection', 'building', 'domain', 'strip', 'attention', 'dml', 'network'], ['improve', 'efficiency', 'vehicular', 'traffic', 'discus', 'cav', 'behavior', 'traffic', 'theory', 'traffic', 'bistability', 'phenomenon', 'congestion', 'driver', 'bistability', 'lead', 'phantom', 'traffic', 'model', 'explain', 'mechanism', 'bistability', 'driver', 'traffic', 'cav', 'behavior', 'show', 'penetration', 'cav', 'traffic', 'flow', 'eliminate', 'bistability', 'controller', 'mobility']], [['feature', 'consistency', 'alignment', 'difference', 'mining', 'remote', 'image', 'change', 'detection'], ['control', 'gene', 'expression', 'variety', 'part', 'exist', 'complex', 'manner', 'variety', 'work', 'survey', 'compare', 'categorize', 'goal', 'focu', 'core', 'collection', 'algorithm', 'convergence', 'date', 'coverage', 'comparison', 'categorization']], [['feature', 'enhancement', 'network', 'vision', 'transformer', 'building', 'change', 'detection', 'resolution', 'sensing'], ['language', 'language', 'distribution', 'ood', 'training', 'aim', 'causality', 'post', 'training', 'capt', 'prediction', 'estimation', 'extitevent', 'intervention', 'training', 'fine', 'tuning', 'generalization', 'ability', 'causal', 'inference', 'benchmark', 'cladder', 'reasoning', 'dataset', 'prontoqa', 'show', 'language', 'sft', 'distribution', 'id', 'ood', 'tuning', 'efficiency', 'capt']], [['bt', 'hrscd', 'resolution', 'feature', 'change', 'detection', 'network', 'decoding', 'branch'], ['size', 'effect', 'strength', 'discretenes', 'stem', 'heterogeneity', 'relationship', 'macroscopic', 'mesoscopic', 'challenge', 'size', 'effect', 'concrete', 'rate', 'effect', 'emphasi', 'influence', 'random', 'meso', 'component', 'distribution', 'investigate', 'tensile', 'strain', 'model', 'dataset', 'edge', 'mortar', 'matrix', 'coarse', 'interface', 'transition', 'network', 'capture', 'potential', 'non', 'relationship', 'meso', 'structure', 'strain', 'rate', 'model', 'size', 'stres', 'solution', 'size', 'effect', 'law', 'sd', 'tensile', 'strength', 'propagation', 'bp', 'network', 'enhance', 'rationality', 'verification', 'formula', 'response', 'concrete', 'need', 'tool', 'size', 'effect']], [['change', 'detection', 'model', 'completenes'], ['density', 'parameter', 'bound', 'transpose', 'definition', 'realignment', 'result', 'criterion', 'multipartite', 'quantum', 'conclusion', 'entanglement', 'criterion', 'method', 'detect']], [['reinforcement', 'augmentation', 'change', 'detection'], ['advent', 'radio', 'provide', 'resolution', 'lensing', 'shape', 'measurement', 'development', 'novel', 'lensing', 'radio', 'shape', 'measurement', 'radio', 'waveband', 'accuracy', 'deep', 'learning', 'framework', 'deepshape', 'precision', 'deepshape', 'module', 'plug', 'play', 'image', 'reconstruction', 'half', 'splitting', 'method', 'hq', 'pnp', 'module', 'measurement', 'network', 'point', 'spread', 'function', 'image', 'framework', 'radio', 'ska', 'mid', 'array', 'configuration', 'hq', 'pnp', 'algorithm', 'algorithm', 'deepshape', 'accuracy', 'radio', 'shape', 'measurement', 'method', 'radiolensfit', 'prediction', 'time', 'applicability', 'bia', 'meeting', 'ska', 'mid', 'bia', 'order', 'magnitude', 'level', 'calibration', 'technique', 'quality']], [['cc', 'image', 'change', 'knowledge', 'guidance'], ['maintenance', 'pdm', 'classifier', 'state', 'size', 'type', 'use', 'maintenance', 'similarity', 'pdm', 'sb', 'pdm', 'software', 'classification', 'task', 'similarity', 'measure', 'reference', 'sample', 'classification', 'sb', 'pdm', 'software', 'accuracy', 'machine']], [['island', 'energy', 'transmission', 'reinforcement', 'learning'], ['tight', 'symmetry', 'coalescence', 'pc', 'version', 'point', 'spectrum', 'pair', 'reflection', 'center', 'reflection', 'symmetry', 'literature', 'construction', 'clas', 'spectrum', 'order', 'point', 'orthogonality', 'los', 'norm', 'time', 'evolution']], [['scheduling', 'energy', 'system', 'phase', 'change', 'carbon', 'dioxide', 'energy', 'storage', 'carbon'], ['interplay', 'hermiticity', 'spin', 'orbit', 'interest', 'matter', 'ground', 'expansion', 'einstein', 'momentum', 'gain', 'los', 'trap', 'method', 'impact', 'hermiticity', 'ground', 'dispersion', 'relation', 'ma', 'momentum', 'gain', 'los', 'bec', 'ma', 'lead', 'self', 'interference', 'effect', 'acceleration', 'force', 'order', 'point', 'link', 'point', 'energy', 'dispersion', 'relation', 'order', 'point', 'energy', 'ma', 'impact', 'addition', 'result', 'bec', 'ma', 'los', 'expansion', 'self', 'interference', 'effect', 'rate', 'expansion', 'ma', 'gain', 'los', 'engineering', 'bec', 'body']], [['method', 'energy', 'system', 'hcng', 'certificate', 'carbon', 'trading', 'interaction', 'mechanism'], ['difference', 'trend', 'assumption', 'presence', 'control', 'control', 'group', 'identification', 'introduce', 'forward', 'difference', 'science', 'discus', 'estimation', 'inference', 'document']], [['method', 'energy', 'system', 'ccspg', 'system', 'mutation', 'algorithm'], ['approximation', 'random', 'solution', 'equation', 'spde', 'noise', 'spde', 'correlation', 'length', 'field', 'method', 'representation', 'solution', 'approximation', 'quadrature', 'surface', 'element', 'method', 'error', 'analysi', 'method', 'illustrate']], [['privacy', 'defense', 'power'], ['vertex', 'identity', 'automorphism', 'preserve', 'g', 'graph', 'g', 'number', 'k', 'g', 'calculate', 'product', 'graph', 'number']], [['multus', 'domain', 'target', 'defense', 'security', 'power', 'review'], ['risk', 'field', 'drf', 'way', 'safety', 'drf', 'eye', 'view', 'vehicle', 'level', 'vehicle', 'ev', 'traffic', 'environment', 'fill', 'gap', 'model', 'ego', 'vehicle', 'view', 'collision', 'ev', 'model', 'geometry', 'motion', 'influence', 'coefficient', 'motion', 'ev', 'state', 'information', 'location', 'velocity', 'basi', 'safety', 'assessment', 'vehicle', 'risk', 'field', 'lane', 'risk', 'field', 'lmrf', 'model', 'design', 'trajectory', 'planning', 'method', 'rtpm', 'horizon', 'strategy', 'prediction', 'horizon', 'complexity', 'simulation', 'traffic', 'applicability', 'rtpm', 'drf', 'model', 'perspective']], [['optimization', 'time', 'use', 'electricity', 'price', 'demand', 'response', 'consumer', 'classification', 'model'], ['challenge', 'non', 'dilation', 'method', 'system', 'symmetry', 'qubit', 'resonance', 'system', 'measure', 'number', 'addition', 'topology', 'structure', 'energy', 'band', 'way', 'exploration', 'symmetry']], [['mission', 'defense', 'loop', 'power', 'cp'], ['sequence', 'j', 'p', 'allouche', 'j', 'shallit', 'whetherthesubwordcomplexityofthesubsequencetnn', 'attainsthemaximalvaluethisproblemwa', 'qt', 'hn', 'degh', 'allthesubsequencesthnn', 'attainthemaximalsubwordcomplexitythenheaskedwh']], [['cooperation', 'mechanism', 'electricity', 'ga'], ['fokkerplanck', 'equation', 'domain', 'maxwell', 'reflection', 'condition', 'ultracontractivity', 'hypocoercivity', 'operator', 'deduce', 'convergence', 'rate', 'solution', 'equation', 'state', 'ma', 'datum']], [['design', 'paradigm', 'shift', 'power', 'cp', 'datum', 'injection'], ['review', 'theory', 'picture', 'microscopic', 'focu', 'microscopic', 'response', 'detail']], [['energy', 'design', 'analysi', 'homer'], ['hypervelocity', 'centre', 'gc', 'potential', 'infer', 'ma', 'function', 'history', 'hvs', 'dozen', 'work', 'use', 'method', 'hv', 'infer', 'position', 'motion', 'comparison', 'photometry', 'hv', 'ground', 'velocity', 'ejection', 'ejection', 'rate', 'ejection', 'rate', 'significance', 'hvs', 'gaium', 'catalogue', 'interval', 'sequence', 'indication', 'time', 'ejection', 'rate', 'hvs', 'origin', 'hv']], [['power', 'system', 'reliability', 'assessment', 'machine', 'role'], ['focu', 'comparability', 'outcome', 'risk', 'osteoporosi', 'decision', 'effectivenes', 'safety']], [['scheduling', 'strategy', 'air', 'energy', 'storage', 'system'], ['power', 'system', 'scenario', 'use', 'job', 'power', 'quality', 'pq', 'voltage', 'sag', 'swell', 'voltage', 'advancement', 'custom', 'power', 'energy', 'cpd', 'point', 'effect', 'supply', 'system', 'role', 'role', 'cpd', 'stability', 'grid', 'generation', 'improvement', 'literature', 'therefore', 'literature', 'reference', 'volume']], [['review', 'datum', 'injection', 'power', 'cp', 'detection', 'resilience'], ['query', 'optimization', 'technique', 'work', 'opportunity', 'constropt', 'database', 'design', 'query', 'execution', 'set', 'test', 'verify', 'technique', 'datum', 'query', 'execution', 'query', 'world', 'web', 'code', 'analysi', 'world', 'application', 'performance']], [['energy', 'management', 'cost', 'vehicle', 'grid'], ['system', 'schrdinger', 'amplification', 'plasma', 'method', 'result', 'existence', 'ma', 'resonance', 'condition', 'existence', 'result', 'absence', 'symmetry', 'system']], [['power', 'injection'], ['cauchy', 'problem', 'system', 'schrdinger', 'nonlinearlity', 'system', 'colin', 'differ', 'int', 'equ', 'model', 'laser', 'plasma', 'ground', 'state', 'system', 'stability', 'system', 'ground', 'stability', 'prove', 'stability', 'speed', 'dimension']], [['energy', 'management', 'system', 'fuzzy', 'hamacher', 'power', 'aggregation'], ['transportation', 'safety', 'sub', 'system', 'sub', 'safety', 'problem', 'safety', 'control', 'cp', 'failure', 'attack', 'safety', 'faulty', 'case', 'faulty', 'safety', 'rsi', 'condition', 'synthesi', 'control', 'sub', 'control', 'guarantee', 'safety', 'formulate', 'sum', 'optimization', 'rsi', 'safety', 'control', 'case', 'temperature', 'regulation', 'case', 'guarantee', 'safety']], [['interval', 'method', 'energy', 'system', 'ground', 'source', 'heat', 'pump', 'algorithm'], ['prediction', 'receive', 'answer', 'example', 'selection', 'model', 'specific', 'addres', 'challenge', 'antus', 'causal', 'prediction', 'model', 'sam', 'framework', 'information', 'predictor', 'antus', 'causal', 'classifier', 'independence', 'criterion', 'focu', 'path', 'label', 'image', 'regularization', 'strategy', 'distance', 'correlation', 'independence', 'regression', 'mitigation']], [['power', 'energy', 'intelligent', 'review', 'transformation', 'integration'], ['complexity', 'weight', 'multiplication', 'bound', 'complexity', 'weight', 'multiplication', 'table', 'analysi', 'search', 'complexity']], [['review', 'co', 'desalination', 'refrigeration', 'development'], ['quality', 'role', 'quality', 'control', 'gscv', 'rf', 'rfe', 'search', 'cro', 'validation', 'gscv', 'random', 'rf', 'feature', 'elimination', 'rfe', 'kqc', 'production', 'method', 'imputation', 'interpolation', 'dataset', 'method', 'analysi', 'rf', 'model', 'algorithm', 'model', 'rf', 'algorithm', 'balance', 'input', 'correlation', 'analysi', 'eliminate', 'result', 'reveal', 'strategy', 'clas', 'error', 'rate', 'accuracy', 'rate', 'quality', 'feature', 'identification', 'performance']], [['fault', 'location', 'method', 'distribution', 'optimization', 'algorithm'], ['entanglement', 'resource', 'information', 'processing', 'number', 'qubit', 'criterion', 'entanglement', 'number', 'quantum', 'state', 'tomography', 'demonstrate', 'effectivenes', 'detection', 'scheme', 'application', 'moment', 'detection', 'quantum', 'number', 'breaking', 'breaking', 'implication', 'moment', 'criterion', 'manifestation', 'channel', 'discrimination']], [['truncate', 'split', 'contrast', 'framework'], ['augmentation', 'da', 'diversity', 'training', 'model', 'generalization', 'ability', 'image', 'classification', 'detection', 'da', 'detection', 'specificity', 'change', 'image', 'article', 'mask', 'mgm', 'da', 'change', 'detection', 'sample', 'prediction', 'quality', 'reinforcement', 'da', 'method', 'adaaug', 'da', 'policy', 'training', 'augmentation', 'operation', 'operation', 'image', 'pair', 'image', 'change', 'detector', 'detection', 'performance', 'training', 'time', 'training', 'proces', 'redundancy', 'policy', 'change', 'detection', 'change', 'performance', 'state', 'art', 'da', 'time']], [['video', 'fine', 'story', 'generation'], ['question', 'vqa', 'challenge', 'proces', 'transformer', 'architecture', 'attention', 'mechanism', 'choice', 'vqa', 'challenge', 'balance', 'dependency', 'transformer', 'issue', 'region', 'self', 'attention', 'contrast', 'inter', 'window', 'attention', 'information', 'feature', 'model', 'redundancy', 'self', 'attention', 'efficacy', 'technique', 'vqa', 'benchmark', 'model', 'benchmark', 'performance', 'test', 'vqa']], [['distribution', 'adaptation', 'guidance'], ['document', 'panel', 'discussion', 'university', 'part', 'forum', 'intelligence', 'world', 'series', 'panel', 'intelligence', 'ai', 'society']], [['context', 'transformer', 'level', 'scene', 'understanding'], ['inverse', 'random', 'function', 'covariance', 'operator', 'power', 'differential', 'operator', 'incorporate', 'range', 'information', 'integer', 'method', 'noninteger', 'method', 'covariance', 'operator', 'subspace', 'covariance', 'matrix', 'vector', 'distribution', 'equation', 'expansion', 'show', 'representation', 'formulation', 'show', 'estimate', 'approximate', 'variance', 'focu', 'inverse', 'random', 'performance', 'scalability', 'model', 'inverse', 'time', 'heat', 'equation']], [['efficient', 'layout', 'generation', 'diffusion'], ['bridgeclip', 'framework', 'power', 'vision', 'language', 'inspection', 'clip', 'multus', 'label', 'classifier', 'bridge', 'image', 'pre', 'vision', 'language', 'image', 'domain', 'concept', 'appearance', 'bridge', 'damage', 'introduce', 'description', 'attention', 'module', 'dam', 'incorporate', 'domain', 'knowledge', 'inspection', 'knowledge', 'pre', 'knowledge', 'bridge', 'inspection', 'bridgeclip', 'clas', 'state', 'art', 'multus', 'label']], [['lensing', 'accuracy', 'challenge', 'handbook'], ['plate', 'recognition', 'learning', 'resolution', 'world', 'traffic', 'surveillance', 'resolution', 'blurry', 'blend', 'background', 'issue', 'los', 'function', 'character', 'los', 'lcofl', 'performance', 'lpr', 'task', 'enhance', 'character', 'feature', 'attention', 'module', 'character', 'recognition', 'model', 'discriminator', 'resolution', 'proces', 'character', 'reconstruction', 'quality', 'state', 'art']], [['deepshape', 'radio', 'learning'], ['letter', 'design', 'criterion', 'non', 'field', 'capacity', 'scale', 'mimo', 'mimo', 'characterization', 'channel', 'uniform', 'maximizing', 'system', 'capacity', 'array', 'optimization', 'problem', 'non', 'antenna', 'array', 'arrangement', 'center', 'capacity', 'gain']], [['srgerositum', 'sky', 'survey', 'ma', 'galaxy'], ['r', 'proces', 'producer', 'iron', 'role', 'neutronization', 'point', 'determine', 'r', 'proces', 'path', 'investigation', 'decay', 'neutron', 'z', 'proton', 'neutron', 'quasiparticle', 'phase', 'approximation', 'pn', 'qrpa', 'model', 'calculate', 'gamow', 'teller', 'half', 'emission', 'investigation', 'model', 'decay', 'half', 'factor', 'model', 'agreement', 'datum', 'present', 'time', 'core', 'r', 'proces', 'nucleosynthesi', 'time', 'evolution']], [['preparation'], ['transition', 'economy', 'time', 'energy', 'structure', 'energy', 'energy', 'energy', 'transition', 'definition', 'energy', 'commission', 'association', 'energy', 'cost', 'energy', 'energy', 'waste', 'definition', 'rec', 'boost', 'generation', 'development', 'mile', 'energy', 'production', 'tor', 'sapienza', 'district', 'prototype', 'scale', 'infrastructure', 'energy', 'transition', 'role', 'medium', 'survey', 'neighbourhood', 'housing', 'tor', 'sapienza', 'prosumer', 'rec']], [['preparation', 'lx', 'use', 'hst', 'image'], ['scale', 'advance', 'field', 'nf', 'shift', 'field', 'compatibility', 'nf', 'communication', 'paradigm', 'work', 'hbf', 'focusing', 'field', 'stationarity', 'recovery', 'problem', 'domain', 'code', 'greedy', 'dg', 'hbf', 'complexity', 'phase', 'shifter', 'p', 'resolution', 'non', 'stepwise', 'joint', 'greedy', 'hbf', 'sjg', 'hbf', 'proces', 'wave', 'p', 'resolution', 'complexity', 'ability', 'conjugate', 'sequency', 'bit', 'hbf', 'sjg', 'hbf', 'hbf', 'nf', 'beamforming', 'sig', 'hbf', 'sjg', 'hbf', 'highlight', 'feasibility', 'domain', 'cost', 'memory', 'storage', 'hbf']], [['inverse', 'galaxy', 'galaxy', 'magnification', 'cosmology'], ['language', 'reasoning', 'multus', 'modal', 'information', 'integration', 'reasoning', 'awarenes', 'reasoning', 'addres', 'model', 'reconstruction', 'model', 'input', 'mechanism', 'spatial', 'improvement', 'reconstruction', 'zerovlm']], [['analysi'], ['power', 'spectrum', 'brain', 'representation', 'transient', 'activity', 'ac', 'pc', 'neurophysiology', 'decomposition', 'component', 'distribution', 'scale', 'mechanism', 'effectivenes', 'parametric', 'bosc', 'spectrum', 'estimation', 'likelihood', 'shape', 'language', 'expectation', 'maximization', 'framework', 'los', 'sample', 'evaluation', 'evidence', 'simulation', 'shape', 'simulation', 'multiple', 'ac', 'los', 'score', 'number', 'eeg', 'ac', 'state', 'classification', 'accuracy', 'ieeg', 'discovery', 'performance', 'decomposition', 'parameterization', 'tool', 'brain', 'decoding', 'neuroscience', 'brain', 'computer', 'brain']], [['preparation', 'lxvius', 'learning', 'galaxy', 'bia', 'calibration'], ['crossmodal', 'knowledge', 'distillation', 'kd', 'enhance', 'student', 'teacher', 'model', 'information', 'improve', 'knowledge', 'transfer', 'image', 'classification', 'image', 'clas', 'level', 'avenue', 'incorporate', 'world', 'leakage', 'performance', 'addres', 'kd', 'framework', 'image', 'wordnet', 'los', 'use', 'clas', 'wordnet', 'leakage', 'introduce', 'strategy', 'student', 'performance', 'hinder', 'distillation', 'efficiency', 'interpretability', 'wordnet', 'reliance', 'state', 'effectivenes', 'kd']], [['preparation', 'learning', 'galaxy', 'bia', 'calibration'], ['entanglement', 'component', 'quantum', 'information', 'theory', 'attention', 'quantum', 'information', 'processing', 'characterization', 'entanglement', 'pt', 'al', 'ann', 'phy', 'berlin', 'region', 'pt', 'qubit', 'region', 'entanglement', 'moreover', 'space', 'qubit', 'region', 'pt', 'qubit', 'region', 'qubit', 'analysi', 'region', 'pt', 'extension', 'qubit', 'work', 'entanglement', 'qubit']], [['weaknes', 'range'], ['order', 'egg', 'element', 'g', 'group', 'integer', 'ldotsxk', 'g', 'gx', 'gx', 'let', 'egg', 'g', 'g', 'group', 'show', 'g', 'mboxpslnq', 'mboxpsunq', 'latter', 'nn', 'addition', 'order', 'semisimple', 'type']], [['polaron'], ['challenge', 'density', 'theory', 'dft', 'practice', 'ability', 'treat', 'electron', 'correlation', 'prediction', 'electron', 'density', 'matrix', 'generalization', 'dft', 'correlation', 'letter', 'enhance', 'theory', 'treatment', 'trace', 'electron', 'identity', 'matrix', 'correction', 'schwarz', 'repulsion', 'matrix', 'theory', 'hydrogen', 'singlet', 'triplet', 'gap', 'equilibrium', 'series', 'dft', 'scaling', 'dft', 'treatment', 'correlation', 'range']], [['stability', 'instability', 'transition', 'fermi'], ['group', 'element', 'eigenvalue', 'machinery', 'motivation', 'geometry', 'galoi', 'theory', 'group', 'theory', 'representation', 'theory', 'aspect', 'theory', 'field', 'case', 'problem', 'question', 'existence', 'question', 'question']], [['limit', 'criticality', 'dimension'], ['management', 'integrity', 'maintenance', 'query', 'optimization', 'database', 'design', 'integrity', 'support', 'database', 'need', 'level', 'use', 'support', 'notion', 'cover', 'comprising', 'fd', 'set', 'algorithm', 'complement', 'performance', 'number', 'size', 'cover', 'latter', 'integrity', 'maintenance', 'performance', 'query', 'refresh', 'benchmark', 'constraint']], [['history', 'learning'], ['performance', 'narrowband', 'field', 'system', 'antenna', 'array', 'transmit', 'field', 'array', 'factor', 'sidelobe', 'level', 'processing', 'field', 'resolution', 'factor', 'aperture', 'system', 'approximation', 'mainlobe', 'array', 'factor', 'improvement', 'factor', 'sqrt', 'sidelobe', 'performance', 'field', 'factor', 'array', 'factor']], [['review', 'cro', 'domain', 'image', 'translation', 'framework'], ['vision', 'language', 'navigation', 'task', 'indoor', 'environment', 'language', 'vln', 'feature', 'fusion', 'information', 'navigation', 'information', 'scarcity', 'domain', 'image', 'language', 'result', 'performance', 'herein', 'cro', 'feature', 'fusion', 'history', 'information', 'navigation', 'model', 'self', 'monitoring', 'advantage', 'actor', 'criticac', 'reinforcement', 'navigation', 'succes', 'rate', 'action', 'redundancy', 'navigation', 'augmentation', 'method', 'speaker', 'model', 'generalizability', 'room', 'room', 'rr', 'room', 'room', 'rr', 'comparison', 'algorithm', 'state', 'art']], [['reliability', 'rock', 'comparison', 'electron', 'microprobe', 'laser', 'ablation', 'ma', 'spectroscopy'], ['dmft', 'method', 'wang', 'rev', 'recover', 'correlation', 'van', 'der', 'prototype', 'van', 'der', 'ground', 'state', 'dmft', 'case', 'interaction', 'potential', 'depth', 'basi', 'set', 'generate', 'van', 'der', 'electron', 'cumulant', 'energy', 'ecum', 'function', 'entropy', 'dissociation', 'basi', 'dmft', 'case', 'van', 'der', 'covalent', 'bonding']], [['brain', 'intelligence', 'intelligence', 'impact'], ['brain', 'stimulation', 'db', 'movement', 'pd', 'loop', 'db', 'system', 'parameter', 'offering', 'energy', 'efficiency', 'effect', 'thalamu', 'restoration', 'basal', 'bgt', 'model', 'design', 'environment', 'rl', 'rl', 'actor', 'sac', 'twin', 'policy', 'gradient', 'policy', 'optimization', 'ppo', 'advantage', 'actor', 'ac', 'comparison', 'rl', 'reduction', 'power', 'dissipation', 'loop', 'system', 'response', 'circuitry', 'result', 'method', 'error', 'overstimulation', 'parameter', 'loop', 'db', 'system', 'promise', 'integration', 'rl']], [['intelligence', 'analysi'], ['memristor', 'design', 'style', 'promise', 'memory', 'functionality', 'ability', 'implement', 'gate', 'design', 'style', 'ratio', 'taox', 'set', 'reset', 'implementation', 'design', 'style', 'momentum', 'understand', 'breakdown', 'energy', 'consumption', 'operation', 'array', 'energy', 'distribution', 'energy', 'consumption', 'initialization', 'design', 'style', 'energy', 'split', 'execution', 'initialization']], [['harmony', 'gan', 'performance', 'perfect', 'sync'], ['localization', 'role', 'flight', 'navigation', 'satellite', 'system', 'gns', 'localization', 'image', 'variance', 'database', 'map', 'dataset', 'baseline', 'method', 'development', 'aerial', 'localization', 'addres', 'issue', 'construct', 'scale', 'dataset', 'time', 'image', 'trajectory', 'reference', 'satellite', 'image', 'database', 'flight', 'area', 'perform', 'localization', 'time', 'evaluation', 'place', 'recognition', 'alignment', 'localization', 'odometry', 'comparison', 'aerial', 'localization', 'framework', 'architecture', 'note', 'flight', 'framework', 'localization', 'accuracy', 'robustnes']], [['ai', 'thinking'], ['intersection', 'chow', 'homology', 'understood', 'motivation', 'contact', 'space', 'variety', 'ramification', 'space', 'scheme', 'strict', 'contact', 'ring', 'space', 'analogue', 'result', 'chow', 'artin', 'role', 'piecewise', 'cone', 'complex', 'analysi', 'aluffi', 'degeneration', 'model', 'calculation', 'intersection', 'theory']], [['panel', 'discussion', 'university', 'chicago'], ['elucidation', 'ability', 'model', 'expense', 'correlation', 'interest', 'consequence', 'type', 'correlation', 'superconductivity', 'condensation', 'cooper', 'electron', 'electron', 'solution', 'limitation', 'utilization', 'superfluidity', 'condensation', 'particle', 'hole', 'pair', 'condense', 'ma', 'result', 'frictionles', 'flow', 'excitation', 'energy', 'andin', 'bilayer', 'superconductivity', 'focu', 'identification', 'condensation', 'scale', 'effort', 'design', 'exciton', 'pair', 'exciton', 'avenue', 'creation', 'characterization', 'condensation', 'phenomenon', 'step', 'phenomenon', 'quantum', 'order', 'quantum', 'fermion', 'exciton', 'quantum', 'hybrid', 'model', 'quantum', 'device', 'machine', 'learning', 'electron', 'problem', 'electron', 'problem', 'scaling', 'system', 'size']], [['product', 'drug', 'development'], ['performance', 'field', 'legacy', 'input', 'multiple', 'output', 'frequency', 'division', 'communication', 'system', 'likelihood', 'antenna', 'array', 'estimation', 'error', 'closedform', 'circular', 'respect', 'key', 'system', 'array', 'size', 'bandwidth', 'target', 'distance', 'error', 'noise', 'ratio', 'regime', 'aperture', 'nise', 'performance', 'bandwidth', 'error', 'ceiling', 'nise', 'target', 'distance', 'bandwidth', 'number', 'wideband', 'nise', 'performance', 'uca', 'angle', 'wideband', 'nise', 'performance', 'aperture']], [['rule', 'extraction', 'networksauthor', 'luka', 'leko'], ['work', 'field', 'extension', 'field']], [[], ['correlation', 'method', 'correlation', 'pairwise', 'representation', 'correlation', 'investigate', 'hierarchy', 'feature', 'extraction', 'extension', 'minimax', 'distance', 'correlation', 'representation', 'performance']], [['ai'], ['tool', 'example', 'model', 'concept', 'order', 'order', 'methodology', 'time', 'series']], [['exominer', 'transit', 'classification', 'catalog', 'minute', 'te'], ['work', 'laplacian', 'operator', 'k', 'behavior', 'subdivision', 'procedure', 'case', 'textdiv', 'property', 'call', 'inclusion', 'uniformity', 'spectrum', 'distribution', 'dimension', 'clas', 'subdivision', 'textesdr', 'rgeq', 'dimension', 'subdivision', 'textsd', 'welker', 'dimension', 'k', 'family', 'subdivision', 'cone', 'show', 'choice', 'generalization', 'graph', 'subdivision', 'sense', 'decimation', 'sequence', 'graph', 'sequence', 'schreier', 'graph', 'tree', 'sequence', 'sequence', 'analysi', 'construction', 'self', 'sequence', 'graph', 'application', 'subdivision']], [['homogenization'], ['key', 'point', 'date', 'time', 'progress', 'share', 'hinge', 'structure', 'orientation', 'rotation', 'bone', 'length', 'ratio', 'difference', 'difference', 'transformation', 'fact', 'method', 'calibrate', 'pre', 'generator', 'distribution', 'treat', 'representation', 'joint', 'image', 'transfer', 'pre', 'annotation', 'generator', 'annotation', 'guidance', 'tuning', 'number', 'transformation', 'generator', 'produce', 'number', 'target', 'method', 'cro', 'state', 'art', 'performance', 'model', 'transfer', 'annotation', 'guidance']], [['graph', 'algorithm'], ['material', 'behavior', 'result', 'network', 'information', 'material', 'state', 'energy', 'stres', 'evolution', 'scenario', 'advantage', 'work', 'material', 'effort', 'time', 'package', 'model', 'methodology', 'rate', 'von', 'plasticity', 'model', 'law', 'damage', 'behavior', 'law', 'order', 'demonstrate', 'applicability', 'methodology', 'path', 'dependency', 'scenario', 'damage', 'model', 'interface', 'model', 'fracture', 'grain', 'definition', 'collocation', 'equality', 'regime', 'agreement', 'methodology', 'standard']], [['ssh', 'model', 'role', 'pt', 'symmetry'], ['query', 'workload', 'database', 'task', 'privacy', 'confidentiality', 'datum', 'generation', 'database', 'management', 'system', 'benchmark', 'order', 'fidelity', 'conform', 'query', 'cardinality', 'schema', 'work', 'generation', 'query', 'generator', 'application', 'cardinality', 'probability', 'approximation', 'model', 'ezgen', 'rule', 'method', 'translate', 'decouple', 'query', 'cardinality', 'attribute', 'cardinality', 'addition', 'work', 'aim', 'world', 'database', 'application', 'integrity', 'application', 'source', 'code', 'fidelity']], [['observation', 'topology', 'symmetry'], ['enabler', 'performance', 'degradation', 'field', 'isac', 'technique', 'way', 'position', 'channel', 'state', 'beam', 'alignment', 'field', 'beam', 'form', 'model', 'terahertz', 'field', 'samc', 'samc', 'system', 'division', 'field', 'framework', 'rao', 'bound', 'assistance', 'sensing', 'form', 'capacity', 'analysi', 'samc', 'performance', 'division', 'factor', 'cramr', 'rao', 'point', 'form', 'tnf', 'samc', 'conclusion', 'division', 'scheme', 'mobility', 'scenario', 'division', 'scheme', 'beam', 'alignment', 'case', 'frequency', 'division', 'scheme', 'tnf', 'samc']], [['edge', 'pt', 'symmetric', 'su', 'schrieffer', 'heeger', 'model'], ['coal', 'ablaze', 'brick', 'kiln', 'matter', 'pm', 'pm', 'environment', 'variety', 'health', 'ambient', 'pollutant', 'monitoring', 'deployment', 'technology', 'location', 'monitor', 'quality', 'air', 'calibration', 'reference', 'monitoring', 'industry', 'reference', 'monitor', 'emission', 'iot', 'calibration', 'reference', 'sensor', 'calibration', 'sensor', 'reading', 'metum', 'transfer', 'performance', 'evaluation', 'machine', 'learning', 'regression', 'model', 'mean', 'error', 'rmse', 'error', 'ma', 'ml', 'matter', 'pm', 'emission', 'rate', 'industry']], [['non', 'hatano', 'nelson', 'disorder', 'amplification'], ['imaging', 'area', 'diagnosi', 'vision', 'language', 'pre', 'training', 'vlp', 'radiology', 'vlp', 'focu', 'pixel', 'level', 'dense', 'prediction', 'example', 'image', 'segmentationto', 'addres', 'challenge', 'vlp', 'framework', 'dense', 'level', 'representation', 'gd', 'dense', 'image', 'text', 'gd', 'segmentation', 'p', 'task', 'model', 'dense', 'p', 'vlp', 'idea', 'gd', 'performance', 'imaging', 'segmentation', 'task', 'finetuning']], [['nature', 'edge', 'symmetry', 'protection'], ['system', 'compensatory', 'stability', 'center', 'ma', 'com', 'pressure', 'distribution', 'body', 'influence', 'lack', 'performance', 'themany', 'perturbation', 'way', 'divergence', 'com', 'equilibrium', 'pressure', 'distribution', 'situation', 'apa', 'cpa', 'way', 'risk', 'perturbation', 'rehabilitation', 'recovery', 'balance', 'disorder', 'design', 'implementation', 'evaluation', 'novel', 'dof', 'manipulator', 'treat', 'balance', 'disorder', 'msthe', 'platform', 'motion', 'end', 'effector', 'pressure', 'distribution', 'foot', 'com', 'body', 'respectivelydatum', 'performance', 'level', 'control', 'platform', 'regulate', 'difficulty', 'level', 'simulation', 'level', 'control', 'prototype', 'controllerthe', 'capacity', 'platform', 'set', 'pressure', 'distribution', 'foot', 'system', 'balance', 'apa', 'cpa']], [['entrant', 'phase', 'transition', 'su', 'schrieffer', 'heeger', 'model'], ['order', 'permutation', 'climate', 'time', 'series', 'day', 'day', 'market', 'motion', 'model', 'order', 'point', 'order', 'time', 'series', 'rate', 'balance', 'change', 'brain', 'rate', 'balance', 'motion', 'respect', 'version', 'test', 'bienayme']], [['phase', 'transition', 'non', 'suschriefferheeger', 'model'], ['rise', 'popularity', 'application', 'education', 'popularity', 'custom', 'require', 'design', 'cost', 'intuitive', 'system', 'surface', 'instrument', 'time', 'experience', 'user', 'play', 'instrument', 'surface', 'sensor', 'calibration', 'user', 'detection', 'position', 'identification', 'generation', 'demonstrate', 'performance', 'system', 'accuracy', 'precision', 'hand', 'location']], [['spectrum', 'pairwise', 'coalescence'], ['automobile', 'market', 'design', 'response', 'demand', 'design', 'market', 'application', 'similarity', 'verification', 'task', 'wheel', 'model', 'cloud', 'technology', 'jan', 'application', 'wheel', 'design', 'proces', 'hyundai', 'motor', 'company', 'design', 'team', 'similarity', 'verification', 'time', 'build', 'wheel', 'image', 'database', 'cro', 'entropy', 'los', 'pairwise', 'space', 'result', 'hyundai', 'task', 'wheel', 'design', 'similarity', 'motor', 'advantage', 'application']], [['body', 'fermionic', 'chain'], ['schrdinger', 'system', 'interaction', 'problem', 'solution', 'contribution', 'deal', 'case', 'range']], [['characterization', 'non', 'ladder', 'floquet', 'non', 'bloch', 'theory'], ['order', 'calculu', 'engineering', 'operator', 'frequency', 'domain', 'number', 'order', 'value', 'number', 'work', 'time', 'domain', 'expression', 'function', 'ftt', 'verify', 'expression', 'field', 'analog', 'array', 'order', 'approximation', 'operator', 'sj']], [['correspondence', 'entanglement', 'hatano', 'nelson', 'model'], ['observation', 'superconductivity', 'bilayer', 'wse', 'origin', 'electron', 'electron', 'band', 'structure', 'model', 'analyze', 'mechanism', 'coulomb', 'interaction', 'superconductivity', 'evolution', 'difference', 'plane', 'field', 'strength', 'non', 'function', 'interlayer', 'triplet', 'contrast', 'pairing', 'tendency', 'repulsion', 'state', 'regime', 'transition', 'superconductor', 'potential', 'difference', 'state', 'intervalley', 'superposition', 'triplet', 'singlet', 'superconductor', 'altland', 'zirnbauer', 'clas', 'c', 'interlayer', 'difference', 'state', 'clas', 'candidate', 'computation']], [['post', 'reflection', 'asymmetry', 'su', 'schrieffer', 'heeger', 'system'], ['attention', 'driving', 'car', 'lane', 'lane', 'model', 'control', 'car', 'vehicle', 'follower', 'vehicle', 'fv', 'car', 'lane', 'anticipation', 'perception', 'preparation', 'relaxation', 'perception', 'index', 'human', 'create', 'perception', 'behavior', 'guidance', 'account', 'opacity', 'efficacy', 'technique', 'comfort', 'safety', 'uniformity', 'traffic', 'flow', 'time', 'motion', 'sicknes']], [['skin', 'effect'], ['score', 'method', 'energy', 'accuracy', 'proces', 'score', 'diffusion', 'structure', 'optimization', 'force', 'equilibrium', 'gradient', 'energy', 'surface', 'target', 'score', 'space', 'score', 'method', 'energy', 'landscape', 'space', 'method', 'score', 'method', 'accuracy', 'chemical', 'accuracy', 'chemistry', 'tool', 'structure', 'prediction']], [['theory'], ['field', 'heisenberg', 'model', 'renormalization', 'group', 'theory', 'renormalization', 'group', 'field', 'heisenberg', 'model', 'order', 'reentrance', 'function', 'temperature']], [['differentiability', 'clas', 'non'], ['memory', 'memory', 'divide', 'core', 'concept', 'leverage', 'memory', 'organization', 'perform', 'memory', 'phase', 'change', 'memory', 'pcm', 'memory', 'technology', 'perspective', 'review', 'state', 'phase', 'change', 'device', 'design', 'fabrication', 'pcm', 'application', 'landscape', 'offer']], [[], ['adoption', 'machine', 'fiber', 'frp', 'design', 'reliance', 'box', 'accuracy', 'lack', 'interpretability', 'regression', 'pysr', 'solution', 'industry', 'addres', 'gap', 'framework', 'design', 'damage', 'initiation', 'element', 'feature', 'selection', 'ml', 'pysr', 'joint', 'damage', 'initiation', 'design', 'feature', 'selection', 'performance', 'ml', 'quality', 'huber', 'regression', 'model', 'feature', 'analysi', 'ml', 'equation', 'accuracy', 'equation', 'joint', 'design', 'damage', 'initiation', 'accuracy', 'scalability', 'bolt', 'row', 'engineering', 'metal', 'design', 'optimization', 'accuracy']], [['involution'], ['dependency', 'optimization', 'database', 'system', 'performance', 'optimization', 'management', 'throughput', 'use', 'transformation', 'schema', 'provide', 'workload', 'dependency', 'discovery', 'throughput', 'improvement', 'state', 'art', 'dbm', 'dependency', 'optimization', 'optimizer', 'execution', 'engine', 'e', 'g', 'dependency', 'propagation', 'subquery', 'standard', 'dependency', 'discovery', 'workload', 'execution']], [['chebyshev', 'approximation', 'random'], ['state', 'preparation', 'simulation', 'transition', 'preparation', 'ground', 'complexity', 'tritium', 'quantum', 'spin', 'isospin', 'circuit', 'energy', 'error', 'ground', 'state', 'state', 'system', 'simulation', 'probability', 'polarization', 'work', 'step', 'quantum']], [['matrn', 'model', 'journey', 'analysi', 'machine', 'learning'], ['clas', 'non', 'composition', 'piecewise', 'function', 'optimization', 'optimization', 'rank', 'orand', 'sparsity', 'optimization', 'goal', 'differentiability', 'epus', 'differentiability', 'regularity', 'estimate', 'clas', 'chain', 'rule', 'employ', 'regularity', 'differentiability', 'group', 'sparsity', 'indicator', 'order', 'cone']], [['algorithm', 'inverse'], ['image', 'diffusion', 'image', 'segmentation', 'diffusion', 'hand', 'issue', 'extent', 'model', 'sketch', 'contain', 'information', 'segmentation', 'text', 'therefore', 'sketchseg', 'sketch', 'image', 'segmentation', 'method', 'diffusion', 'model', 'image', 'diffusion', 'model', 'pixel', 'classifier', 'voc', 'shot', 'sketch', 'segmentation', 'detection', 'contribute', 'sketchycocoseg', 'dataset', 'sketchycoco', 'dataset']], [['approximation', 'random'], ['phase', 'heisenberg', 'spin', 'glas', 'system', 'component', 'spin', 'spin', 'glas', 'system', 'temperature', 'spin', 'glas', 'phase', 'temperature', 'number', 'dimension', 'phase', 'dirty', 'magnet', 'result', 'renormalization', 'group', 'lattice', 'lattice', 'phase', 'spin', 'glas', 'phase', 'phase', 'lyapunov', 'glas', 'chao', 'show', 'n']], [['posterior', 'proces', 'diffusion', 'climate'], ['reason', 'act', 'question', 'shape', 'pursuit', 'intelligence', 'claude', 'sonnet', 'phi', 'grok', 'exhibit', 'fluency', 'reliance', 'level', 'prediction', 'lack', 'agency', 'synthesi', 'agi', 'development', 'intelligence', 'neuroscience', 'psychology', 'intelligence', 'role', 'memory', 'multus', 'agent', 'coordination', 'rise', 'rag', 'retrieval', 'planning', 'tool', 'use', 'behavior', 'generalization', 'information', 'compression', 'test', 'time', 'adaptation', 'domain', 'intelligence', 'vision', 'language', 'perception', 'task', 'completion', 'intelligence', 'integration', 'memory', 'orchestration', 'self', 'compression', 'behavior', 'scaffolding', 'bridge', 'gap', 'learning', 'goal', 'cognition', 'agi']], [['approximation', 'levy', 'heat', 'equation'], ['diffusion', 'conformer', 'generation', 'performance', 'scarcity', 'fragment', 'diffusion', 'fragdiff', 'augmentation', 'strategy', 'fragmentation', 'phase', 'diffusion', 'innovation', 'building', 'augmentation', 'diffusion', 'model', 'learn', 'geometry', 'topology', 'focu', 'model', 'design', 'performance', 'performance', 'improvement', 'pretraining', 'paradigm', 'diffusion', 'chemistry']], [['random', 'error', 'analysi'], ['impedance', 'control', 'preparation', 'phase', 'introduction', 'implementation', 'conclusion', 'reference', 'page', 'impedance', 'control', 'ankle']], [['note', 'random', 'advection', 'diffusion'], ['power', 'spectrum', 'redshift', 'distance', 'cosmology', 'nextgeneration', 'combination', 'survey', 'technique', 'constrain', 'matter', 'energy', 'density', 'analysi', 'gravitationalwave', 'source', 'detector', 'crosscorrelation', 'percent', 'sub', 'percent', 'precision', 'choice', 'configuration', 'operation', 'time', 'conclusion', 'tracer', 'powerspectrum', 'density', 'show', 'combination', 'autocorrelation', 'crosscorrelation', 'improvement', 'factor', 'power', 'presence', 'yield', 'precise', 'sky', 'localization', 'use', 'spectroscopic', 'redshift', 'catalog', 'detectability']], [['blockchain', 'execution'], ['lensing', 'accuracy', 'challenge', 'series', 'image', 'analysi', 'goal', 'development', 'measure', 'lensing', 'measurement', 'estimation', 'galaxy', 'shape', 'presence', 'galaxy', 'challenge', 'machine', 'relevance', 'community', 'challenge', 'galaxy', 'resolution', 'space', 'blurring', 'combination', 'entry', 'field', 'use', 'tool', 'simulation', 'software', 'challenge', 'challenge', 'sample', 'challenge', 'see', 'information']], [['privacy', 'decision', 'making', 'dapp'], ['clas', 'multivariate', 'source', 'cro', 'spectrum', 'resolution', 'source', 'connectivity', 'efficiency', 'simulation', 'source', 'resolution', 'eeg', 'cro', 'spectrum', 'age', 'model', 'inversion', 'net', 'conduction', 'trajectory', 'concentration', 'distribution', 'component', 'isotropic', 'distribution', 'surface', 'band', 'rythm', 'brain', 'model', 'frequency', 'peak', 'alpha', 'frequency', 'trajectory', 'gradient', 'inflation', 'paf', 'cortex', 'source', 'solution', 'harmnqeeg']], [['muon', 'g', 'type', 'hdm', 'lhc'], ['speed', 'response', 'vibration', 'analysi', 'engineering', 'spite', 'eigenvalue', 'treatment', 'machine', 'learning', 'literature', 'network', 'nonlinearity', 'network', 'conversion', 'equation', 'standard', 'eigenvalue', 'problem', 'analysi', 'network', 'discretization', 'eigenfunction', 'form', 'eigenvalue', 'problem', 'quotient', 'tandem', 'gram', 'schmidt', 'orthogonalization', 'procedure', 'eigenanalysi', 'utility', 'basi', 'engineering', 'combination', 'gram', 'procedure', 'network', 'discretization', 'eigenfunction', 'offer', 'eigenvalue']], [['order', 'control', 'system'], ['array', 'uca', 'field', 'communication', 'isac', 'framework', 'coordinate', 'performance', 'joint', 'position', 'error', 'speb', 'target', 'st', 'non', 'coplanar', 'case', 'st', 'region', 'approximate', 'cramr', 'rao', 'distance', 'estimation', 'wavefront', 'model', 'minimization', 'problem', 'communication', 'requirement', 'power', 'budget', 'solution', 'crb', 'angle', 'form', 'expression', 'complexity', 'vector', 'transformation', 'vqf', 'algorithm', 'quotient', 'non', 'coplanar', 'case', 'st', 'region', 'speb', 'performance', 'relaxation', 'sdr', 'method', 'complexity', 'vqf', 'algorithm', 'information', 'matrix', 'angle', 'distance', 'propagation', 'matrix', 'trinity', 'los', 'ius', 'planar', 'array', 'performance', 'st', 'coplanar', 'antenna', 'array', 'iius', 'solution', 'precision', 'sdr', 'computation', 'complexity']], [['stage', 'motion', 'control'], ['point', 'ability', 'precision', 'point', 'cloud', 'challenge', 'nerc', 'extbf', 'point', 'cloud', 'compression', 'framework', 'geometry', 'coordinate', 'point', 'cloud', 'occupancy', 'statu', 'voxel', 'point', 'network', 'information', 'reconstruction', 'point', 'cloud', 'compression', 'redundancy', 'representation', 'point', 'g', 'point', 'geometry', 'compression', 'state', 'art', 'g', 'pcc', 'v', 'pcc', 'geometry', 'attribute', 'compression']], [['examination', 'order', 'phenomenon', 'iopd', 'controller', 'design'], ['phrase', 'language', 'image', 'disease', 'localization', 'state', 'art', 'self', 'text', 'image', 'diffusion', 'cro', 'attention', 'phrase', 'performance', 'diffusion', 'domain', 'language', 'model', 'cxr', 'bert', 'domain', 'generative', 'performance', 'introduce', 'bimodal', 'bia', 'bbm', 'post', 'processing', 'technique', 'image', 'certainty', 'bbm', 'attention', 'localization', 'accuracy', 'phrase', 'imaging', 'domain', 'way', 'practice']], [['control', 'phase', 'lead', 'precision', 'motion'], ['algorithm', 'evaluation', 'time', 'representation', 'dlr', 'time', 'addition', 'discretization', 'approximation', 'basi', 'time', 'line', 'expansion', 'impurity', 'strategy', 'complexity', 'order', 'diagram', 'inverse', 'temperature', 'width', 'max', 'max', 'quadrature', 'order', 'accuracy', 'benchmark', 'algorithm', 'order', 'impurity', 'hybridization', 'spin', 'orbit', 'diagonalization', 'quantum', 'monte', 'carlo', 'field', 'theory', 'calculation', 'band', 'hubbard', 'model', 'spin', 'orbit', 'model', 'caruo', 'promise', 'method', 'multiband', 'order', 'method', 'evaluation', 'procedure', 'sense', 'order', 'inaccurate', 'order']], [['order', 'integrationdifferentiation', 'function', 'verification'], ['efficacy', 'incidence', 'vaccine', 'viru', 'incidence', 'non', 'efficacy', 'vaccination', 'regard', 'outcome', 'control', 'outcome', 'increase', 'precision', 'efficacy', 'estimate', 'outcome', 'equation', 'function', 'outcome', 'ius', 'treatment', 'risk', 'infection', 'use', 'efficacy', 'efficacy', 'outcome', 'demonstrate', 'utility', 'example', 'precision']], [['remark', 'formulation', 'transport', 'non', 'convex', 'cost'], ['computation', 'monitor', 'dimensional', 'article', 'phase', 'ius', 'monitoring', 'number', 'phase', 'comparison', 'number', 'multivariate', 'covariance', 'matrix', 'procedure', 'remedy', 'effect', 'procedure', 'parameter', 'estimation', 'phase', 'performance', 'method', 'phase', 'ius', 'run', 'length', 'arl', 'criterion', 'absence', 'presence', 'control', 'chart', 'scheme', 'proces', 'mean', 'vector', 'applicability', 'method', 'manufacturing', 'application']], [['transport', 'growth', 'cost'], ['client', 'selection', 'consider', 'network', 'wherein', 'server', 'task', 'time', 'step', 'computation', 'intent', 'algorithm', 'client', 'client', 'information', 'exchange', 'term', 'participation', 'privacy', 'guarantee', 'efficacy']], [['system', 'interaction'], ['application', 'mapping', 'compact', 'patch', 'strategy', 'quality', 'coordinate', 'mapping', 'reconstruction', 'frequency', 'patch', 'introduce', 'coherence', 'video', 'representation', 'method', 'structure', 'patch', 'pixelunshuffle', 'operation', 'structure', 'level', 'train', 'decoder', 'reconstruct', 'strategy', 'layout', 'video', 'method', 'reconstruction', 'quality', 'compression', 'performance']], [['energy', 'schrodinger', 'system', 'power', 'type', 'growth', 'case'], ['westudy', 'trade', 'problem', 'seller', 'item', 'buyer', 'purchase', 'problem', 'case', 'buyer', 'drawn', 'contrast', 'trade', 'distribution', 'buyer', 'mechanism', 'welfare', 'distribution', 'buyer', 'mechanism', 'incentive', 'seller', 'strategy', 'buyer', 'mechanism', 'sense', 'mechanism', 'strategy', 'approximation', 'ratio', 'mechanism', 'strategy', 'approximation', 'welfare', 'distribution', 'impossibility', 'power', 'incentive', 'incentive', 'mechanismcanprovideanapproximationratiobetterthanln']], [['system', 'interaction', 'r', 'xe'], ['quantum', 'inter', 'boundary', 'quantum', 'control', 'mechanism', 'condition', 'pbc', 'spectrum', 'condition', 'obc', 'reconstruction', 'zone', 'bz', 'zone', 'gbz', 'skin', 'interplay', 'bz', 'gbz', 'control', 'similarity', 'control', 'spectrum', 'topology', 'bulk', 'correspondence']], [['schrdinger', 'system', 'interaction'], ['image', 'image', 'translation', 'ius', 'image', 'source', 'domain', 'target', 'domain', 'source', 'content', 'computer', 'vision', 'field', 'image', 'image', 'translation', 'style', 'transfer', 'image', 'segmentation', 'photo', 'degree', 'preservation', 'content', 'source', 'proces', 'problem', 'application', 'point', 'view', 'field', 'image', 'image', 'translation', 'content', 'categorization', 'ius', 'category', 'addition', 'introduce', 'evaluation', 'translation', 'field', 'ius', 'evaluation', 'translation', 'problem', 'simulation', 'application', 'image', 'image', 'translation', 'benchmark', 'sim', 'translation', 'extent', 'obligation', 'issue', 'ius', 'model', 'application']], [['theory', 'schrdinger', 'system', 'dimension'], ['video', 'compression', 'number', 'memory', 'consumption', 'inference', 'resource', 'succes', 'video', 'compression', 'proces', 'video', 'frame', 'frame', 'adopt', 'strategy', 'decrease', 'memory', 'consumption', 'timeline', 'modeling', 'work', 'inr', 'perspective', 'introduce', 'framework', 'memory', 'video', 'compression', 'nvc', 'video', 'compression', 'paradigm', 'model', 'instance', 'compression', 'adaptation', 'form', 'redundancy', 'initialization', 'training', 'compression', 'model', 'clip', 'length', 'nvc', 'video', 'clip', 'resource', 'performance', 'baseline']], [['existence', 'schr', 'odinger', 'system', 'interaction'], ['brain', 'stimulation', 'treatment', 'parkinson', 'disease', 'pd', 'brain', 'feedback', 'gadget', 'amount', 'control', 'consequence', 'control', 'algorithm', 'herein', 'introduce', 'benchmark', 'comparing', 'ganglion', 'circuit', 'drift', 'electrode', 'conductance', 'variability', 'betum', 'band', 'activity', 'brain', 'feedback', 'framework', 'environment', 'reinforcement', 'control', 'machine', 'community', 'field', 'neurostimulation']], [['system', 'schrdinger'], ['interplay', 'interaction', 'hermiticity', 'disorder', 'avenue', 'engineering', 'phase', 'localization', 'hubbard', 'lattice', 'mobility', 'edge', 'fact', 'spectral', 'transition', 'spectrum', 'transition', 'particle', 'particle', 'localization', 'mobility', 'edge', 'quasicrystal', 'way', 'body']], [['dense', 'style', 'image', 'image', 'translation'], ['vibration', 'condition', 'health', 'management', 'phm', 'nature', 'condition', 'monitoring', 'evolution', 'sensor', 'fabrication', 'rise', 'internet', 'vbcm', 'industry', 'transportation', 'agriculture', 'wildlife', 'vbcm', 'processing', 'machine', 'paradigm', 'shift', 'performance', 'reliability', 'vbcm', 'core', 'future', 'vbcm', 'thesi', 'signal', 'processing', 'extraction', 'availability', 'complexity', 'power', 'efficiency', 'thesi', 'span', 'processing', 'dsp', 'ml', 'learning', 'dl', 'signal', 'frequency', 'domain', 'time', 'frequency', 'domain', 'analysi', 'feature', 'extraction', 'signal', 'compression', 'expansion', 'reconstruction', 'extraction', 'condition', 'availability', 'noise', 'removal', 'complexity', 'power', 'efficiency', 'power', 'sensor', 'end', 'performance', 'vbcm', 'size', 'training', 'reliability', 'monitoring', 'proces', 'system', 'delay', 'memory', 'power', 'consumption', 'explainability', 'extraction', 'condition', 'processing', 'feature', 'engineering', 'processing', 'thesi', 'literature', 'signal', 'processing', 'signal', 'pipeline', 'application', 'review', 'feature', 'extraction', 'thesi', 'deployment', 'world', 'vbcm']], [['image', 'image', 'translation', 'content', 'review'], ['localization', 'play', 'role', 'future', 'wireles', 'awarenes', 'navigation', 'localization', 'equipment', 'hand', 'frequency', 'framework', 'resolution', 'range', 'implementation', 'sense', 'end', 'localization', 'algorithm', 'beam', 'beam', 'focusing', 'technique', 'estimate', 'location', 'receiver', 'algorithm', 'antenna', 'performance', 'mobile', 'carlo', 'cdf', 'mobile', 'estimation']], [['vision', 'transformer', 'normalization', 'histopathology', 'image', 'analysi'], ['blockchain', 'trust', 'transparency', 'execution', 'blockchain', 'storage', 'execution', 'dapp', 'blockchain', 'web', 'contract', 'contract', 'agreement', 'implementation']], [['sparsity', 'hierarchy', 'segmentation'], ['speech', 'synthesi', 'av', 'attention', 'utility', 'learning', 'av', 'stream', 'content', 'source', 'target', 'speaker', 'voice', 'conversion', 'stream', 'target', 'speaker', 'synthesi', 'av', 'work', 'vision', 'transformer', 'vit', 'combination', 'cycle', 'consistency', 'reconstruction', 'los', 'synthesi', 'quality', 'attention', 'mechanism', 'method', 'combination', 'cycle', 'consistency', 'reconstruction', 'los', 'quality', 'information', 'framework', 'benchmark', 'state', 'art', 'sotum', 'superiority', 'intelligibility', 'world']], [['car', 'controller', 'design', 'comfort', 'enhance', 'safety'], ['feature', 'group', 'interest', 'lipkin', 'model', 'fermion', 'system', 'temperature', 'discover', 'phenomenon', 'fermion', 'model', 'simplicity', 'gain', 'fermion', 'behavior', 'focu', 'attention', 'behavior', 'entropy', 'kind', 'quantum', 'purity']], [['stability', 'analysi', 'simulation', 'car', 'model', 'safety', 'field', 'vx', 'communication', 'focu', 'influence'], ['problem', 'chao', 'zero', 'lyapunov', 'model', 'review', 'example', 'version', 'lorenz', 'system', 'flow', 'system', 'frequency', 'quasiperiodicity', 'chao', 'resonant']], [['application', 'dynamic', 'backstepping', 'control', 'design', 'traffic', 'system'], ['expansion', 'energy', 'union', 'rise', 'development', 'energy', 'energy', 'res', 'rec', 'energy', 'directive', 'ius', 'idea', 'rec', 'energy', 'self', 'consumption', 'energy', 'energy', 'work', 'time', 'model', 'basi', 'maximize', 'profit', 'number', 'load', 'matlab', 'software', 'work', 'rec', 'plant', 'become', 'vice', 'versa', 'consumption', 'configuration', 'rec', 'work', 'analysi', 'plant', 'value', 'npv', 'function', 'plant', 'size', 'advantage', 'case', 'framework', 'distribution', 'load', 'profile', 'profitability', 'optimization', 'load', 'analysi', 'plant', 'size', 'work', 'rec']], [['connectivity', 'automation', 'traffic'], ['quantum', 'error', 'correction', 'erasure', 'error', 'correction', 'advantage', 'practice', 'ability', 'erasure', 'qubit', 'rail', 'qubit', 'pair', 'erasure', 'qubit', 'millisecond', 'scale', 'coherence', 'qubit', 'subspace', 'show', 'qubit', 'probability', 'erasure', 'gate', 'demonstrate', 'midcircuit', 'detection', 'erasure', 'error', 'check', 'suppression', 'transmon', 'noise', 'rail', 'qubit', 'coherence', 'operating', 'range', 'offering', 'capacity', 'avoid', 'frequency', 'rail', 'building', 'block', 'hardware', 'quantum', 'error', 'correction']], [['perception', 'control', 'car', 'lane', 'behavior'], ['exominer', 'learning', 'model', 'succes', 'exominer', 'transit', 'classification', 'minute', 'te', 'exominer', 'periodogram', 'trend', 'difference', 'image', 'flux', 'attitude', 'control', 'transit', 'performance', 'leverage', 'source', 'training', 'quality', 'kepler', 'space', 'telescope', 'te', 'accuracy', 'classification', 'search', 'space', 'community', 'te', 'catalog', 'exominer', 'confidence', 'te', 'interest', 'toi', 'community', 'interest', 'ctoi', 'ctoi', 'toi', 'planet', 'planet', 'reduction', 'quality', 'exominer', 'planet', 'yield']], [['lane', 'change', 'decision', 'time', 'trajectory', 'prediction', 'vehicle'], ['panel', 'share', 'advance', 'analysi', 'coefficient', 'information', 'estimation', 'group', 'structure', 'method', 'estimate', 'panel', 'variance', 'information', 'method', 'number', 'level', 'parameter', 'estimation', 'uncertainty', 'simulation', 'performance', 'method']], [['risk', 'field', 'model', 'application', 'trajectory', 'perspective'], ['energy', 'schrdinger', 'system', 'energy', 'resonance', 'condition', 'energy', 'ground', 'state', 'compactnessrigidity', 'method', 'classification', 'versu', 'energy', 'ground', 'state']], [['vehicle', 'control', 'synthesi', 'time', 'headway', 'model'], ['change', 'detection', 'time', 'aperture', 'radar', 'sar', 'cloud', 'weather', 'monitoring', 'change', 'detection', 'complexity', 'scene', 'gap', 'introduce', 'change', 'dataset', 'change', 'detection', 'change', 'detection', 'framework', 'hetecd', 'architecture', 'non', 'feature', 'feature', 'consistency', 'los', 'harmonize', 'clas', 'consistency', 'attention', 'difference', 'module', 'difference', 'information', 'demonstrate', 'hetecd', 'iou', 'state', 'art']], [['control', 'car', 'lane', 'behavior'], ['crossbar', 'memory', 'logic', 'technique', 'pinatubo', 'pinatubo', 'acronym', 'processing', 'memory', 'architecture', 'bulk', 'bitwise', 'activation', 'bitwise', 'pinatubo', 'change', 'memory', 'pcm', 'difference', 'resistance', 'robustnes', 'pinatubo', 'architecture', 'pcm', 'technology']], [['consensu', 'vehicle', 'platoon', 'control', 'psychological', 'comfort'], ['spin', 'phase', 'matterhave', 'attention', 'behavior', 'correlation', 'content', 'revolution', 'harbinger', 'paradigm', 'evolution', 'report', 'use', 'power', 'model', 'spin', 'unit', 'cell', 'antiferromagnet', 'unit', 'spin', 'liquid', 'ground', 'state', 'employ', 'density', 'renormalization', 'group', 'nature', 'ground', 'state', 'product', 'state', 'formulation', 'use', 'construct', 'hamiltonian', 'gate', 'efficient', 'error', 'mitigation', 'demonstrate', 'target', 'ground', 'state', 'accuracy', 'energy', 'protocol', 'number', 'unit', 'number', 'way', 'construction', 'spin', 'liquid', 'ground', 'device']], [['reinforcement', 'synchronization', 'brain'], ['bottleneck', 'parameter', 'server', 'p', 'framework', 'communication', 'cost', 'issue', 'gradient', 'descent', 'sgd', 'worker', 'selection', 'communication', 'frequency', 'number', 'participation', 'convergence', 'rate', 'communication', 'efficiency', 'proces', 'worker', 'selection', 'strategy', 'enabler', 'agesel', 'utilization', 'participation', 'sgd', 'age', 'worker', 'participation', 'simulation', 'agesel', 'strategy', 'number', 'training', 'accuracy', 'communication', 'cost', 'influence', 'hyper', 'parameter', 'benefit', 'age', 'worker', 'selection']], [['control', 'rigidity', 'hand', 'tremor', 'fuzzy', 'q', 'learning'], ['homotopy', 'idea', 'deformation', 'map', 'selection', 'homotopy', 'btd', 'iteration', 'homotopy', 'path', 'homotopy', 'selection', 'rothberger', 'property', 'h', 'menger', 'property', 'ph', 'rothberger', 'property', 'ph', 'menger', 'property', 'weaker']], [['loop', 'brain', 'stimulation', 'reinforcement', 'simulation'], ['clas', 'convex', 'sum', 'optimization', 'cfcco', 'group', 'optimization', 'gdro', 'addres', 'loop', 'block', 'coordinate', 'algorithm', 'block', 'coordinate', 'mirror', 'extrapolation', 'gradient', 'descent', 'convergence', 'smoothnes', 'cfcco', 'cfcco', 'form', 'gdro', 'complexity', 'optimality', 'alexr', 'clas', 'algorithm', 'cfcco', 'area', 'roc', 'curve', 'pauc', 'maximization', 'demonstrate', 'performance', 'algorithm']], [['environment', 'brain', 'stimulation', 'parkinson', 'disease'], ['neuron', 'interaction', 'chemical', 'coupling', 'function', 'model', 'behavior', 'quasi', 'scenario', 'formation', 'hyperchao', 'appearance', 'shilnikov', 'attractor', 'formation', 'appearance', 'phase', 'bursting']], [['singularity', 'avoidance', 'performance', 'attitude', 'spacecraft'], ['scenario', 'type', 'x', 'doublet', 'model', 'inert', 'doublet', 'type', 'x', 'hdm', 'offer', 'solution', 'muon', 'g', 'anomaly', 'show', 'framework', 'accomodate', 'account', 'loop', 'barr', 'zee', 'bz', 'doublet', 'tautau', 'transverse', 'energy', 'signal', 'probe', 'scenario', 'tev', 'lhc']], [['regulation', 'energy'], ['rd', 'domain', 'consider', 'problem', 'activation', 'function', 'error', 'norm', 'radon', 'transform', 'discrepancy', 'approximation', 'p', 'p', 'skd', 'consequence', 'adaptivity', 'approximation', 'order', 'piecewise', 'k']], [['role', 'participant', 'distribution', 'consumption', 'optimization', 'pv', 'energy'], ['quantum', 'spin', 'range', 'presence', 'spin', 'spin', 'clas', 'particle', 'schrodinger', 'range', 'pair']], [['client', 'selection'], ['particle', 'time', 'frequency', 'interpolation', 'recover', 'representation', 'sparse', 'representation', 'use', 'rank', 'compression', 'accuracy', 'consider', 'use', 'dlr', 'field', 'theory', 'matsubara', 'frequency', 'grid', 'dlr', 'matsubara', 'frequency', 'test', 'performance', 'method', 'dmft', 'calculation', 'srruo', 'temperature', 'k', 'time', 'quantum', 'monte', 'carlo', 'impurity', 'solver', 'demonstrate', 'matsubara', 'frequency', 'reduction', 'accuracy', 'increase', 'number', 'presence', 'monte', 'noise']], [['building', 'energy', 'community', 'tor', 'sapienza', 'district', 'rome'], ['effectivenes', 'vision', 'language', 'question', 'ability', 'capture', 'series', 'vqa', 'performance', 'gcn', 'variability', 'size', 'training', 'selection', 'vqa', 'evaluation', 'framework', 'vqa', 'word', 'model', 'addres', 'performance', 'framework', 'evaluation', 'effectivenes', 'evaluation']], [['communication', 'allocation', 'multiple', 'agent', 'system'], ['inverse', 'case', 'distribution', 'matrix', 'function', 'dirac', 'system', 'wiener', 'case']], [['limit', 'theorem', 'spectrum', 'inclusion', 'uniform'], ['proton', 'amplitude', 'method', 'form', 'implementation', 'skyrme', 'quasiparticle', 'phase', 'approximation', 'particle', 'phase', 'approximation', 'strength', 'decay', 'time', 'test', 'strength', 'agreement', 'decay']], [['graph'], ['metal', 'array', 'antenna', 'power', 'capacity', 'strength', 'intermodulation', 'pim', 'metal', 'modular', 'array', 'tcda', 'time', 'article', 'tcda', 'dipole', 'element', 'assembly', 'ease', 'replacement', 'case', 'damage', 'edge', 'truncation', 'effect', 'half', 'aperture', 'simulation', 'tcda', 'operate', 'bandwidth', 'ghz', 'e', 'plane', 'h', 'plane', 'profile', 'h', 'operating', 'frequency', 'metal', 'tcda', 'modular', 'array', 'ring', 'cro', 'printing', 'technique', 'agreement']], [['domination', 'number', 'haj', 'vertex', 'sum', 'graph'], ['confidence', 'uncertainty', 'group', 'panel', 'group', 'probability', 'unit', 'group', 'membership', 'justify', 'monte', 'carlo', 'evidence', 'confidence', 'coverage', 'finite', 'application', 'confidence', 'set']], [['number', 'product', 'graph'], ['number', 'k', 'dombi', 'sequence', 'rkann', 'explicit', 'counterexample', 'density']]]\n"
          ]
        }
      ],
      "source": [
        "def tokenize_title_and_abstract(titles, abstracts):\n",
        "    result = []\n",
        "    for t, a in zip(titles, abstracts):\n",
        "        t_toks = clean_str(t).split()\n",
        "        a_toks = clean_str(a).split()\n",
        "        result.append([t_toks, a_toks])\n",
        "    return result\n",
        "\n",
        "# Usage\n",
        "all_data = tokenize_title_and_abstract(all_titles_lists, sentences)\n",
        "print(all_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "Z2mjHqF4n-QV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "all_train_data: 517 test_data: 130\n",
            "train_data: 465 valid_data: 52\n"
          ]
        }
      ],
      "source": [
        "all_train_data, test_data = train_test_split(all_data, test_size=0.2, random_state=42)\n",
        "train_data, valid_data = train_test_split(all_train_data, test_size=0.1, random_state=42)\n",
        "print(\"all_train_data:\", len(all_train_data), \"test_data:\", len(test_data))\n",
        "print(\"train_data:\", len(train_data), \"valid_data:\", len(valid_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMH_2squVJP0"
      },
      "outputs": [],
      "source": [
        "# import pandas as pd\n",
        "# import numpy as np\n",
        "# import torch\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# # 1) Extract top-K TF–IDF terms from titles\n",
        "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "# K = 10\n",
        "# vec    = TfidfVectorizer(stop_words=\"english\")\n",
        "# tfidf  = vec.fit_transform([ clean_str(t) for t in all_titles_lists ])\n",
        "# terms  = np.array(vec.get_feature_names_out())\n",
        "# scores = np.asarray(tfidf.sum(axis=0)).ravel()\n",
        "# top_terms = terms[scores.argsort()[-K:][::-1]].tolist()\n",
        "# print(\"Top-20 terms:\", top_terms)\n",
        "\n",
        "# title_abstract_labels = []\n",
        "\n",
        "# for doc in all_data:\n",
        "#     label = []\n",
        "#     for term in top_terms:\n",
        "#         if term in doc:\n",
        "#             label.append(1)\n",
        "#         else:\n",
        "#             label.append(0)\n",
        "#     title_abstract_labels.append(label)\n",
        "\n",
        "\n",
        "# print(\"doc_labels:\", len(title_abstract_labels))\n",
        "# print(title_abstract_labels[:5])\n",
        "\n",
        "\n",
        "# all_train_labels, test_labels = train_test_split(doc_labels, test_size=0.2, random_state=42)\n",
        "# train_labels, valid_labels = train_test_split(all_train_labels, test_size=0.1, random_state=42)\n",
        "# print(\"train_labels:\", len(all_train_labels), \"test_labels:\", len(test_labels))\n",
        "# print(\"train_labels:\", len(train_labels), \"valid_labels:\", len(valid_labels))\n",
        "\n",
        "\n",
        "# import numpy as np\n",
        "# from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# # Assuming original_labels_train is a list of lists, where each inner list contains the labels for a single sample\n",
        "# mlb = MultiLabelBinarizer()\n",
        "# train_labels = mlb.fit_transform(train_labels)\n",
        "# test_labels = mlb.transform(test_labels)\n",
        "\n",
        "# import torch\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# # Assuming you want to flatten the labels into a single list\n",
        "# llm_labels = train_labels.flatten().tolist() + test_labels.flatten().tolist()  #CS_test=1172  #SS_test =1023\n",
        "# llm_labels = torch.LongTensor(labels).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "3i7RRKlMqFBu"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train encodings shape: torch.Size([465, 256])\n",
            "Validation encodings shape: torch.Size([52, 111])\n",
            "Test encodings shape: torch.Size([130, 117])\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "def preprocess_texts(data_list):\n",
        "    text_list = []\n",
        "    for doc_tokens in data_list:\n",
        "        # doc_tokens is expected to be [title_tokens, abstract_tokens]\n",
        "        if len(doc_tokens) == 2 and isinstance(doc_tokens[0], list) and isinstance(doc_tokens[1], list):\n",
        "            # Join title and abstract tokens into a single string\n",
        "            combined_text = \" \".join(doc_tokens[0] + doc_tokens[1])\n",
        "            text_list.append(combined_text)\n",
        "        else:\n",
        "            # Handle cases where the structure might be different, or skip\n",
        "            print(f\"Warning: Unexpected data structure for document: {doc_tokens}. Skipping or handling differently.\")\n",
        "            # Depending on expected input, you might want to raise an error or log\n",
        "            pass # Or add other handling logic\n",
        "\n",
        "    return tokenizer(\n",
        "        text_list,\n",
        "        truncation=True,\n",
        "        padding=True,\n",
        "        max_length=256,\n",
        "        return_tensors=\"pt\"\n",
        "    )\n",
        "\n",
        "train_encodings = preprocess_texts(train_data)\n",
        "val_encodings = preprocess_texts(valid_data)\n",
        "test_encodings = preprocess_texts(test_data)\n",
        "\n",
        "print(\"Train encodings shape:\", train_encodings['input_ids'].shape)\n",
        "print(\"Validation encodings shape:\", val_encodings['input_ids'].shape)\n",
        "print(\"Test encodings shape:\", test_encodings['input_ids'].shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "of-HB7mvq7xV"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 465\n",
            "Val   size: 52\n",
            "Test  size: 130\n"
          ]
        }
      ],
      "source": [
        "# 0) define K, top_terms, and your labeling function\n",
        "K = len(top_terms)  # number of labels\n",
        "assert K > 1, \"You must have loaded your top_terms\"\n",
        "\n",
        "def label_documents(docs, top_terms, threshold=4):\n",
        "    labels = []\n",
        "    top_set = set(top_terms)\n",
        "    for doc in docs:\n",
        "        toks = clean_str(doc).split()\n",
        "        hits = len(set(toks) & top_set)\n",
        "        labels.append([1 if i<hits and i<threshold else 0 for i in range(K)])\n",
        "        # ←–– adjust this line to produce an actual length-K list of 0/1s\n",
        "    return labels\n",
        "\n",
        "# 1) Build your full doc list in the same order you encoded them:\n",
        "all_docs = train_data + valid_data + test_data\n",
        "\n",
        "# 2) Generate your binary_labels list\n",
        "binary_labels = label_documents(all_docs, top_terms, threshold=4)\n",
        "assert len(binary_labels) == len(all_docs)\n",
        "\n",
        "# 3) Now split exactly as your data\n",
        "n_train = len(train_data)\n",
        "n_val   = len(valid_data)\n",
        "n_test  = len(test_data)\n",
        "\n",
        "train_labels_split = binary_labels[0 : n_train]\n",
        "val_labels_split   = binary_labels[n_train : n_train+n_val]\n",
        "test_labels_split  = binary_labels[n_train+n_val : n_train+n_val+n_test]\n",
        "\n",
        "# 4) Define your Dataset class (no change)\n",
        "class SentDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels    = labels\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "    def __getitem__(self, idx):\n",
        "        item = {\n",
        "            'input_ids':      self.encodings['input_ids'][idx].to(device),\n",
        "            'attention_mask': self.encodings['attention_mask'][idx].to(device),\n",
        "            'labels':         torch.tensor(\n",
        "                                   self.labels[idx],\n",
        "                                   dtype=torch.float,\n",
        "                                   device=device\n",
        "                               )\n",
        "        }\n",
        "        return item\n",
        "\n",
        "# 5) Finally instantiate\n",
        "train_dataset = SentDataset(train_encodings, train_labels_split)\n",
        "val_dataset   = SentDataset(val_encodings,   val_labels_split)\n",
        "test_dataset  = SentDataset(test_encodings,  test_labels_split)\n",
        "\n",
        "print(\"Train size:\", len(train_dataset))\n",
        "print(\"Val   size:\", len(val_dataset))\n",
        "print(\"Test  size:\", len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "G1urCWBpwKXr"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "# import torch\n",
        "# from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "# from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "# # Assuming K (number of top terms) is defined in a previous cell\n",
        "# # If not, you might need to define it or get it from the label data\n",
        "# # Based on cell K6qDEpow-Acl, K is set to 10.\n",
        "# num_labels = K # Use the number of top TF-IDF terms as the number of labels\n",
        "\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=num_labels)\n",
        "\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir=\"./results\",\n",
        "#     eval_strategy=\"epoch\",\n",
        "#     learning_rate=2e-5,\n",
        "#     per_device_train_batch_size=4,\n",
        "#     per_device_eval_batch_size=4,\n",
        "#     optim='adamw_torch',\n",
        "#     num_train_epochs=1,\n",
        "#     dataloader_pin_memory=False,\n",
        "#     weight_decay=0.01,\n",
        "#     max_grad_norm = 1.0,\n",
        "#     warmup_ratio = 0.1,\n",
        "#     logging_dir=\"./logs\",\n",
        "#     logging_steps=10,\n",
        "#     lr_scheduler_type = \"constant\",\n",
        "#     load_best_model_at_end=True,\n",
        "#     save_strategy=\"epoch\",\n",
        "#     report_to = \"tensorboard\",\n",
        "#     save_safetensors=True,\n",
        "#     fp16=True,\n",
        "#     seed=42 # Assuming a seed is needed, using 42 as a common practice\n",
        "# )\n",
        "\n",
        "# def compute_metrics(pred):\n",
        "#     labels = pred.label_ids\n",
        "#     # For multi-label classification with BCEWithLogitsLoss, predictions are logits\n",
        "#     # Apply sigmoid and a threshold to get binary predictions\n",
        "#     preds = (torch.sigmoid(torch.tensor(pred.predictions)) > 0.5).long().numpy()\n",
        "#     # Ensure labels are also numpy for sklearn metrics\n",
        "#     labels = labels.astype(np.int64)\n",
        "\n",
        "\n",
        "#     # Use multi-label appropriate metrics\n",
        "#     # accuracy: subset accuracy (all labels must match) or micro/macro/weighted accuracy\n",
        "#     # precision, recall, f1: typically calculated with average='macro', 'micro', or 'weighted'\n",
        "\n",
        "#     # Example using micro average for precision, recall, f1\n",
        "#     precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average=\"micro\")\n",
        "#     # For accuracy, you might want micro accuracy (same as precision/recall/f1 micro)\n",
        "#     # or subset accuracy (strict match of all labels)\n",
        "#     acc = accuracy_score(labels, preds) # This calculates subset accuracy by default\n",
        "\n",
        "#     return {\n",
        "#         \"accuracy\": acc,\n",
        "#         \"precision\": precision,\n",
        "#         \"recall\": recall,\n",
        "#         \"f1\": f1,\n",
        "#     }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "4g7atmFPwmL_"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\romeo\\anaconda3\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:440: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:263.)\n",
            "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='117' max='117' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [117/117 00:06, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.042300</td>\n",
              "      <td>0.032874</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\romeo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\romeo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "c:\\Users\\romeo\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=117, training_loss=0.17559528656494924, metrics={'train_runtime': 6.858, 'train_samples_per_second': 67.804, 'train_steps_per_second': 17.06, 'total_flos': 61177714375680.0, 'train_loss': 0.17559528656494924, 'epoch': 1.0})"
            ]
          },
          "execution_count": 48,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=train_dataset,\n",
        "#     eval_dataset=val_dataset,\n",
        "#     compute_metrics=compute_metrics,\n",
        "# )\n",
        "# trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "17bc8eac"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Warning: 'features' is 1D with shape torch.Size([1671]). Attempting to reshape to 2D assuming 1671 nodes and an embedding dimension of 768. Please ensure this assumption is correct in your data preparation steps.\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n",
        "import scipy.sparse as sp # Needed for sparse matrix operations in GCN\n",
        "\n",
        "# ————————————————— Assumptions ——————————————————\n",
        "# device, features, adj,\n",
        "# train_encodings, val_encodings, test_encodings,\n",
        "# train_labels_split, val_labels_split, test_labels_split (from SentDataset setup, already tensors)\n",
        "# idx_train, idx_val, idx_test (from generate_train_val)\n",
        "# LR, WEIGHT_DECAY, NUM_EPOCHS, EARLY_STOPPING, HIDDEN_DIM, NUM_LAYERS, DROP_OUT\n",
        "# are defined elsewhere in your notebook and are accessible in this scope.\n",
        "\n",
        "# Ensure encodings are on the correct device and are of type torch.LongTensor\n",
        "for enc in (train_encodings, val_encodings, test_encodings):\n",
        "    for k in ('input_ids', 'attention_mask'):\n",
        "        if not isinstance(enc[k], torch.Tensor):\n",
        "            enc[k] = torch.tensor(enc[k], dtype=torch.long)\n",
        "        # Move to device\n",
        "        enc[k] = enc[k].to(device)\n",
        "\n",
        "# Determine number of labels (K should be defined from top_terms in previous cells)\n",
        "try:\n",
        "    num_labels = K\n",
        "except NameError:\n",
        "    print(\"Warning: K not defined, defaulting to 10 labels.\")\n",
        "    num_labels = 10\n",
        "\n",
        "# Load the LLM head for sequence classification\n",
        "llm_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", num_labels=num_labels\n",
        ").to(device)\n",
        "\n",
        "# Multi-label binary cross-entropy with logits loss\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "def calc_acc(preds, labels, thresh=0.5):\n",
        "    \"\"\"\n",
        "    Calculates multi-label accuracy.\n",
        "    Args:\n",
        "        preds (torch.Tensor): Raw logits from the model.\n",
        "        labels (torch.Tensor): Ground truth binary labels.\n",
        "        thresh (float): Threshold to convert logits to binary predictions.\n",
        "    Returns:\n",
        "        float: Mean accuracy.\n",
        "    \"\"\"\n",
        "    # Apply sigmoid to logits and then threshold to get binary predictions\n",
        "    preds_bin = (torch.sigmoid(preds) > thresh).float()\n",
        "    # Ensure labels are float for element-wise comparison\n",
        "    if labels.dtype != torch.float:\n",
        "        labels = labels.float()\n",
        "    # Calculate accuracy: (correct predictions / total predictions) for each label, then mean\n",
        "    return (preds_bin == labels).float().mean().item()\n",
        "\n",
        "# --- GCN Layer Definition (Copied from your original notebook for completeness) ---\n",
        "class GraphConvolution(Module):\n",
        "    \"\"\"\n",
        "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, out_features, drop_out=0, activation=None, bias=True):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.zeros(1, out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters(in_features, out_features)\n",
        "        self.dropout = torch.nn.Dropout(drop_out)\n",
        "        self.activation = activation\n",
        "\n",
        "    def reset_parameters(self, in_features, out_features):\n",
        "        stdv = np.sqrt(6.0 / (in_features + out_features))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        # if self.bias is not None:\n",
        "        #     torch.nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, input, adj, feature_less=False):\n",
        "        if feature_less:\n",
        "            support = self.weight\n",
        "            support = self.dropout(support)\n",
        "        else:\n",
        "            input = self.dropout(input)\n",
        "            support = torch.mm(input, self.weight)\n",
        "        output = torch.spmm(adj, support)\n",
        "        if self.bias is not None:\n",
        "            output = output + self.bias\n",
        "        if self.activation is not None:\n",
        "            output = self.activation(output)\n",
        "        return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'\n",
        "\n",
        "# --- GCN Model Definition (Corrected) ---\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, nfeat, nhid, nclass, dropout, n_layers=2):\n",
        "        super(GCN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.gc_list = nn.ModuleList() # Initialize as ModuleList for proper registration\n",
        "\n",
        "        if n_layers >= 2:\n",
        "            # Explicitly pass drop_out and bias arguments\n",
        "            self.gc1 = GraphConvolution(nfeat, nhid, drop_out=dropout, activation=nn.ReLU(), bias=True)\n",
        "            for _ in range(self.n_layers - 2):\n",
        "                self.gc_list.append(GraphConvolution(nhid, nhid, drop_out=dropout, activation=nn.ReLU(), bias=True))\n",
        "            self.gcf = GraphConvolution(nhid, nclass, drop_out=dropout, activation=None, bias=True) # Last layer typically no activation for classification\n",
        "        else:\n",
        "            self.gc1 = GraphConvolution(nfeat, nclass, drop_out=dropout, activation=None, bias=True)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        if self.n_layers >= 2:\n",
        "            # For the first layer, if features are not actual node features (e.g., just indices),\n",
        "            # `feature_less=True` uses only the weight matrix.\n",
        "            # If `features` are actual LLM embeddings, `feature_less` should be False.\n",
        "            # Assuming 'features' are now LLM embeddings, so `feature_less` should be False.\n",
        "            x = self.gc1(x, adj, feature_less=False) # Changed to False assuming LLM embeddings are real features\n",
        "            for i in range(self.n_layers - 2):\n",
        "                x = self.gc_list[i](x, adj)\n",
        "            x = self.gcf(x, adj)\n",
        "        else:\n",
        "            x = self.gc1(x, adj, feature_less=False) # Changed to False\n",
        "        return x\n",
        "\n",
        "def train_combined_model(show_result=True):\n",
        "    \"\"\"\n",
        "    Trains the combined GCN-LLM model.\n",
        "    Args:\n",
        "        show_result (bool): Whether to print epoch-wise training results.\n",
        "    Returns:\n",
        "        tuple: Lists of training combined loss, training accuracy,\n",
        "               validation combined loss, and validation accuracy.\n",
        "    \"\"\"\n",
        "    # Ensure labels for GCN training/validation are on the correct device and are float.\n",
        "    # These are assumed to be already prepared as `train_labels_split` and `val_labels_split`\n",
        "    # from the `SentDataset` setup (cell `of-HB7mvq7xV`), and should be `torch.float` tensors.\n",
        "\n",
        "    # Convert lists of labels to torch.Tensor and move to device\n",
        "    gcn_train_labels_for_loss = torch.tensor(train_labels_split, dtype=torch.float).to(device)\n",
        "    gcn_val_labels_for_loss = torch.tensor(val_labels_split, dtype=torch.float).to(device)\n",
        "\n",
        "    # History lists to store metrics\n",
        "    history = {\n",
        "        'train_combined': [], 'train_gcn': [], 'train_llm': [], 'train_acc': [],\n",
        "        'val_combined': [],     'val_gcn': [],   'val_llm': [],   'val_acc': []\n",
        "    }\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        t0 = time.time() # Start time for the epoch\n",
        "\n",
        "        # Set models to training mode\n",
        "        model.train()\n",
        "        llm_model.train()\n",
        "\n",
        "        # Zero gradients for both optimizers\n",
        "        optimizer_gcn.zero_grad()\n",
        "        optimizer_llm.zero_grad()\n",
        "\n",
        "        # — GCN Forward Pass —\n",
        "        # The GCN processes all nodes in the graph. `features` are the node features\n",
        "        # (which should include LLM embeddings for document nodes). `adj` is the adjacency matrix.\n",
        "        all_gcn_logits = model(features, adj)\n",
        "        # Select GCN logits corresponding to the training documents based on `idx_train`\n",
        "        gcn_logits_train = all_gcn_logits[idx_train]\n",
        "\n",
        "        # — LLM Forward Pass —\n",
        "        # The LLM processes its specific training input data (`train_encodings`).\n",
        "        # Note: We use the entire `train_encodings` here, not sliced by `idx_train`,\n",
        "        # as `train_encodings` already represents the LLM's training set.\n",
        "        llm_output_train = llm_model(input_ids=train_encodings['input_ids'],\n",
        "                                     attention_mask=train_encodings['attention_mask'])\n",
        "        llm_logits_train = llm_output_train.logits\n",
        "\n",
        "        # — Loss Calculation —\n",
        "        # GCN loss: uses GCN's training logits and the corresponding labels for GCN's training documents.\n",
        "        loss_gcn_train = criterion(gcn_logits_train, gcn_train_labels_for_loss)\n",
        "        # LLM loss: uses LLM's training logits and the corresponding labels for LLM's training data.\n",
        "        # Assuming `gcn_train_labels_for_loss` is correctly aligned with `train_encodings`.\n",
        "        loss_llm_train = criterion(llm_logits_train, gcn_train_labels_for_loss)\n",
        "\n",
        "        # Combined loss for backpropagation\n",
        "        loss_comb_train = loss_gcn_train + loss_llm_train\n",
        "        loss_comb_train.backward() # Backpropagate combined loss\n",
        "\n",
        "        # Optimizer steps for both models\n",
        "        optimizer_gcn.step()\n",
        "        optimizer_llm.step()\n",
        "\n",
        "        # — Training Accuracy Calculation —\n",
        "        # For combined accuracy, average the logits from GCN and LLM.\n",
        "        # This assumes a direct correspondence between documents in `idx_train` and `train_encodings`.\n",
        "        acc_train = calc_acc((gcn_logits_train + llm_logits_train) / 2, gcn_train_labels_for_loss)\n",
        "\n",
        "        # — Validation Phase —\n",
        "        # Set models to evaluation mode\n",
        "        model.eval()\n",
        "        llm_model.eval()\n",
        "\n",
        "        with torch.no_grad(): # Disable gradient calculations for validation\n",
        "            # GCN validation\n",
        "            all_gcn_logits_val = model(features, adj)\n",
        "            gcn_logits_val = all_gcn_logits_val[idx_val]\n",
        "\n",
        "            # LLM validation\n",
        "            llm_output_val = llm_model(input_ids=val_encodings['input_ids'],\n",
        "                                       attention_mask=val_encodings['attention_mask'])\n",
        "            llm_logits_val = llm_output_val.logits\n",
        "\n",
        "            # Validation Losses\n",
        "            loss_gcn_val = criterion(gcn_logits_val, gcn_val_labels_for_loss)\n",
        "            loss_llm_val = criterion(llm_logits_val, gcn_val_labels_for_loss)\n",
        "            loss_comb_val = loss_gcn_val + loss_llm_val\n",
        "\n",
        "            # Validation Accuracy\n",
        "            acc_val = calc_acc((gcn_logits_val + llm_logits_val) / 2, gcn_val_labels_for_loss)\n",
        "\n",
        "        # — Record Metrics —\n",
        "        history['train_combined'].append(loss_comb_train.item())\n",
        "        history['train_gcn'].append(loss_gcn_train.item())\n",
        "        history['train_llm'].append(loss_llm_train.item())\n",
        "        history['train_acc'].append(acc_train)\n",
        "        history['val_combined'].append(loss_comb_val.item())\n",
        "        history['val_gcn'].append(loss_gcn_val.item())\n",
        "        history['val_llm'].append(loss_llm_val.item())\n",
        "        history['val_acc'].append(acc_val)\n",
        "\n",
        "        # — Print Results (if show_result is True) —\n",
        "        if show_result:\n",
        "            print(\n",
        "                f\"Epoch {epoch+1:02d} | \"\n",
        "                f\"Train ▶ Comb={loss_comb_train:.4f}, GCN={loss_gcn_train:.4f}, LLM={loss_llm_train:.4f}, Acc={acc_train:.4f} | \"\n",
        "                f\"Val   ▶ Comb={loss_comb_val:.4f}, GCN={loss_gcn_val:.4f}, LLM={loss_llm_val:.4f}, Acc={acc_val:.4f} | \"\n",
        "                f\"{time.time()-t0:.1f}s\"\n",
        "            )\n",
        "\n",
        "        # — Early Stopping Logic —\n",
        "        # Stop if validation combined loss does not improve for `EARLY_STOPPING` epochs\n",
        "        if loss_comb_val.item() < best_val_loss:\n",
        "            best_val_loss = loss_comb_val.item()\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= EARLY_STOPPING:\n",
        "                if show_result: print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    return (\n",
        "        history['train_combined'], history['train_acc'],\n",
        "        history['val_combined'],   history['val_acc']\n",
        "    )\n",
        "\n",
        "# Explicitly initialize GCN model and its optimizer before training\n",
        "# This ensures 'model' is the GCN instance and not overwritten by other modules.\n",
        "try:\n",
        "    # Validate features shape before initializing GCN\n",
        "    # If features is 1D, attempt to reshape it assuming the 1D size is num_nodes\n",
        "    # and we need to add a feature dimension (e.g., LLM embedding size).\n",
        "    if features.ndim == 1:\n",
        "        assumed_embedding_dim = 768 # Common BERT embedding dimension\n",
        "        print(f\"Warning: 'features' is 1D with shape {features.shape}. \"\n",
        "              f\"Attempting to reshape to 2D assuming {features.shape[0]} nodes and an embedding dimension of {assumed_embedding_dim}. \"\n",
        "              f\"Please ensure this assumption is correct in your data preparation steps.\")\n",
        "        features = features.unsqueeze(1).repeat(1, assumed_embedding_dim) # Reshape to (num_nodes, 1) and then repeat to (num_nodes, assumed_embedding_dim)\n",
        "        # Alternatively, if features are meant to be one-hot for vocab nodes, and LLM for doc nodes,\n",
        "        # this reshaping might not be universally applicable. The ideal fix is upstream.\n",
        "    elif features.ndim != 2:\n",
        "        raise ValueError(f\"Expected 'features' to be a 2D tensor (num_nodes, feature_dim), but got shape {features.shape}. \"\n",
        "                         f\"Please ensure LLM embeddings and other node features are correctly combined into a 2D tensor \"\n",
        "                         f\"in the preceding cells (e.g., where 'combined_features' is created).\")\n",
        "\n",
        "    # Assuming GCN class is defined and accessible in the notebook context\n",
        "    # and HIDDEN_DIM, NUM_LAYERS, DROP_OUT are defined.\n",
        "    # 'features.shape[1]' provides the correct input feature dimension (LLM embedding dim).\n",
        "    model = GCN(nfeat=features.shape[1], nhid=HIDDEN_DIM, nclass=num_labels, dropout=DROP_OUT, n_layers=NUM_LAYERS).to(device)\n",
        "    optimizer_gcn = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "except NameError as e:\n",
        "    print(f\"Error initializing GCN model: {e}. Please ensure GCN class and all necessary variables (HIDDEN_DIM, NUM_LAYERS, DROP_OUT, features, num_labels, device) are defined and accessible.\")\n",
        "    raise # Re-raise to stop execution if critical variables are missing.\n",
        "except ValueError as e:\n",
        "    print(f\"Configuration Error: {e}\")\n",
        "    raise # Re-raise to stop execution if features are malformed.\n",
        "\n",
        "\n",
        "# Execute the training process\n",
        "train_losses, train_accs, val_losses, val_accs = train_combined_model()\n",
        "\n",
        "# Print the final results after training\n",
        "print(f\"Final Training Combined Loss: {train_losses[-1]:.4f}\")\n",
        "print(f\"Final Training Accuracy: {train_accs[-1]:.4f}\")\n",
        "print(f\"Final Validation Combined Loss: {val_losses[-1]:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {val_accs[-1]:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from torch.optim import AdamW\n",
        "from torch.nn.parameter import Parameter\n",
        "from torch.nn.modules.module import Module\n",
        "import scipy.sparse as sp # Needed for sparse matrix operations in GCN\n",
        "\n",
        "# ————————————————— Assumptions ——————————————————\n",
        "# device, features, adj,\n",
        "# doc_encodings (all document encodings, e.g., from preprocess_texts for all_nodes)\n",
        "# labels (the original full labels tensor for all documents)\n",
        "# idx_train, idx_val, idx_test (from generate_train_val)\n",
        "# LR, WEIGHT_DECAY, NUM_EPOCHS, EARLY_STOPPING, HIDDEN_DIM, NUM_LAYERS, DROP_OUT\n",
        "# BATCH_SIZE (new assumption for LLM mini-batching)\n",
        "# are defined elsewhere in your notebook and are accessible in this scope.\n",
        "\n",
        "# Ensure encodings are on the correct device and are of type torch.LongTensor\n",
        "# This loop now applies to doc_encodings, as we will batch from it.\n",
        "for k in ('input_ids', 'attention_mask'):\n",
        "    if not isinstance(doc_encodings[k], torch.Tensor):\n",
        "        doc_encodings[k] = torch.tensor(doc_encodings[k], dtype=torch.long)\n",
        "    # Move to device (only once for the full dataset)\n",
        "    doc_encodings[k] = doc_encodings[k].to(device)\n",
        "\n",
        "\n",
        "# Determine number of labels (K should be defined from top_terms in previous cells)\n",
        "try:\n",
        "    num_labels = K\n",
        "except NameError:\n",
        "    print(\"Warning: K not defined, defaulting to 10 labels.\")\n",
        "    num_labels = 10\n",
        "\n",
        "# Load the LLM head for sequence classification\n",
        "llm_model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", num_labels=num_labels\n",
        ").to(device)\n",
        "\n",
        "# Multi-label binary cross-entropy with logits loss\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "\n",
        "def calc_acc(preds, labels, thresh=0.5):\n",
        "    \"\"\"\n",
        "    Calculates multi-label accuracy.\n",
        "    Args:\n",
        "        preds (torch.Tensor): Raw logits from the model.\n",
        "        labels (torch.Tensor): Ground truth binary labels.\n",
        "        thresh (float): Threshold to convert logits to binary predictions.\n",
        "    Returns:\n",
        "        float: Mean accuracy.\n",
        "    \"\"\"\n",
        "    # Apply sigmoid to logits and then threshold to get binary predictions\n",
        "    preds_bin = (torch.sigmoid(preds) > thresh).float()\n",
        "    # Ensure labels are float for element-wise comparison\n",
        "    if labels.dtype != torch.float:\n",
        "        labels = labels.float()\n",
        "    # Calculate accuracy: (correct predictions / total predictions) for each label, then mean\n",
        "    return (preds_bin == labels).float().mean().item()\n",
        "\n",
        "# --- GCN Layer Definition (Copied from your original notebook for completeness) ---\n",
        "class GraphConvolution(Module):\n",
        "    \"\"\"\n",
        "    Simple GCN layer, similar to https://arxiv.org/abs/1609.02907\n",
        "    \"\"\"\n",
        "    def __init__(self, in_features, out_features, drop_out=0, activation=None, bias=True):\n",
        "        super(GraphConvolution, self).__init__()\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.weight = Parameter(torch.FloatTensor(in_features, out_features))\n",
        "        if bias:\n",
        "            self.bias = Parameter(torch.zeros(1, out_features))\n",
        "        else:\n",
        "            self.register_parameter('bias', None)\n",
        "        self.reset_parameters(in_features, out_features)\n",
        "        self.dropout = torch.nn.Dropout(drop_out)\n",
        "        self.activation = activation\n",
        "\n",
        "    def reset_parameters(self, in_features, out_features):\n",
        "        stdv = np.sqrt(6.0 / (in_features + out_features))\n",
        "        self.weight.data.uniform_(-stdv, stdv)\n",
        "        # if self.bias is not None:\n",
        "        #     torch.nn.init.zeros_(self.bias)\n",
        "\n",
        "    def forward(self, input, adj, feature_less=False):\n",
        "        if feature_less:\n",
        "            support = self.weight\n",
        "            support = self.dropout(support)\n",
        "        else:\n",
        "            input = self.dropout(input)\n",
        "            support = torch.mm(input, self.weight)\n",
        "        output = torch.spmm(adj, support)\n",
        "        if self.bias is not None:\n",
        "            output = output + self.bias\n",
        "        if self.activation is not None:\n",
        "            output = self.activation(output)\n",
        "        return output\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + ' (' \\\n",
        "               + str(self.in_features) + ' -> ' \\\n",
        "               + str(self.out_features) + ')'\n",
        "\n",
        "# --- GCN Model Definition (Corrected) ---\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, nfeat, nhid, nclass, dropout, n_layers=2):\n",
        "        super(GCN, self).__init__()\n",
        "        self.n_layers = n_layers\n",
        "        self.gc_list = nn.ModuleList() # Initialize as ModuleList for proper registration\n",
        "\n",
        "        if n_layers >= 2:\n",
        "            # Explicitly pass drop_out and bias arguments\n",
        "            self.gc1 = GraphConvolution(nfeat, nhid, drop_out=dropout, activation=nn.ReLU(), bias=True)\n",
        "            for _ in range(self.n_layers - 2):\n",
        "                self.gc_list.append(GraphConvolution(nhid, nhid, drop_out=dropout, activation=nn.ReLU(), bias=True))\n",
        "            self.gcf = GraphConvolution(nhid, nclass, drop_out=dropout, activation=None, bias=True) # Last layer typically no activation for classification\n",
        "        else:\n",
        "            self.gc1 = GraphConvolution(nfeat, nclass, drop_out=dropout, activation=None, bias=True)\n",
        "\n",
        "    def forward(self, x, adj):\n",
        "        if self.n_layers >= 2:\n",
        "            # For the first layer, if features are not actual node features (e.g., just indices),\n",
        "            # `feature_less=True` uses only the weight matrix.\n",
        "            # If `features` are actual LLM embeddings, `feature_less` should be False.\n",
        "            # Assuming 'features' are now LLM embeddings, so `feature_less` should be False.\n",
        "            x = self.gc1(x, adj, feature_less=False) # Changed to False assuming LLM embeddings are real features\n",
        "            for i in range(self.n_layers - 2):\n",
        "                x = self.gc_list[i](x, adj)\n",
        "            x = self.gcf(x, adj)\n",
        "        else:\n",
        "            x = self.gc1(x, adj, feature_less=False) # Changed to False\n",
        "        return x\n",
        "\n",
        "def train_combined_model(show_result=True):\n",
        "    \"\"\"\n",
        "    Trains the combined GCN-LLM model with memory optimization.\n",
        "    Args:\n",
        "        show_result (bool): Whether to print epoch-wise training results.\n",
        "    Returns:\n",
        "        tuple: Lists of training combined loss, training accuracy,\n",
        "               validation combined loss, and validation accuracy.\n",
        "    \"\"\"\n",
        "    # Ensure all labels are on device and float\n",
        "    all_labels_tensor = torch.tensor(labels, dtype=torch.float).to(device) \\\n",
        "                        if not isinstance(labels, torch.Tensor) else labels.to(device).float()\n",
        "\n",
        "    # History lists to store metrics\n",
        "    history = {\n",
        "        'train_combined': [], 'train_gcn': [], 'train_llm': [], 'train_acc': [],\n",
        "        'val_combined': [],     'val_gcn': [],   'val_llm': [],   'val_acc': []\n",
        "    }\n",
        "\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS):\n",
        "        t0 = time.time()\n",
        "\n",
        "        model.train()\n",
        "        llm_model.train()\n",
        "\n",
        "        # Initialize epoch-level accumulators for training\n",
        "        total_gcn_loss_train_epoch = 0\n",
        "        total_llm_loss_train_epoch = 0\n",
        "        total_combined_loss_train_epoch = 0\n",
        "        correct_predictions_train = 0\n",
        "        total_samples_train = 0\n",
        "\n",
        "        # Shuffle idx_train for each epoch for better training\n",
        "        shuffled_idx_train = idx_train[torch.randperm(len(idx_train))]\n",
        "\n",
        "        # GCN forward pass for the entire graph (done once per epoch)\n",
        "        # This might still be memory intensive if 'features' or 'adj' are huge,\n",
        "        # but GCNs are generally more efficient with sparse 'adj'.\n",
        "        all_gcn_logits = model(features, adj)\n",
        "\n",
        "        # Iterate over mini-batches of training indices\n",
        "        for i in range(0, len(shuffled_idx_train), BATCH_SIZE):\n",
        "            batch_idx = shuffled_idx_train[i:i + BATCH_SIZE]\n",
        "\n",
        "            # Get LLM inputs and labels for the current batch from the full doc_encodings\n",
        "            batch_input_ids = doc_encodings['input_ids'][batch_idx].to(device)\n",
        "            batch_attention_mask = doc_encodings['attention_mask'][batch_idx].to(device)\n",
        "            batch_labels = all_labels_tensor[batch_idx] # Labels for this specific batch\n",
        "\n",
        "            # Zero gradients for both optimizers for this batch\n",
        "            optimizer_gcn.zero_grad()\n",
        "            optimizer_llm.zero_grad()\n",
        "\n",
        "            # — LLM Forward Pass for batch —\n",
        "            llm_output_batch = llm_model(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n",
        "            llm_logits_batch = llm_output_batch.logits\n",
        "            loss_llm_batch = criterion(llm_logits_batch, batch_labels)\n",
        "\n",
        "            # — GCN Forward Pass for batch (using pre-computed all_gcn_logits) —\n",
        "            gcn_logits_batch = all_gcn_logits[batch_idx]\n",
        "            loss_gcn_batch = criterion(gcn_logits_batch, batch_labels)\n",
        "\n",
        "            # Combined loss for backpropagation\n",
        "            loss_comb_batch = loss_gcn_batch + loss_llm_batch\n",
        "            loss_comb_batch.backward()\n",
        "\n",
        "            optimizer_gcn.step()\n",
        "            optimizer_llm.step()\n",
        "\n",
        "            # Accumulate losses and accuracy for epoch reporting\n",
        "            total_gcn_loss_train_epoch += loss_gcn_batch.item() * len(batch_idx)\n",
        "            total_llm_loss_train_epoch += loss_llm_batch.item() * len(batch_idx)\n",
        "            total_combined_loss_train_epoch += loss_comb_batch.item() * len(batch_idx)\n",
        "\n",
        "            # Calculate accuracy for the batch\n",
        "            combined_logits_batch = (gcn_logits_batch + llm_logits_batch) / 2\n",
        "            preds_bin_batch = (torch.sigmoid(combined_logits_batch) > 0.5).float()\n",
        "            correct_predictions_batch = (preds_bin_batch == batch_labels).float().sum().item()\n",
        "            total_samples_batch = batch_labels.numel() # Total elements in the batch labels\n",
        "\n",
        "            correct_predictions_train += correct_predictions_batch\n",
        "            total_samples_train += total_samples_batch\n",
        "\n",
        "            # Clear CUDA cache periodically to free up memory\n",
        "            if device.type == 'cuda':\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "        # Calculate epoch-level average losses and accuracy\n",
        "        avg_gcn_loss_train = total_gcn_loss_train_epoch / len(idx_train) if len(idx_train) > 0 else 0\n",
        "        avg_llm_loss_train = total_llm_loss_train_epoch / len(idx_train) if len(idx_train) > 0 else 0\n",
        "        avg_comb_loss_train = total_combined_loss_train_epoch / len(idx_train) if len(idx_train) > 0 else 0\n",
        "        acc_train = correct_predictions_train / total_samples_train if total_samples_train > 0 else 0\n",
        "\n",
        "\n",
        "        # — Validation Phase —\n",
        "        model.eval()\n",
        "        llm_model.eval()\n",
        "        with torch.no_grad():\n",
        "            # Initialize epoch-level accumulators for validation\n",
        "            total_gcn_loss_val_epoch = 0\n",
        "            total_llm_loss_val_epoch = 0\n",
        "            total_combined_loss_val_epoch = 0\n",
        "            correct_predictions_val = 0\n",
        "            total_samples_val = 0\n",
        "\n",
        "            # Iterate over mini-batches of validation indices\n",
        "            for i in range(0, len(idx_val), BATCH_SIZE):\n",
        "                batch_idx_val = idx_val[i:i + BATCH_SIZE]\n",
        "\n",
        "                # Get LLM inputs and labels for the current validation batch\n",
        "                batch_input_ids_val = doc_encodings['input_ids'][batch_idx_val].to(device)\n",
        "                batch_attention_mask_val = doc_encodings['attention_mask'][batch_idx_val].to(device)\n",
        "                batch_labels_val = all_labels_tensor[batch_idx_val]\n",
        "\n",
        "                # LLM Forward Pass for validation batch\n",
        "                llm_output_val_batch = llm_model(input_ids=batch_input_ids_val, attention_mask=batch_attention_mask_val)\n",
        "                llm_logits_val_batch = llm_output_val_batch.logits\n",
        "                loss_llm_val_batch = criterion(llm_logits_val_batch, batch_labels_val)\n",
        "\n",
        "                # GCN Forward Pass for validation batch (using pre-computed all_gcn_logits)\n",
        "                gcn_logits_val_batch = all_gcn_logits[batch_idx_val]\n",
        "                loss_gcn_val_batch = criterion(gcn_logits_val_batch, batch_labels_val)\n",
        "\n",
        "                # Combined loss for validation\n",
        "                loss_comb_val_batch = loss_gcn_val_batch + loss_llm_val_batch\n",
        "\n",
        "                # Accumulate losses and accuracy for epoch reporting\n",
        "                total_gcn_loss_val_epoch += loss_gcn_val_batch.item() * len(batch_idx_val)\n",
        "                total_llm_loss_val_epoch += loss_llm_val_batch.item() * len(batch_idx_val)\n",
        "                total_combined_loss_val_epoch += loss_comb_val_batch.item() * len(batch_idx_val)\n",
        "\n",
        "                # Calculate accuracy for the batch\n",
        "                combined_logits_val_batch = (gcn_logits_val_batch + llm_logits_val_batch) / 2\n",
        "                preds_bin_val_batch = (torch.sigmoid(combined_logits_val_batch) > 0.5).float()\n",
        "                correct_predictions_val_batch = (preds_bin_val_batch == batch_labels_val).float().sum().item()\n",
        "                total_samples_val_batch = batch_labels_val.numel()\n",
        "\n",
        "                correct_predictions_val += correct_predictions_val_batch\n",
        "                total_samples_val += total_samples_val_batch\n",
        "\n",
        "                if device.type == 'cuda':\n",
        "                    torch.cuda.empty_cache()\n",
        "\n",
        "            # Calculate epoch-level average losses and accuracy\n",
        "            avg_gcn_loss_val = total_gcn_loss_val_epoch / len(idx_val) if len(idx_val) > 0 else 0\n",
        "            avg_llm_loss_val = total_llm_loss_val_epoch / len(idx_val) if len(idx_val) > 0 else 0\n",
        "            avg_comb_loss_val = total_combined_loss_val_epoch / len(idx_val) if len(idx_val) > 0 else 0\n",
        "            acc_val = correct_predictions_val / total_samples_val if total_samples_val > 0 else 0\n",
        "\n",
        "        # Record metrics\n",
        "        history['train_combined'].append(avg_comb_loss_train)\n",
        "        history['train_gcn'].append(avg_gcn_loss_train)\n",
        "        history['train_llm'].append(avg_llm_loss_train)\n",
        "        history['train_acc'].append(acc_train)\n",
        "        history['val_combined'].append(avg_comb_loss_val)\n",
        "        history['val_gcn'].append(avg_gcn_loss_val)\n",
        "        history['val_llm'].append(avg_llm_loss_val)\n",
        "        history['val_acc'].append(acc_val)\n",
        "\n",
        "        # Print Results\n",
        "        if show_result:\n",
        "            print(\n",
        "                f\"Epoch {epoch+1:02d} | \"\n",
        "                f\"Train ▶ Comb={avg_comb_loss_train:.4f}, GCN={avg_gcn_loss_train:.4f}, LLM={avg_llm_loss_train:.4f}, Acc={acc_train:.4f} | \"\n",
        "                f\"Val   ▶ Comb={avg_comb_loss_val:.4f}, GCN={avg_gcn_val:.4f}, LLM={avg_llm_val:.4f}, Acc={acc_val:.4f} | \"\n",
        "                f\"{time.time()-t0:.1f}s\"\n",
        "            )\n",
        "\n",
        "        # Early stopping\n",
        "        if avg_comb_loss_val < best_val_loss:\n",
        "            best_val_loss = avg_comb_loss_val\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= EARLY_STOPPING:\n",
        "                if show_result: print(\"Early stopping triggered.\")\n",
        "                break\n",
        "\n",
        "    return (\n",
        "        history['train_combined'], history['train_acc'],\n",
        "        history['val_combined'],   history['val_acc']\n",
        "    )\n",
        "\n",
        "# Explicitly initialize GCN model and its optimizer before training\n",
        "# This ensures 'model' is the GCN instance and not overwritten by other modules.\n",
        "try:\n",
        "    # Validate features shape before initializing GCN\n",
        "    # If features is 1D, attempt to reshape it assuming the 1D size is num_nodes\n",
        "    # and we need to add a feature dimension (e.g., LLM embedding size).\n",
        "    if features.ndim == 1:\n",
        "        assumed_embedding_dim = 768 # Common BERT embedding dimension\n",
        "        print(f\"Warning: 'features' is 1D with shape {features.shape}. \"\n",
        "              f\"Attempting to reshape to 2D assuming {features.shape[0]} nodes and an embedding dimension of {assumed_embedding_dim}. \"\n",
        "              f\"Please ensure this assumption is correct in your data preparation steps.\")\n",
        "        features = features.unsqueeze(1).repeat(1, assumed_embedding_dim) # Reshape to (num_nodes, 1) and then repeat to (num_nodes, assumed_embedding_dim)\n",
        "        # Alternatively, if features are meant to be one-hot for vocab nodes, and LLM for doc nodes,\n",
        "        # this reshaping might not be universally applicable. The ideal fix is upstream.\n",
        "    elif features.ndim != 2:\n",
        "        raise ValueError(f\"Expected 'features' to be a 2D tensor (num_nodes, feature_dim), but got shape {features.shape}. \"\n",
        "                         f\"Please ensure LLM embeddings and other node features are correctly combined into a 2D tensor \"\n",
        "                         f\"in the preceding cells (e.g., where 'combined_features' is created).\")\n",
        "\n",
        "    # Assuming GCN class is defined and accessible in the notebook context\n",
        "    # and HIDDEN_DIM, NUM_LAYERS, DROP_OUT are defined.\n",
        "    # 'features.shape[1]' provides the correct input feature dimension (LLM embedding dim).\n",
        "    model = GCN(nfeat=features.shape[1], nhid=HIDDEN_DIM, nclass=num_labels, dropout=DROP_OUT, n_layers=NUM_LAYERS).to(device)\n",
        "    optimizer_gcn = optim.Adam(model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)\n",
        "except NameError as e:\n",
        "    print(f\"Error initializing GCN model: {e}. Please ensure GCN class and all necessary variables (HIDDEN_DIM, NUM_LAYERS, DROP_OUT, features, num_labels, device) are defined and accessible.\")\n",
        "    raise # Re-raise to stop execution if critical variables are missing.\n",
        "except ValueError as e:\n",
        "    print(f\"Configuration Error: {e}\")\n",
        "    raise # Re-raise to stop execution if features are malformed.\n",
        "\n",
        "\n",
        "# Execute the training process\n",
        "train_losses, train_accs, val_losses, val_accs = train_combined_model()\n",
        "\n",
        "# Print the final results after training\n",
        "print(f\"Final Training Combined Loss: {train_losses[-1]:.4f}\")\n",
        "print(f\"Final Training Accuracy: {train_accs[-1]:.4f}\")\n",
        "print(f\"Final Validation Combined Loss: {val_losses[-1]:.4f}\")\n",
        "print(f\"Final Validation Accuracy: {val_accs[-1]:.4f}\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
